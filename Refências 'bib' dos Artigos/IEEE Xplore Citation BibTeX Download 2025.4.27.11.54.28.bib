@INPROCEEDINGS{10349705,
  author={Liu, Huaizhe and Wang, Zhizongkai and Wu, Jiaqi and Gao, Lin},
  booktitle={2023 21st International Symposium on Modeling and Optimization in Mobile, Ad Hoc, and Wireless Networks (WiOpt)}, 
  title={A Stochastic Programming Approach for Joint Edge Server Deployment and Computation Offloading}, 
  year={2023},
  volume={},
  number={},
  pages={318-325},
  abstract={Mobile Edge Computing (MEC) is a promising approach for enhancing the quality-of-service (QoS) of AI-enabled applications in the B5G/6G era, via providing computation services at the network edge that approximate end-users. In this work, we focus on the joint optimization of edge server (ES) deployment, service placement, and computation task offloading under stochastic information scenario. In traditional solutions, these decisions are often treated equally without considering differences in the information realization. In practice, however, the ES deployment decision needs to be made in advance before the complete information is realized, while the service placement and computation task offloading decisions can be made after the complete information is realized. To capture the time coupling between different decisions and information realizations, we formulate a two-layer stochastic programming (SP) problem, which consists of a strategic-layer decision for ES deployment, and a tactical-layer decision for service placement and computation task offloading. The strategic-layer decision will be made based on the stochastic information (i.e., before the complete information is realized), while the tactical-layer decision will be made based on every information realization. The problem is very challenging due to the large number of information realizations and the corresponding tactical-layer decisions. To solve the problem effectively, we propose a Sample Average Approximate (SAA) method to approximate the optimal solution, which involves generating a large number of randomly sampled information scenarios and using their averages to estimate the expected value of the objective function. Numerical simulations show that our proposed SP approach outperforms the traditional solutions that do not consider the coupling between decisions and information realizations. Moreover, compared with the ideal benchmark solution that assumes complete information, our proposed SP approach only results in a small performance degradation of 1.03% $\sim$ 6.26%.},
  keywords={Couplings;Wireless networks;Stochastic processes;Quality of service;Programming;Linear programming;Numerical simulation},
  doi={10.23919/WiOpt58741.2023.10349705},
  ISSN={2690-3342},
  month={Aug},}@INPROCEEDINGS{10799961,
  author={Wang, Siyi and Wen, Xinyi and Wang, Ying and Liu, Yunzheng and Li, Jian and He, Haojie and Zeng, Dexian and Zhang, Wenzheng},
  booktitle={2024 4th International Conference on Electronic Information Engineering and Computer Science (EIECS)}, 
  title={Deep Learning Based Oracle Segmentation and Recognition}, 
  year={2024},
  volume={},
  number={},
  pages={1132-1140},
  abstract={Oracle bone writing is the earliest known mature writing system in China, which is an ancient script engraved on tortoise shell or animal bone. Oracle script has extremely important research value, which is not only of great significance to the origin of Chinese civilisation, but also has a far-reaching impact on the study of world civilisation. Under the vigorous promotion of our government, the study of oracle bone inscriptions has entered a brand new stage of development. Artificial intelligence and big data technology are applied to oracle bone holographic research and digital engineering construction, which has become a research hotspot in the field of oracle bone information processing [1].},
  keywords={Deep learning;Image segmentation;Computational modeling;Government;Writing;Predictive models;Big Data;Bones;Data models;Artificial intelligence;component;filter;U-Net model;Transforme model;fully connected layer},
  doi={10.1109/EIECS63941.2024.10799961},
  ISSN={},
  month={Sep.},}@ARTICLE{9920165,
  author={Heo, Ki Joon and Lee, Yeawan and Kim, Sang Bok and Kim, Yong-Jin and Han, Bangwoo and Kim, Hak-Joon},
  journal={IEEE Transactions on Industry Applications}, 
  title={The Electro-Thermal Antimicrobial Carbon Surface}, 
  year={2023},
  volume={59},
  number={1},
  pages={473-478},
  abstract={Microorganisms on the surface are important contributors to producing a serious threat to global public health. Herein, we introduce an electro-thermal antimicrobial carbon surface. When a 9 V direct voltage was applied to the carbon surface, the carbon fibre surface temperature reached 80 °C. This electro-thermal-based antimicrobial carbon surface showed outstanding inactivation performance, exhibiting a potent inactivation rate of ∼99.99% against Gram-positive bacteria (Staphylococcus epidermidis) and Gram-negative bacteria (Escherichia coli) in just 10 min. Interestingly, under the same temperature, when alternating voltages were applied, electro-thermal antimicrobial performance was enhanced, resulting in a >6.0 log reduction against both Gram-positive and Gram-negative bacteria. In addition, under alternating voltage applied conditions, this excellent electro-thermal-based antimicrobial performance was maintained even at a lower surface temperature (50 °C).},
  keywords={Microorganisms;Carbon;Surface cleaning;Surface resistance;Immune system;Optical fibers;Voltage;Alternating current;antimicrobial surface;carbon fibre;direct current;electro-thermal effects},
  doi={10.1109/TIA.2022.3214802},
  ISSN={1939-9367},
  month={Jan},}@INPROCEEDINGS{10405622,
  author={Barletta, Vita Santa and Caivano, Danilo and De Vincentiis, Mirko and Pal, Anibrata and Volpe, Francesco},
  booktitle={2023 IEEE International Conference on Metrology for eXtended Reality, Artificial Intelligence and Neural Engineering (MetroXRAINE)}, 
  title={Automotive Knowledge Base for Supporting Vehicle-SOC Analysts}, 
  year={2023},
  volume={},
  number={},
  pages={960-965},
  abstract={With the introduction of more and more ECUs and components in vehicles, the automotive industry is moving towards increasingly connected and autonomous driving. This means not only more functionality available but also an increased risk to vehicle security and driver safety. Therefore, it is necessary to improve the existing solutions and create new techniques and methods not only to detect cyber attacks but also to mitigate and respond with appropriate actions. The paper proposes a Knowledge Base in Automotive to be integrated within a Vehicle Security Operation Center (V-SOC) in order to provide support to analysts in being able to reconstruct the attack kill chain and understand the impact of the attack on other components. The idea is to exploit, at this stage of the research, existing taxonomies in the literature on automotive attacks in order to obtain the classification of existing attacks, the automotive security development process, and the decomposition of incidents that consist of multiple attack steps.},
  keywords={Knowledge based systems;Taxonomy;Neural engineering;Safety;Security;Automotive engineering;Vehicles;knowledge base;automotive;cybersecurity},
  doi={10.1109/MetroXRAINE58569.2023.10405622},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10896033,
  author={Onishi, Kazuho and Uranishi, Yuki and Kobayashi, Masato and Liu, Chang and Yamamoto, Goshiro and Photchara, Ratsamee},
  booktitle={2025 IEEE International Conference on Artificial Intelligence and eXtended and Virtual Reality (AIxVR)}, 
  title={Generating Double Dyno Motion for Humanoid Agents in Simulated Bouldering Environment Through Deep Reinforcement Learning}, 
  year={2025},
  volume={},
  number={},
  pages={441-447},
  abstract={Capturing human motion data is crucial for creating realistic character animation and analyzing sports movements. With the widespread availability of motion capture devices, obtaining realistic motion data has become more accessible. Meanwhile, it is still challenging to capture quality motion data of extensive movements due to bulky equipment or simply the high cost. This paper investigates the feasibility of generating realistic motion data by combining virtual humanoids and deep reinforcement learning. Specifically, we take bouldering as a target environment where it is challenging to deploy conventional motion capture devices. If motion generation can be achieved in bouldering, a potential application could involve observing exemplary motions through VR or AR, thereby enhancing the efficiency of training. We trained a humanoid to perform a double dyno in a simulated bouldering environment and compared this motion to a human performing the same move. By evaluating the realism of the motion data, we found that although the humanoid's movements differed from human movements, there were certain aspects where the humanoid's actions closely resem-bled those of humans. Furthermore, it is suggested that applying penalties for inappropriate movements can lead to more natural motions.},
  keywords={Training;Performance evaluation;Motion segmentation;Humanoid robots;Virtual reality;Deep reinforcement learning;Minimization;Dynamometers;Motion capture;Sports;reinforcement learning;humanoid;motion generation},
  doi={10.1109/AIxVR63409.2025.00083},
  ISSN={2771-7453},
  month={Jan},}@INPROCEEDINGS{10369921,
  author={P, Elantheraiyan and K, Vinayagam and P, Sasikumar and M, Kotteeswaran and K S, Thirunavukkarasu and K, Sankar Singh},
  booktitle={2023 International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering (RMKMATE)}, 
  title={Revolutionizing E-Commerce - Deep Learning and Distributed Expression for Cutting-Edge Product Advertising}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={This research paper explores the revolutionary potential of leveraging deep learning techniques and distributed expression strategies to transform the landscape of e-commerce product advertising. With the exponential growth of online shopping, effective product advertising has become a critical aspect of capturing consumer attention and driving sales. In this study, the research delves into the application of deep learning algorithms for analyzing vast amounts of product data, enabling automated content generation, personalized recommendations, and improved understanding of consumer behavior. Additionally, the research investigates the benefits of employing distributed expression methods to enhance the reach and impact of product advertisements across various online platforms. By combining the power of deep learning with distributed expression, businesses can create cutting-edge advertising campaigns that are not only highly engaging but also tailored to individual customer preferences. Through real-world case studies and performance evaluations, the research highlights the significant potential of this approach in revolutionizing e-commerce product advertising and its implications for the future of online retail.},
  keywords={Deep learning;Visualization;Consumer behavior;Heuristic algorithms;Biological system modeling;Customer satisfaction;Transforms;Deep Learning;E-Commerce;Product Advertising;Distributed Expression;Personalization},
  doi={10.1109/RMKMATE59243.2023.10369921},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10405384,
  author={Goh, Michelle and Jeong, Harim and Yoo, Joo Hun and Han, Oakyoung},
  booktitle={2023 IEEE International Conference on Agents (ICA)}, 
  title={Self-Disclosure in Digital Healthcare: Enhancing User Engagement}, 
  year={2023},
  volume={},
  number={},
  pages={63-68},
  abstract={In the growing digital healthcare field, enhancing user engagement is crucial for the sustained usage of e-intervention treatments. This study focuses on improving user engagement by investigating how users interact with agents in a conversational context. To achieve this, we examined communication techniques for building relationships in counseling and selected self-disclosure (SD) as our approach to assess its effectiveness. We created conversational scripts based on iCBT, a prevalent psychotherapy method in digital mental healthcare, and conducted an empirical study with 40 participants. Participants were randomly assigned to two groups: one that contained SD and one without. Our analysis focused on the user experience and its impact on engagement. The findings indicate that employing SD enhances user engagement, agent perception, and intention to use. Conversely, conversations without SD are perceived as task-focused, resulting in reduced engagement and intention to use. This study serves as a foundation for understanding the potential of SD and underscores the need for further exploration in diverse digital healthcare contexts.},
  keywords={Employee welfare;Instruments;Medical treatment;Oral communication;User experience;Electronic healthcare;Task analysis;Human-computer interaction;self-disclosure;virtual agent;digital healthcare;conversational AI agent},
  doi={10.1109/ICA58824.2023.00020},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9222984,
  author={Pohl, Daniel and Panneer, Selvakumar and Vembar, Deepak S. and Marshall, Carl S.},
  booktitle={2020 15th Conference on Computer Science and Information Systems (FedCSIS)}, 
  title={15 Years Later: A Historic Look Back at “Quake 3: Ray Traced”}, 
  year={2020},
  volume={},
  number={},
  pages={401-412},
  abstract={Real-time ray tracing has been a goal and a challenge in the graphics field for many decades. With recent advances in the hardware and software domains, this is becoming a reality today. In this work, we describe how we got to this point by taking a look back at one of the first fully ray traced games: “Quake 3: Ray Traced”. We provide insight into the development steps of the project with unreleased internal details and images. From a historical perspective, we look at the challenges pioneering in this area in the year 2004 and highlight the learnings in implementing the system, many of which are relevant today. We start by going from a blank screen to the full ray traced gaming experience with dynamic animations, lighting, rendered special effects and a simplistic implementation of the gameplay with basic AI enemies. We describe the challenges encountered with aliasing and the methods used to alleviate it. Lastly, we describe for the first time the unofficial continuation of the project, code named “Quake 3: Team Arena Ray Traced”, and provide an overview of the changes over the past 15 years that made it possible to generate fully ray-traced interactive gaming experiences with mass market hardware and an open software stack.},
  keywords={Computer science;Lighting;Games;Computer architecture;Ray tracing;Rendering (computer graphics);Hardware;ray tracing;computer},
  doi={10.15439/2020F3},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10205307,
  author={Zheng, Juntian and Zheng, Qingyuan and Fang, Lixing and Liu, Yun and Yi, Li},
  booktitle={2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={CAMS: CAnonicalized Manipulation Spaces for Category-Level Functional Hand-Object Manipulation Synthesis}, 
  year={2023},
  volume={},
  number={},
  pages={585-594},
  abstract={In this work, we focus on a novel task of category-level functional hand-object manipulation synthesis covering both rigid and articulated object categories. Given an object geometry, an initial human hand pose as well as a sparse control sequence of object poses, our goal is to generate a physically reasonable hand-object manipulation sequence that performs like human beings. To address such a challenge, we first design CAnonicalized Manipulation Spaces (CAMS), a two-level space hierarchy that canonicalizes the hand poses in an object-centric and contact-centric view. Benefiting from the representation capability of CAMS, we then present a two-stage framework for synthesizing human-like manipulation animations. Our framework achieves state-of-the-art performance for both rigid and articulated categories with impressive visual effects. Codes and video results can be found at our project homepage: https://cams-hoi.github.io/},
  keywords={Geometry;Computer vision;Codes;Synthesizers;Aerospace electronics;Visual effects;Animation;Vision + graphics},
  doi={10.1109/CVPR52729.2023.00064},
  ISSN={2575-7075},
  month={June},}@INPROCEEDINGS{9747023,
  author={Lakew, Surafel M. and Virkar, Yogesh and Mathur, Prashant and Federico, Marcello},
  booktitle={ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={ISOMETRIC MT: Neural Machine Translation for Automatic Dubbing}, 
  year={2022},
  volume={},
  number={},
  pages={6242-6246},
  abstract={Automatic dubbing (AD) is among the machine translation (MT) use cases where translations should match a given length to allow for synchronicity between source and target speech. For neural MT, generating translations of length close to the source length (e.g. within ±10% in character count), while preserving quality is a challenging task. Controlling MT output length comes at a cost to translation quality, which is usually mitigated with a two step approach of generating N-best hypotheses and then re-ranking based on length and quality. This work introduces a self-learning approach that allows a transformer model to directly learn to generate outputs that closely match the source length, in short Isometric MT. In particular, our approach does not require to generate multiple hypotheses nor any auxiliary ranking function. We report results on four language pairs (English → French, Italian, German, Spanish) with a publicly available benchmark. Automatic and manual evaluations show that our method for Isometric MT outperforms more complex approaches proposed in the literature.},
  keywords={Costs;Impedance matching;Conferences;Manuals;Signal processing;Benchmark testing;Transformers;Machine Translation;Isometric Translation;Automatic Dubbing},
  doi={10.1109/ICASSP43922.2022.9747023},
  ISSN={2379-190X},
  month={May},}@ARTICLE{10474024,
  author={Liu, Chang and Jia, Kebin},
  journal={IEEE Access}, 
  title={Multi-Layer Features Fusion Model-Guided Low-Complexity 3D-HEVC Intra Coding}, 
  year={2024},
  volume={12},
  number={},
  pages={41074-41083},
  abstract={Three-dimensional (3D) video with depth information is essential for many applications in the consumer electronics industry. The 3D-high efficiency video coding (3D-HEVC) is the latest 3D video coding standard. Nonetheless, it utilizes various complex coding techniques to create extra intermediate views for better representation of 3D videos, which imposes significant challenges for real-time 3D video applications. Specifically, the high complexity of 3D-HEVC intra coding could be a significant barrier to the adoption of 3D video in consumer electronics. Therefore, in this research, a low-complexity 3D-HEVC intra coding technique is proposed. Firstly, we perform a complexity analysis of 3D-HEVC intra coding. Secondly, we develop a multi-layer features fusion (MLFF) model to estimate the optimal coding tree unit (CTU) depth and prediction unit (PU) mode. Thirdly, to improve the model’s prediction accuracy, we incorporate two external features into the model: the quantization parameter (QP) and texture complexity. Finally, we embed the MLFF model into the 3D-HEVC test platform. The experimental results demonstrate that the suggested method can effectively reduce the 3D-HEVC intra coding time with a small amount of rate-distortion (RD) performance loss while maintaining the subjective quality of the synthesized view.},
  keywords={Encoding;Three-dimensional displays;Streaming media;Predictive models;Video coding;Convolutional neural networks;Computational complexity;3D video;3D-HEVC;intra coding;low-complexity;multi-layer features fusion model},
  doi={10.1109/ACCESS.2024.3378285},
  ISSN={2169-3536},
  month={},}@ARTICLE{10928340,
  author={Muhammad Raza Ur Rehman, Hafiz and Arfan Haider, Syed and Faisal, Hiba and Yoo, Kook-Yeol and Jhandir, M. Z. and Choi, Gyu Sang},
  journal={IEEE Access}, 
  title={A Novel Framework for Saraiki Script Recognition Using Advanced Machine Learning Models (YOLOv8 and CNN)}, 
  year={2025},
  volume={13},
  number={},
  pages={56843-56860},
  abstract={In recent years, a lot of local languages require careful consideration in terms of knowledge exchange. Each language creates a sophisticated understanding system that allows users to interact, communicate, express ideas, and define demands. With an emphasis on language’s structure, usage, and social dimensions, linguistics examines these systems holistically. Linguistics’ fundamental goal is to comprehend how language functions in composition and context. On the other hand, machine learning is the study of how to teach machines to learn and predict using data instead of explicit programming. By combining these two domains, machine learning has emerged as a potent instrument in linguistics, improving our capacity to comprehend semantics, analyze verbal patterns, and even simulate human-like replies. This work represents a major breakthrough in the use of machine learning models for the detection and replication of Saraiki handwritten text as Saraiki is one of the important language. Accurate and reliable OCR systems tailored to the Saraiki script were the aim. The study used Convolutional Neural Networks (CNNs) in conjunction with YOLOv8 models to address the problems of recognizing Saraiki alphabets’ primary and secondary components. Several data augmentation approaches were used to improve the performance of these models, which had been painstakingly trained. After four distinct models A, B, C, and D were trained, Model D continuously performed better than the others. Additionally, the study introduced the “Saraiki Handwritten Characters” Dataset (SHC), which features well-labeled segmented characters evaluated by annotators. This research provides insight into Saraiki script machine learning models and opens the door to Saraiki language text processing, transcription, and document digitization, contributing to OCR and showing how machine learning can preserve linguistic diversity.},
  keywords={Optical character recognition;Machine learning;Accuracy;Text recognition;Convolutional neural networks;Data models;Character recognition;Predictive models;Linguistics;Handwriting recognition;OCR;neural networks;YOLOv8;language recognition system;Saraiki;CNN},
  doi={10.1109/ACCESS.2025.3551747},
  ISSN={2169-3536},
  month={},}@ARTICLE{9712270,
  author={Fan, Chen-Chen and Peng, Liang and Wang, Tian and Yang, Hongjun and Zhou, Xiao-Hu and Ni, Zhen-Liang and Wang, Guan’an and Chen, Sheng and Zhou, Yan-Jie and Hou, Zeng-Guang},
  journal={IEEE Transactions on Medical Imaging}, 
  title={TR-GAN: Multi-Session Future MRI Prediction With Temporal Recurrent Generative Adversarial Network}, 
  year={2022},
  volume={41},
  number={8},
  pages={1925-1937},
  abstract={Magnetic Resonance Imaging (MRI) has been proven to be an efficient way to diagnose Alzheimer’s disease (AD). Recent dramatic progress on deep learning greatly promotes the MRI analysis based on data-driven CNN methods using a large-scale longitudinal MRI dataset. However, most of the existing MRI datasets are fragmented due to unexpected quits of volunteers. To tackle this problem, we propose a novel Temporal Recurrent Generative Adversarial Network (TR-GAN) to complete missing sessions of MRI datasets. Unlike existing GAN-based methods, which either fail to generate future sessions or only generate fixed-length sessions, TR-GAN takes all past sessions to recurrently and smoothly generate future ones with variant length. Specifically, TR-GAN adopts recurrent connection to deal with variant input sequence length and flexibly generate future variant sessions. Besides, we also design a multiple scale & location (MSL) module and a SWAP module to encourage the model to better focus on detailed information, which helps to generate high-quality MRI data. Compared with other popular GAN architectures, TR-GAN achieved the best performance in all evaluation metrics of two datasets. After expanding the Whole MRI dataset, the balanced accuracy of AD vs. cognitively normal (CN) vs. mild cognitive impairment (MCI) and stable MCI vs. progressive MCI classification can be increased by 3.61% and 4.00%, respectively.},
  keywords={Magnetic resonance imaging;Generative adversarial networks;Task analysis;Three-dimensional displays;Training;Generators;Data models;Alzheimer’s disease;magnetic resonance imaging;generative adversarial network},
  doi={10.1109/TMI.2022.3151118},
  ISSN={1558-254X},
  month={Aug},}@ARTICLE{9732473,
  author={Lee, Chang-Ki and Cheon, Yu-Jeong and Hwang, Wook-Yeon},
  journal={IEEE Access}, 
  title={Least Squares Generative Adversarial Networks-Based Anomaly Detection}, 
  year={2022},
  volume={10},
  number={},
  pages={26920-26930},
  abstract={Multivariate statistical process control (MSPC) is a technique for detecting anomalies by monitoring several quality characteristics simultaneously. For the MSPC problem, the Hotelling’s  $T^{2}$  control chart has been widely used as a typical method. Recently, researchers have converted the MSPC problem into a classification problem such as the artificial contrast (AC) and the one-class classification (OCC). Previous studies have shown that these methods outperform the Hotelling’s  $T^{2}$  chart when the data do not follow a multivariate normal distribution. However, unless the size of the process data is enough for the AC and the OCC, they cannot work properly. To tackle this problem, in this paper, we propose a novel anomaly detection (AD) approach. The proposed method adopts the least square generative adversarial network (LS-GAN) to estimate the probability distribution of the training data. It generates new training samples from the learned probability distribution. The classifiers such as the random forests (RF) and the one-class support vector machines (OC-SVM) are considered for tackling the AC and the OCC respectively. The numerical experiments demonstrate that the proposed approach outperforms the existing methods in terms of the area under the receiver operating characteristic (ROC) curve (AUC).},
  keywords={Generative adversarial networks;Process control;Monitoring;Control charts;Anomaly detection;Support vector machines;Data models;Anomaly detection;artificial contrast;one-class classification;least square generative adversarial network;Hotelling’s control boundary;random forests;one-class support vector machines},
  doi={10.1109/ACCESS.2022.3158343},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10654959,
  author={Liu, Chang and Wu, Haoning and Zhong, Yujie and Zhang, Xiaoyun and Wang, Yanfeng and Xie, Weidi},
  booktitle={2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Intelligent Grimm - Open-ended Visual Storytelling via Latent Diffusion Models}, 
  year={2024},
  volume={},
  number={},
  pages={6190-6200},
  abstract={Generative models have recently exhibited exceptional capabilities in text-to-image generation, but still struggle to generate image sequences coherently. In this work, we focus on a novel, yet challenging task of generating a co-herent image sequence based on a given storyline, denoted as open-ended visual storytelling. We make the following three contributions: (i) to fulfill the task of visual sto-rytelling, we propose a learning-based auto-regressive im-age generation model, termed as Story Gen, with a novel vision-language context module, that enables to generate the current frame by conditioning on the corresponding text prompt and preceding image-caption pairs; (ii) to ad-dress the data shortage of visual storytelling, we collect paired image-text sequences by sourcing from online videos and open-source E-books, establishing processing pipeline for constructing a large-scale dataset with diverse characters, storylines, and artistic styles, named StorySalon; (iii) Quantitative experiments and human evaluations have vali-dated the superiority of our StoryGen, where we show it can generalize to unseen characters without any optimization, and generate image sequences with coherent content and consistent character. Code, dataset, and models are avail-able at https://haoningwu3639.github.io/StoryGen_Webpage/. “Mirror mirror on the wall, who's the fairest of them all?” -Grimms' Fairy Tales},
  keywords={Visualization;Electronic publishing;Computational modeling;Pipelines;Text to image;Image sequences;Pattern recognition;Story Generation;Diffusion Models},
  doi={10.1109/CVPR52733.2024.00592},
  ISSN={2575-7075},
  month={June},}@ARTICLE{9709124,
  author={Dhar, Sandipan and Jana, Nanda Dulal and Das, Swagatam},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={An Adaptive-Learning-Based Generative Adversarial Network for One-to-One Voice Conversion}, 
  year={2023},
  volume={4},
  number={1},
  pages={92-106},
  abstract={Voice conversion (VC) emerged as a significant domain of research in the field of speech synthesis in recent years due to its emerging application in voice-assistive technologies, such as automated movie dubbing speech-to-singing conversion, to name a few. VC deals with the conversion of the vocal style of one speaker to another speaker while keeping the linguistic contents unchanged. Nowadays, generative adversarial network (GAN) models are widely used for speech feature mapping from the source speaker to the target speaker. In this article, we propose an adaptive-learning-based GAN model, called ALGAN-VC, to improve the one-to-one VC of speakers. Our ALGAN-VC framework consists of some approaches to improve the speech quality and voice similarity between the source and target speakers. We incorporate a dense residual network architecture into the generator network for efficient speech feature learning between source and target speakers. Our framework also includes an adaptive learning mechanism to compute the loss function for the proposed model. Moreover, a boosted learning rate approach is incorporated to enhance the learning capability of the proposed model. The proposed model is tested on Voice Conversion Challenge 2016, 2018, and 2020 datasets along with our self-prepared Indian regional-language-based speech dataset. In addition, an emotional speech dataset is also considered for evaluating the model’s performance. The objective and subjective evaluations of the generated speech samples indicated that the proposed model elegantly performed the voice conversion task by achieving high speaker similarity and good speech quality.},
  keywords={Generative adversarial networks;Adaptation models;Generators;Data models;Computational modeling;Wide band gap semiconductors;Aluminum gallium nitride;Adaptive learning;boosted learning;generative adversarial network (GAN);speech synthesis;voice conversion (VC)},
  doi={10.1109/TAI.2022.3149858},
  ISSN={2691-4581},
  month={Feb},}@ARTICLE{10230214,
  author={Martins, Paulo and da Silva, Altigran Soares and Afonso, Ariel and Cavalcanti, João and de Moura, Edleno},
  journal={IEEE Access}, 
  title={Supporting Schema References in Keyword Queries Over Relational Databases}, 
  year={2023},
  volume={11},
  number={},
  pages={92365-92390},
  abstract={Relational Keyword Search (R-KwS) systems enable naive/informal users to explore and retrieve information from relational databases without knowing schema details or query languages. They take a keyword query, locate their corresponding elements in the target database, and connect them using information on PK/FK constraints. Although there are many such systems in the literature, most of them only support queries with keywords referring to the contents of the database and just very few support queries with keywords refering the database schema. We propose Lathe, a novel R-KwS that supports such queries. To this end, we first generalize the well-known concepts of Candidate Joining Networks (CJNs) and Query Matches (QMs) to handle keywords referring to schema elements and propose new algorithms to generate them. Then, we introduce two major innovations: a ranking algorithm for selecting better QMs, yielding the generation of fewer but better CJNs, and an eager evaluation strategy for pruning void useless CJNs. We present experiments performed with query sets and datasets previously experimented with state-of-theart R-KwS systems. Our results indicate that Lathe can handle a wider variety of queries while remaining highly effective, even for databases with intricate schemas.},
  keywords={Relational databases;Keyword search;Terminology;Technological innovation;Motion pictures;Films;Information retrieval;Relational databases;keyword search;information retrieval},
  doi={10.1109/ACCESS.2023.3308908},
  ISSN={2169-3536},
  month={},}@ARTICLE{8746184,
  author={Miklosik, Andrej and Kuchta, Martin and Evans, Nina and Zak, Stefan},
  journal={IEEE Access}, 
  title={Towards the Adoption of Machine Learning-Based Analytical Tools in Digital Marketing}, 
  year={2019},
  volume={7},
  number={},
  pages={85705-85718},
  abstract={Exponential technological expansion creates opportunities for competitive advantage by applying new data-oriented approaches to digital marketing practices. Machine learning (ML) can predict future developments and support decision-making by extracting insights from large amounts of generated data. This functionality greatly impacts and streamlines the strategic decision-making process of organizations. The research gap analysis revealed that a little is known about marketers' attitude toward, and knowledge about, ML tools and their adoption and utilization to support strategic and operational management. The research presented here focuses on the selection and adoption of the ML-driven analytical tools by three distinct groups: marketing agencies, media companies, and advertisers. Qualitative and quantitative research was conducted on a sample of these organizations operating in Slovakia. The findings highlight: 1) the important role of intelligent analytical tools in the creation and deployment of marketing strategies; 2) the lack of knowledge about emerging technologies, such as ML and artificial intelligence (AI); 3) the potential application of the ML tools in marketing, and; 4) the low level of adoption and utilization of the ML-driven analytical tools in marketing management. A framework consisting of enablers and a process map was developed to help organizations identify the opportunities and successfully execute projects that are oriented toward the deployment and adoption of the analytical ML tools in digital marketing.},
  keywords={Tools;Decision making;Strategic planning;Companies;Internet;Big data;data-driven analytical tools;digital marketing;machine learning (ML);marketing agencies;marketing analysis},
  doi={10.1109/ACCESS.2019.2924425},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10550894,
  author={Liao, Tingting and Yi, Hongwei and Xiu, Yuliang and Tang, Jiaxiang and Huang, Yangyi and Thies, Justus and Black, Michael J.},
  booktitle={2024 International Conference on 3D Vision (3DV)}, 
  title={TADA! Text to Animatable Digital Avatars}, 
  year={2024},
  volume={},
  number={},
  pages={1508-1519},
  abstract={We introduce TADA, a simple-yet-effective approach that takes textual descriptions and produces expressive 3D avatars with high-quality geometry and lifelike textures, that can be animated and rendered with traditional graphics pipelines. Existing text-based character generation methods are limited in terms of geometry and texture quality, and cannot be realistically animated due to the misalignment between the geometry and the texture, particularly in the face region. To address these limitations, TADA leverages the synergy of a 2D diffusion model and a parametric body model. Specifically, we derive a high-resolution upsampled version of SMPL-X with a displacement layer and a texture map, and use hierarchical rendering with score distillation sampling (SDS) to create high-quality, detailed, holistic 3D avatars from text. To ensure alignment between the geometry and texture, we render normals and RGB images of the generated character and exploit their latent embeddings during the SDS optimization process. We further drive the character’s face with multiple expressions during optimization, ensuring that its semantics remain consistent with the original SMPL-X model. Both qualitative and quantitative evaluations show that TADA significantly surpasses existing approaches. TADA enables large-scale creation of digital characters ready for animation and rendering, while also enabling text-guided editing. The code is public for research purposes at tada.is.tue.mpg.de},
  keywords={Geometry;Training;Three-dimensional displays;Avatars;Semantics;Pipelines;Rendering (computer graphics);text-to-3D generation;animatable human},
  doi={10.1109/3DV62453.2024.00150},
  ISSN={2475-7888},
  month={March},}@INPROCEEDINGS{9898510,
  author={Chao, Jia},
  booktitle={2022 International Conference on Artificial Intelligence in Everything (AIE)}, 
  title={3D visual art design method based on virtual reality}, 
  year={2022},
  volume={},
  number={},
  pages={389-394},
  abstract={Vision is the most primitive perceptual impulse of human beings. Modern visual art widely exists in consumer life in daily life. It is a rational combination of visual enjoyment. Visual images such as advertising, film and television are the intermediary for people to express their desires. 3D visual art design method is a digital art creation method based on virtual reality. This process first creates a 3D model of an object or scene, and then uses computer graphics software to create a real image that can be viewed through VR goggles. This allows the artist to see the appearance of the work before it is actually created, thereby reducing pressure and improving accuracy. It also allows artists who have not been trained in traditional painting techniques to create high-quality images without having to learn new skills. Therefore, the research of 3D visual art design method based on virtual reality is an advanced computer interface, which has the basic characteristics of storage, interaction and imagination. Users perceive the information in the virtual environment by observing, listening, touching and other perceptual behaviors, interact with the virtual environment, cause real-time changes in the virtual environment, and create a human multi-dimensional information space, which has a wide application prospect.},
  keywords={Visualization;Technological innovation;Solid modeling;Art;Three-dimensional displays;TV;Design methodology;Virtual reality technology;Three dimensional visual art;Art de-sign},
  doi={10.1109/AIE57029.2022.00081},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10263493,
  author={He, Haichuan and Yang, Siyi},
  booktitle={2023 IEEE International Conference on Sensors, Electronics and Computer Engineering (ICSECE)}, 
  title={Mechanical Mouse with Artificial Intelligence Vision}, 
  year={2023},
  volume={},
  number={},
  pages={625-632},
  abstract={Pests not only harm agricultural production but also pose a threat to the lives of ordinary people. To maximize the efficiency of eliminating pests in the fields, after reading extensively about bio-mimicking, we set out to create a mechanical mouse. Learning from one of the traits of mice, flexibility, the design of the model is made up of three big servos and four mini servos. The mobile phone is used as a remote Bluetooth control, which successfully realizes the mouse’s various gestures. A camera is installed at the front of the mouse, and through multi-joint movements, the camera is capable of filming in various degrees and directions. Combining with the deep learning methods for insect recognition that we studied, including YOLOv5 object detection, semi-supervised pseudo-label learning, and fine-tuning, pests identification could eventually be realized. Through our experiments, the mouse has an average speed of 0.117m/s. The camera at the front could film in a wide range of upward 84 degrees, downward 47 degrees, leftward 85 degrees and rightward 85 degrees.When the mouse is working in the fields while filming in wide view, once a pest is detected, the person behind the mouse could efficiently and precisely eliminate the pest rather than spraying pesticides on a large scale. In this case, people could effectively reduce the issues such as environmental damage and human health impacts.},
  keywords={Mechanical sensors;Spraying;Production;Pesticides;Object detection;Cameras;Mice;Bionic;Mechanical mouse;insect Recognition;Object Detection},
  doi={10.1109/ICSECE58870.2023.10263493},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10782737,
  author={Dhinagar, Nikhil J. and Thomopoulos, Sophia I. and Laltoo, Emily and Thompson, Paul M.},
  booktitle={2024 46th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)}, 
  title={Counterfactual MRI Generation with Denoising Diffusion Models for Interpretable Alzheimer’s Disease Effect Detection}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Generative AI models have recently achieved mainstream attention with the advent of powerful approaches such as SORA, DALL-E and stable diffusion. The underlying breakthrough generative mechanism of denoising diffusion modeling can generate high quality synthetic images and can learn the underlying distribution of complex, high-dimensional data. In our paper, we train conditional latent diffusion models (LDM) and denoising diffusion probabilistic models (DDPM) to provide insight into Alzheimer’s disease (AD) effects on the brain’s anatomy at the individual level. We first created diffusion models that could generate synthetic MRIs, by training them on real 3D T1-weighted MRI scans, and conditioning the generative process on the clinical diagnosis as a context variable. We conducted experiments to overcome limitations in training dataset size, compute time and memory resources by testing different models, effects of pretraining, training duration. We tested the sampling quality of the disease-conditioned diffusion using metrics to assess realism and diversity of the generated synthetic MRIs. We also evaluated the ability of diffusion models to conditionally sample MRI brains using a 3D CNN-based disease classifier relative to real MRIs. In our experiments, the diffusion models generated synthetic data that helped to train an AD classifier (using only 500 real MRI scans) - and boosted its performance by over 3% when tested on real MRI scans. Further, we used classifier-free guidance to alter the conditioning of an encoded individual scan to its counterfactual (representing a healthy subject of the same age and sex) while preserving subject-specific image details. From this counterfactual image (where the same person appears healthy), a personalized disease map was generated to identify possible disease effects on the brain. Our approach efficiently generates realistic and diverse synthetic data, and may create interpretable AI-based maps for neuroscience research and clinical diagnostic applications.},
  keywords={Training;Three-dimensional displays;Magnetic resonance imaging;Biological system modeling;Noise reduction;Training data;Diffusion models;Brain modeling;Alzheimer's disease;Synthetic data;Generative AI;denoising diffusion model;Alzheimer’s disease;MRI},
  doi={10.1109/EMBC53108.2024.10782737},
  ISSN={2694-0604},
  month={July},}@INPROCEEDINGS{10428284,
  author={Prabakaran, P and Chandra Sekhar Reddy, L. and Ravikumar, LVD and Verma, Manish Kumar},
  booktitle={2023 3rd International Conference on Advancement in Electronics & Communication Engineering (AECE)}, 
  title={Simulate the Machine Learning Algorithm to Organize the CRAHN Network System}, 
  year={2023},
  volume={},
  number={},
  pages={613-617},
  abstract={Using available channels in a wireless spectrum, cognitive radio (CR) may automatically adjust transmission settings to optimize radio operational behaviour. To function properly, a CR ad hoc network (CRAHN) has to be dynamically capable construct autonomous and decentralized networks without negatively impacting licensed main user (PU) systems. For this reason, an effective spectrum necessitates a system structure based on artificial intelligence. This research provides a model for network planning, learning, and dynamic configuration that is based on a distributed autonomous CRAHN network system that uses reinforcement learning. The proposed optimization techniques for spectrum sensing, ad hoc network design, and context-aware signal categorization are all derived from the system model and are based on machine learning. The cognitive and detection engines may be used to examine the spectrum utilization and neighbour network status in the immediate area. To adapt to the ever-changing nature of the wireless environment, the suggested policy engine may generate network operating policies, identify policy conflicts, and infer the best course of action. Together with the erudition engine, whereby apply the recommended machine-learning methods, the decision engine arrives at the best possible settings for the CRAHN. In addition, guarantee peaceful cohabitation with surrounding systems to have excellent signal context recognition ability.},
  keywords={Adaptation models;Wireless sensor networks;Machine learning algorithms;Sensors;Engines;Network systems;Narrowband;CRAHN;PU;Machine learning;Spectrum;Cognitive engine;Network design},
  doi={10.1109/AECE59614.2023.10428284},
  ISSN={},
  month={Nov},}@ARTICLE{8970510,
  author={Salcedo-Hernández, Javier and García-Barruetabeña, Jon and Pastor-López, Iker and Sanz-Urquijo, Borja},
  journal={IEEE Access}, 
  title={Predicting Enamel Layer Defects in an Automotive Paint Shop}, 
  year={2020},
  volume={8},
  number={},
  pages={22748-22757},
  abstract={The appearance of the painted surface of the vehicle is key in the quality that the automotive customer perceives. The assurance of this quality starts in the automotive paint shop and compromises the effectiveness of the painting process as every paint defect is reworked. This entails material and labour costs, reducing the efficiency of the process and affecting the competitiveness of the product. To improve the efficiency while guaranteeing the quality, predictive control rather than corrective must be implemented. In order to achieve this control, a predictive model of quality is needed. As a first step to generate said model, this article demonstrates the correlation between the variables of the enamel coating process and the quality of the paint film of the vehicle. As there are no available application examples in the industry, a procedure is proposed in which the necessary steps for the creation of an industrial data set and a predictive model of quality are defined. The procedure is tested in an automotive paint shop. As a result, relevant variables for the quality assurance are identified and the correlation between process variables and the resulting quality is verified, concluding that the implementation of predictive control in the process is feasible.},
  keywords={Paints;Automotive engineering;Painting;Predictive models;Process control;Predictive modelling;automotive industry;manufacturing digitization;industrial data set},
  doi={10.1109/ACCESS.2020.2969816},
  ISSN={2169-3536},
  month={},}@ARTICLE{10444508,
  author={Lee, Young-Suk and Choi, Jaehyeon and Je, Seung-Mo and Huh, Jun-Ho},
  journal={IEEE Access}, 
  title={A Scalable Vector Graphics Warping System for Anthropomorphizing Game Characters}, 
  year={2024},
  volume={12},
  number={},
  pages={32472-32481},
  abstract={How can scalable vector graphics (SVG) data of human faces be transformed to resemble specific animal faces? Since the early  $20^{th}$  century, multimedia featuring animals has garnered significant attention, particularly as interest in anthropomorphic animals has grown. In this paper, we survey various anthropomorphic studies. Additionally, we develop a warping system for anthropomorphizing animal characters. Our system enables the automatic generation of anthropomorphized animal characters using SVG datasets. This dataset includes frontal and side views of 60 animal species commonly featured in animations, as well as male and female human characters. Users can create new anthropomorphized animal characters using our dataset and their vector data. Our warping system implements a continuous warping technique between animal and human facial shapes in ten stages, supported by a developed algorithm and an SVG warping program. The code of the warping system and SVG dataset are available at link: https://github.com/jenero05458/SVG_warping},
  keywords={Animals;Anthropomorphism;Faces;Animation;Deformation;Scalability;Character recognition;Character generation;Video games;Portals;Teleportation;Scalable vector graphics;anthropomorphized animal character;automatic character creation;game character;warping},
  doi={10.1109/ACCESS.2024.3369185},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10263657,
  author={Tripathy, Santosh Kumar and Singh, Divya and Jaiswal, Ankit},
  booktitle={2023 International Conference on IoT, Communication and Automation Technology (ICICAT)}, 
  title={Multi-Layer Feature Fusion-based Deep Multi-layer Depth Separable Convolution Neural Network for Alzheimer's Disease Detection}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Alzheimer's disease (AD) is a severe degenerative neurological disorder that can cause heart and respiratory dysfunction. Thus, early detection of such disease is highly required. Using MRI images, a number of deep models have been created to predict AD as artificial intelligence (AI) has advanced. However, these models suffer from limited representation in extracting fine-grained features from MRI images thereby performance is declined. The proposed model overcomes such limitation and presents a methodology for AD detection by proposing a novel multi-layer feature fusion-based deep multi-layer depth-wise separable convolution neural network (CNN). The proposed model enhances the quality of features by fusing multi-layer features. These features range from representations of low-level features to features at the object level. The fused multiscale features are used for predicting AD disease. Publicly available dataset is used to validate the model's performance. With an accuracy of 95.16 percent, the suggested model performs better than the current state of the art.},
  keywords={Neurological diseases;Convolution;Magnetic resonance imaging;Predictive models;Feature extraction;Alzheimer's disease;Artificial intelligence;medical image analysis;Alzheimer's disease;deep learning},
  doi={10.1109/ICICAT57735.2023.10263657},
  ISSN={},
  month={June},}@ARTICLE{9328240,
  author={Aljanabi, Saif and Chalechale, Abdolah},
  journal={IEEE Access}, 
  title={Improving IoT Services Using a Hybrid Fog-Cloud Offloading}, 
  year={2021},
  volume={9},
  number={},
  pages={13775-13788},
  abstract={With the rapid development of the internet of things (IoT) devices and applications, the necessity to provide these devices with high processing capabilities appears to run the applications more quickly and smoothly. Though the manufacturing companies try to provide IoT devices with the best technologies, some drawbacks related to run some sophisticated applications like virtual reality and smart healthcare-based are still there. To overcome these drawbacks, a hybrid fog-cloud offloading (HFCO) is introduced, where the tasks associated with the complex applications are offloaded to the cloud servers to be executed and sent back the results to the corresponding applications. In the HFCO, when an IoT node generates a high-requirement processing task that cannot handle itself, it must decide to offload the task to the cloud server or to the nearby fog nodes. The decision depends on the conditions of the task requirements and the nearby fog nodes. Considering many fog nodes and many IoT nodes that need to offload their tasks, the problem is to select the best fog node to offload each task. In this paper, we propose a novel solution to the problem, where the IoT node has the choice to offload tasks to the best fog node or to the cloud based on the requirements of the applications and the conditions of the nearby fog nodes. In addition, fog nodes can offload tasks to each other or to the cloud to balance the load and improve the current conditions allowing the tasks to be executed more efficiently. The problem is formulated as a Markov Decision Process (MDP). Besides, a Q-learning-based algorithm is presented to solve the model and select the optimal offload policy. Numerical simulation results show that the proposed approach has superiority over other methods regarding reducing delay, executing more tasks, and balance the load.},
  keywords={Task analysis;Cloud computing;Internet of Things;Servers;Edge computing;Delays;Quality of service;Internet of Things;cloud computing;fog computing;task offloading;Q-learning},
  doi={10.1109/ACCESS.2021.3052458},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10550666,
  author={Arachchi, H.A. Dimuthu Maduranga and Samarasinghe, G. D.},
  booktitle={2024 International Research Conference on Smart Computing and Systems Engineering (SCSE)}, 
  title={Impact of Deepfake Advertising Attributes on Consumers’ Hedonic & Utilitarian Values and Brand Credibility}, 
  year={2024},
  volume={7},
  number={},
  pages={1-6},
  abstract={Creative AI technologies, like deepfakes and generative adversarial networks, are making it possible to make and edit audio and video material in advertising in new ways. These new tools make it easy to make big changes to ads and create brand related positive consequences in the mind of target consumers. From a marketing paradigm, this study focused on explaining the relationship between the deepfakes Advertising attributes and brand credibility via hedonic and utilitarian value, which is underexploited empirically in an AI driven Advertising space. Thus, in order to address this empirical knowledge void, an extensive literature review was undertaken and four hypotheses were derived to explain the potential relationships. Quantitative methodology with a survey strategy was undertaken drawing an effective sample size of 229 young undergraduate consumers of Sri Lankan public universities. Furthermore, analysis was carried out using Smart partial least squares (PLS)-structural equation modelling. The study first finds a significant direct relationship between the deepfake Advertising, hedonic value and utilitarian value. It also finds significant relationships between hedonic value, utilitarian value and brand credibility. The findings shed the light on improving Advertising and marketing effectiveness through branding applications.},
  keywords={Surveys;Deepfakes;Analytical models;Brand management;Bibliographies;Generative adversarial networks;Mathematical models;deepfakes advertising;hedonic value;utilitarian value;brand credibility},
  doi={10.1109/SCSE61872.2024.10550666},
  ISSN={2613-8662},
  month={April},}@ARTICLE{10522618,
  author={Wang, Weichen and Zhao, Cong and Wang, Zhaoyang and Mao, Baijin and Wang, Haoyu and Zhang, Yiping and Xi, Ziyue and Xiang, Cheng and Xu, Minyi and Qu, Juntian},
  journal={IEEE Sensors Journal}, 
  title={A Durable and Self-Powered Triboelectric Sensor for Hydraulic Pressure Monitoring and Underwater Disturbance Detection}, 
  year={2024},
  volume={24},
  number={12},
  pages={18928-18936},
  abstract={Enhancing marine sensory capabilities is a crucial pathway to advance human understanding of the oceans. Triboelectric nanogenerators (TENGs), known for their high-quality self-powered sensing properties, present a novel solution for underwater sensing. In this article, we introduce a new hydraulic pressure TENG (HP-TENG) structure designed specifically for HP measurements. When the external HP changes, the slider slides along the cylinder shell and the contact area between the fluorinated ethylene propylene (FEP) film and the aluminum (AI) electrodes changes, thus generating the electrical signal. The electromechanical performance characteristics of the HP-TENG are experimentally measured. Through underwater experiments, we validate the ability of HP-TENG to measure water pressure and demonstrate its ability to perceive the magnitude of pressure and the speed of pressure change with a linear correlation coefficient greater than 0.995. Furthermore, we provide insights into its applications in real-time control and underwater disturbance detection to demonstrate its utility. The sensor has the advantages of low production cost, self-powered, environmentally friendly, high sensitivity to environmental disturbances (0.954 V/N), good mechanical reliability, and electrical stability. The experimental results indicate that the proposed sensor exhibits promising potential for environmental monitoring, emphasizing its utility in enhancing ocean perception for underwater robots.},
  keywords={Sensors;Electrodes;Robot sensing systems;Aluminum;Voltage;Triboelectricity;Pressing;Hydraulic pressure (HP) monitoring;self-powered sensor;triboelectric nanogenerator (TENG);underwater disturbance detection;underwater robot},
  doi={10.1109/JSEN.2024.3395970},
  ISSN={1558-1748},
  month={June},}@INPROCEEDINGS{8953217,
  author={Zellers, Rowan and Bisk, Yonatan and Farhadi, Ali and Choi, Yejin},
  booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={From Recognition to Cognition: Visual Commonsense Reasoning}, 
  year={2019},
  volume={},
  number={},
  pages={6713-6724},
  abstract={Visual understanding goes well beyond object recognition. With one glance at an image, we can effortlessly imagine the world beyond the pixels: for instance, we can infer people's actions, goals, and mental states. While this task is easy for humans, it is tremendously difficult for today's vision systems, requiring higher-order cognition and commonsense reasoning about the world. We formalize this task as Visual Commonsense Reasoning. Given a challenging question about an image, a machine must answer correctly and then provide a rationale justifying its answer. Next, we introduce a new dataset, VCR, consisting of 290k multiple choice QA problems derived from 110k movie scenes. The key recipe for generating non-trivial and high-quality problems at scale is Adversarial Matching, a new approach to transform rich annotations into multiple choice questions with minimal bias. Experimental results show that while humans find VCR easy (over 90% accuracy), state-of-the-art vision models struggle (~45%). To move towards cognition-level understanding, we present a new reasoning engine, Recognition to Cognition Networks (R2C), that models the necessary layered inferences for grounding, contextualization, and reasoning. R2C helps narrow the gap between humans and machines (~65%); still, the challenge is far from solved, and we provide analysis that suggests avenues for future work.},
  keywords={Visualization;Grounding;Transforms;Motion pictures;Pattern recognition;Object recognition;Task analysis;Vision + Language;Recognition: Detection;Categorization;Retrieval;Scene Analysis and Understanding;Visual Reasonin},
  doi={10.1109/CVPR.2019.00688},
  ISSN={2575-7075},
  month={June},}@INPROCEEDINGS{10709823,
  author={Lin, Chen-Hao and Chang, Chia-Pao},
  booktitle={2024 4th International Symposium on AI (ISAI)}, 
  title={A Study of Introducing Real-time Object Detection Algorithm into Screen Printing Thermal Transfer Printed Label Defect Detection}, 
  year={2024},
  volume={},
  number={},
  pages={27-32},
  abstract={This research focuses on the necessity and feasibility of improving traditional optical inspection systems and using advanced object detection algorithms to detect industrial defects. Through actual inspection test results, it can successfully detect the content of PET film thermal transfer labels. Defect characteristics. The main architecture of this research includes the YOLO-V3 algorithm and the EfficientDet algorithm. Clear images obtained by planning and analyzing hardware equipment for defect accuracy and characteristics are used as functional verification. This research has achieved good research results, with the calculation accuracy reaching mAP 99% and meeting the speed requirement of real-time defect detection of 30fps (above). The introduction of the inspection system can increase the production capacity of the quality inspection department. In the past, each inspector produced an average of 3,500 labels. With the addition of the AI inspection system, the number can be increased to 5,500 labels. In addition to saving human resources, increasing production capacity can also share fatigue among inspection personnel.},
  keywords={Visualization;Accuracy;Manuals;Production;Object detection;Inspection;Real-time systems;Personnel;Artificial intelligence;Defect detection;Automatic optical inspection;deep learning;screen printing;thermal transfer labels;object detection algorithm},
  doi={10.1109/ISAI63299.2024.00015},
  ISSN={},
  month={April},}@ARTICLE{10148943,
  author={Xu, Xiaolong and Tang, Sizhe and Qi, Lianyong and Zhou, Xiaokang and Dai, Fei and Dou, Wanchun},
  journal={IEEE Communications Magazine}, 
  title={CNN Partitioning and Offloading for Vehicular Edge Networks in Web3}, 
  year={2023},
  volume={61},
  number={8},
  pages={36-42},
  abstract={Web3, an emerging blockchain-based decentralized network, grants users ownership and enhances the collaboration among devices under monitoring. Benefiting from decentralization and in-memory computing, vehicular edge networks can process tasks such as road object detection distributedly without being attacked. Recently, to provide intelligent service for Web3 users, artificial intelligence applications have been booming, thus generating enormous deep learning models. These models are supposed to be deployed in the edge due to their massive computation. Further-more, edge servers may face overload and intolerable delay for the high concurrency of offloaded deep learning tasks. How to determine an optimal offloading decision in the highly dynamic and heterogeneous edge-cloud environment is still a challenge. To tackle the mentioned challenge, a dynamic offloading strategy based on game theory combined with convolutional neural network (CNN) partition for vehicular edge networks, named GPOV, is proposed. Specifically, CNN partition can utilize resources more efficiently and reduce the delay with parallelism. The game theoretic offloading decision strategy can determine the optimal offloading policy according to the real-time environment. The performance of our strategy is validated in the final part of this article.},
  keywords={Computational modeling;Task analysis;Quality of service;Delays;Vehicle dynamics;Common Information Model (computing);Program processors;Semantic Web;Blockchains;Vehicular ad hoc networks},
  doi={10.1109/MCOM.002.2200424},
  ISSN={1558-1896},
  month={August},}@INPROCEEDINGS{10464469,
  author={Kumar, Suraj and Singh, Narendra Pratap and Brahma, Banalaxmi},
  booktitle={2023 IEEE International Conference on Computer Vision and Machine Intelligence (CVMI)}, 
  title={AI-Based Model for Detection and Classification of Alzheimer Disease}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Millions of people worldwide suffer from by the deadly brain disorder known as Alzheimer's Disease (AD). Alzheimer's disease is an incurable neurological disorder that affects brain function. To improve patient quality of life and create efficient treatment options, early AD diagnosis is essential. In this research, we have proposed a novel method for AD detection using Convolutional Neural Networks (CNNs) using Magnetic Resonance Imaging (MRI) datasets. We use a pre-trained CNN model to extract features from brain MRI images and classify them into Alzheimer's or non-Alzheimer's groups. We compare the efficiency of our model with several classifiers, such as: SoftMax, Support Vector Machine (SVM), DNN, and some other classifiers. We evaluated our model on an MRI dataset. We achieve high accuracy on the MRI dataset: 99.56% on the training set and 99% on the validation set. The loss values of training and validation are 0.0146% and 0.153% respectively. Our method is fast, robust, and generalizable. We point out that CNN-based models can be a powerful tool for AD detection using MRI data.},
  keywords={Training;Support vector machines;Neurological diseases;Magnetic resonance imaging;Computational modeling;Brain modeling;Feature extraction;CNN;Alzheimer's;MRI},
  doi={10.1109/CVMI59935.2023.10464469},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10469161,
  author={Bhargava, Medhavi and Chaturvedi, Anoop},
  booktitle={2024 Fourth International Conference on Advances in Electrical, Computing, Communication and Sustainable Technologies (ICAECT)}, 
  title={Energy and Signal Strength based Reliable Route Prediction by Fuzzy Rules in MANET (ESRP)}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={A Mobile Ad hoc Network is a network that does not have a permanent infrastructure is known as a mobile ad hoc network, or MANET. This is a temporary network that does not require a central management or the typical support equipment that is present in standard networks. It is possible to establish networks in any location, which will ensure the life of MANET. The bandwidth and energy or power nodes are limited and due to congestion suffer from high packet loss, buffer overflow and congested links which are created a problem in routing. Delays in the delivery of packets are a consequence of proper routing, which also has an impact on the MANET protocol's rate of packet delivery. In the realm of artificial intelligence (AI), machine learning (ML) is a subfield that has the potential to enhance the routing performance by select nodes have high signal strength in networks. In this paper, proposed a energy and signal strength based reliable route fuzzy based scheme (ESRP) scheme to estimate the signal strength and bandwidth. ESRP is the controlled the congestion in a network is balanced the load and reduces energy consumption. This approach is optimizing network consumption, reduce packet latency, and improve packet distribution ratio. All of these benefits can be achieved simultaneously. The overall efficiency of the network can be improved by moving loads from paths that are overloaded to paths that are less congested. MANET routing protocols provide preference to paths that have fewer hops and do not allow paths with more hops to pass through. However, when the load is extremely high, they give preference to paths that have fewer hops. The performance of ESRP is compared with AODV, OLSR DSR and EAPS. The performance metrics shows that the performance of EAPS is remarkable as compare to existing routing scheme.},
  keywords={Energy consumption;Packet loss;Bandwidth;Machine learning;Routing;Routing protocols;Delays;Congestion;Energy;ML;Multipath;Load balancing;MANET;Single Strength;Routing},
  doi={10.1109/ICAECT60202.2024.10469161},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{9884798,
  author={Guo, Yu-Shi and Li, Heng-Chao and Hu, Wen-Shuai and Wang, Wei-Ye},
  booktitle={IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium}, 
  title={SAR Image Data Augmentation via Residual and Attention-Based Generative Adversarial Network for Ship Detection}, 
  year={2022},
  volume={},
  number={},
  pages={439-442},
  abstract={In recent years, generative adversarial networks (GANs) have been successfully applied to generate the SAR images. However, due to the fact that it is more difficult to generate the images than to distinguish the real or fake, GANs usually suffer from the problems of unstable training and mode collapse. As such, a residual and attention-based generative adversarial network (RAGAN) is proposed for SAR data augmentation. Firstly, the directional bounding box is used as a constraint in the RAGAN to limit the position of ship in the generated SAR image, which can be further set as the annotation of the SAR image for ship detection directly. After that, inspired by the residual and attention learning, a residual and attention block (RABlock) and a transposed RABlock (TRABlock) are designed to improve the generator of the RAGAN, thus preventing the whole model from gradient vanishing and suppressing the effects of speckle noise and background to enhance the quality of the generated SAR images. Experimental results on the HRSID data set demonstrate the effectiveness of our RAGAN model in SAR data augmentation for ship detection.},
  keywords={Training;Annotations;Speckle;Generative adversarial networks;Radar polarimetry;Generators;Data models;Synthetic aperture radar;generative ad-versarial networks;residual learning;attention mechanism;data augmentation;target detection},
  doi={10.1109/IGARSS46834.2022.9884798},
  ISSN={2153-7003},
  month={July},}@INPROCEEDINGS{10800594,
  author={Chang, Chen-Chi and Chen, Ching-Yuan and Lee, Hung-Shin and Lee, Chih-Cheng},
  booktitle={2024 27th Conference of the Oriental COCOSDA International Committee for the Co-ordination and Standardisation of Speech Databases and Assessment Techniques (O-COCOSDA)}, 
  title={Benchmarking Cognitive Domains for LLMS: Insights from Taiwanese Hakka Culture}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This study introduces a comprehensive benchmark designed to evaluate the performance of large language models (LLMs) in understanding and processing cultural knowledge, with a specific focus on Hakka culture as a case study. Leveraging Bloom's Taxonomy, the study develops a multi-dimensional framework that systematically assesses LLMs across six cog-nitive domains: Remembering, Understanding, Applying, Analyzing, Evaluating, and Creating. This benchmark ex-tends beyond traditional single-dimensional evaluations by providing a deeper analysis of LLMs' abilities to handle cul-turally specific content, ranging from basic recall of facts to higher-order cognitive tasks such as creative synthesis. Ad-ditionally, the study integrates Retrieval-Augmented Generation (RAG) technology to address the challenges of minority cultural knowledge representation in LLMs, demonstrating how RAG enhances the models' performance by dynamically incorporating relevant external information. The results high-light the effectiveness of RAG in improving accuracy across all cognitive domains, particularly in tasks requiring precise retrieval and application of cultural know ledge. However, the findings also reveal the limitations of RAG in creative tasks, underscoring the need for further optimization. This benchmark provides a robust tool for evaluating and com-paring LLMs in culturally diverse contexts, offering valuable insights for future research and development in AI -driven cultural knowledge preservation and dissemination.},
  keywords={Databases;Large language models;Taxonomy;Retrieval augmented generation;Knowledge representation;Benchmark testing;Distance measurement;Cultural differences;Research and development;Optimization;Taiwanese Hakka;large language model;LLM;retrieval-augmented generation;RAG},
  doi={10.1109/O-COCOSDA64382.2024.10800594},
  ISSN={2472-7695},
  month={Oct},}@INPROCEEDINGS{9828764,
  author={Saiz, Eduardo and Troiano, Karen and Einarsson, Torbjörn and Curiel, Pablo},
  booktitle={2022 IEEE International Symposium on Broadband Multimedia Systems and Broadcasting (BMSB)}, 
  title={VOD2Live: Exploring the technical challenges in the adaptive generation of linear FAST channels from existing on-demand and live content and personalised ad selection}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={With the streaming services consumption on the rise, Free Ad-Supported TV (FAST) channels are becoming one of the most demanded services with benefits for all stakeholders: Content providers and advertisers have in FAST channels the opportunity to develop new business models while viewers benefit from the access to high-quality contents for free. Despite this not being a new concept, as ad-supported streaming technology has been in the market for a while now, there are still some issues that must be tackled when trying to evolve this market to the next level. VOD2Live, the novel service platform by AgileContent, is aimed at content providers for the quick and cost-effective generation of linear FAST channels from both live streams and on-demand assets. The solution is cost-effective by creating dynamic linear channels without the need for live transcoding, and instead stitching segments by combining video GoPs and corresponding audio frame intervals. VOD2Live offers features such as adaptive selection of geographically disperse assets in the cloud, the smart addition, repetition and/or substitution of contents on the fly on FAST channels already deployed, or even the dynamic relocation of ad-slots in the planned rundown. This paper aims to present and further explore the overall technical challenges of the platform.},
  keywords={Video coding;TV;Costs;Transcoding;Streaming media;Media;Complexity theory;FAST;video streaming;MPEG-DASH;HLS;Scalable video coding and content adaptation;Audio-video coding and processing;AI in media processing},
  doi={10.1109/BMSB55706.2022.9828764},
  ISSN={2155-5052},
  month={June},}@INPROCEEDINGS{10730751,
  author={Zakaria, Muhammad Lutfi and Wibowo, Suryo Adhi and Kurniawan, Isman},
  booktitle={2024 8th International Conference on Information Technology, Information Systems and Electrical Engineering (ICITISEE)}, 
  title={Implementation of Temporal Fusion Transformer Optimized by Grey Wolf Optimizer In Predicting Rice Price In Bandung Regency}, 
  year={2024},
  volume={},
  number={},
  pages={127-132},
  abstract={The price of rice has a significant impact on the welfare of farmers. The sudden fluctuations in rice prices can significantly impact farmers' decisions regarding the optimal strategy for selling their rice. It is challenging for farmers to accurately predict the price of rice due to the specialized knowledge required to do so. The predominant approach to predicting rice prices is statistical science, which necessitates the involvement of highly skilled experts, extensive preparation periods, and substantial financial resources. Consequently, there is a need for an alternative method to predict rice prices. In recent years, machine learning and deep learning have been widely used to predict rice prices. In this study, we build a rice price prediction model in Bandung Regency using the deep learning method Temporal Fusion Transformer - Grey Wolf Optimizer. The results of the validation process indicate that the Temporal Fusion - Grey Wolf Optimizer model produces the highest Pearson Correlation (CC) value of 0.921 in predicting rice prices in the next five days.},
  keywords={Deep learning;Electrical engineering;Fluctuations;Correlation;Predictive models;Transformers;Prediction algorithms;Thin film transistors;Information technology;Information systems;Rice Price;Machine Learning;Deep Learning;Temporal Fusion Transformer;Grey Wolf Optimizer},
  doi={10.1109/ICITISEE63424.2024.10730751},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10377969,
  author={Pan, Wei and Zhu, Anna and Zhou, Xinyu and Iwana, Brian Kenji and Li, Shilin},
  booktitle={2023 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={Few shot font generation via transferring similarity guided global style and quantization local style}, 
  year={2023},
  volume={},
  number={},
  pages={19449-19459},
  abstract={Automatic few-shot font generation (AFFG), aiming at generating new fonts with only a few glyph references, reduces the labor cost of manually designing fonts. However, the traditional AFFG paradigm of style-content disentanglement cannot capture the diverse local details of different fonts. So, many component-based approaches are proposed to tackle this problem. The issue with component-based approaches is that they usually require special pre-defined glyph components, e.g., strokes and radicals, which is infeasible for AFFG of different languages. In this paper, we present a novel font generation approach by aggregating styles from character similarity-guided global features and stylized component-level representations. We calculate the similarity scores of the target character and the referenced samples by measuring the distance along the corresponding channels from the content features, and assigning them as the weights for aggregating the global style features. To better capture the local styles, a cross-attention-based style transfer module is adopted to transfer the styles of reference glyphs to the components, where the components are self-learned discrete latent codes through vector quantization without manual definition. With these designs, our AFFG method could obtain a complete set of component-level style representations, and also control the global glyph characteristics. The experimental results reflect the effectiveness and generalization of the proposed method on different linguistic scripts, and also show its superiority when compared with other state-of-the-art methods. The source code can be found at https://github.com/awei669/VQ-Font.},
  keywords={Weight measurement;Computer vision;Costs;Codes;Vector quantization;Source coding;Design methodology},
  doi={10.1109/ICCV51070.2023.01787},
  ISSN={2380-7504},
  month={Oct},}@INPROCEEDINGS{10722189,
  author={Joshi, Kapil and Sidhu, Kawerinder Singh and Malik, Neeru and Jadhav, Archana and Saini, Dilipkumar Jang Bahadur and Siddharth, Dhirendra},
  booktitle={2024 5th International Conference on Smart Electronics and Communication (ICOSEC)}, 
  title={Innovative Real Estate Management System: Artificial Intelligence-based Segregation}, 
  year={2024},
  volume={},
  number={},
  pages={1973-1977},
  abstract={Information technology has grown very fast and has led to a lot of changes in the property industry, thus demanding businesses to enhance their operational standards. This research study analyses how an advanced Real Estate Management System is designed and executed; this includes creating useful functions for working with data (CRUD operations), and better security measures among others like complex information visualization frameworks. The MERN stack is used here where innovative technologies are employed such as MongoDB as the database system; Express.js which is a web application framework running on Node.js; React that allows building user interfaces and finally Node.js itself being used for server-side scripting enabling asynchronous event-driven I/O. It offers a flexible and responsive structure that can handle huge sets of data common with real estate transactions during different stages. Apart from that, the system has a very broad user authentication method that adheres to the best practices used in the industry for ensuring data integrity and confidentiality. The system also comes with extensive data visualization capabilities by leveraging charting libraries like D3.js and Chart.js which allow quick viewing of property information, financials as well as market analysis by clients and administrators alike. In impact, the whole thing works as a planning tool, allowing professionals in the property sector to the productivity, safety, and definition of vision necessary to make accurate choices in a rapidly evolving digital context.},
  keywords={Productivity;Industries;Scalability;Buildings;Data visualization;Software;Safety;Planning;Security;Standards;Real State;React;Property management;Visual insights;Security;MERN Stack;MongoDB;Visualization tools;Authentication flow},
  doi={10.1109/ICOSEC61587.2024.10722189},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10605550,
  author={Köksal, Ali and Xu, Qianli and Lim, Joo-Hwee},
  booktitle={2024 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={Talking Face Generation via Face Mesh - Controllability without Reference Videos}, 
  year={2024},
  volume={},
  number={},
  pages={1380-1386},
  abstract={Recent development in audio-driven talking face generation strives for controlling facial features including facial expression, head pose, eye blink, etc. as well as accurate lip-synchronization and the ability to apply to arbitrary subjects. Existing audio-visual models that can control facial features require encoders that encode driving videos, which is both computationally expensive and limited by the availability of such driving videos. In this paper, we address this limitation and aim to control facial features without encoding driving videos. We propose a cascaded GAN-based audio-visual model, which incorporates face mesh as an intermediate representation. Different from existing cascaded methods that use facial landmarks, our method uses face mesh as a medium of informative facial feature representation. To the best of our knowledge, this is the first cascaded model that allows controllable talking face generation via face mesh. We train our audio-visual model with training samples of MEAD dataset. In the evaluation, we benchmark our model in extensive experiments on MEAD and LRW datasets. The results show our model outperforms existing ones by generating high-fidelity audio-driven talking faces on arbitrary subjects with realistic emotional expression patterns.},
  keywords={Training;Computational modeling;Avatars;Benchmark testing;Controllability;Encoding;Forgery;talking face generation;facial animation;controllable generation},
  doi={10.1109/CAI59869.2024.00246},
  ISSN={},
  month={June},}@INPROCEEDINGS{10541758,
  author={Singh, J.N. and Gautam, Ashutosh and Tomar, Harsh},
  booktitle={2023 5th International Conference on Advances in Computing, Communication Control and Networking (ICAC3N)}, 
  title={Deep Fake in picture using Convolutional Neural Network}, 
  year={2023},
  volume={},
  number={},
  pages={1104-1107},
  abstract={Deepfake is a system that combines fake pictures and videos with deep learning. Deep learning is the source of Deepfake. The unethical practice of creating falsified photographs and movies is now possible because of neoteric advances in the fields of Artificial Intelligence and Machine Learning. Today, it is very easy to create photo simulative images using generative adversarial networks. These fake images and videos are widely available on the internet and social media. It is difficult to tell which of them is real or not. These images are typically taken with the goal of stirring up social disturbance, political turmoil, or distributing false information among the general public. Viewers will easily comprehend these images because they will look to be real. Deepfake is rapidly harming individuals, communities, companies, security, religion, and democracy, according to recent studies. These videos and photographs are of astounding quality, and they have a huge social media reach. It has far-reaching effects that are destructive beyond comprehension. An extensive overview of the different deep-fake methods is provided in this publication. So, the objective of this paper is to identify these fake images using a conventional neural network. In order to address this issue, we train a model for particular datasets, produce deep fakes, and then use that model to try to identify the deep fake. An authentic and false image is required for the training process in order to train the model.},
  keywords={Deep learning;Training;Deepfakes;Social networking (online);Pipelines;Neural networks;Motion pictures;CNN;Image Detection;RNN},
  doi={10.1109/ICAC3N60023.2023.10541758},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10656690,
  author={Kapon, Roy and Tevet, Guy and Cohen-Or, Daniel and Bermano, Amit H.},
  booktitle={2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={MAS: Multi-view Ancestral Sampling for 3D Motion Generation Using 2D Diffusion}, 
  year={2024},
  volume={},
  number={},
  pages={1965-1974},
  abstract={We introduce Multi-view Ancestral Sampling (MAS), a method for 3D motion generation, using 2D diffusion models that were trained on motions obtained from in-the-wild videos. As such, MAS opens opportunities to exciting and diverse fields of motion previously under-explored as 3D data is scarce and hard to collect. MAS works by simultaneously denoising multiple 2D motion sequences representing different views of the same 3D motion. It ensures consistency across all views at each diffusion step by combining the individual generations into a unified 3D sequence, and projecting it back to the original views. We demonstrate MAS on 2D pose data acquired from videos depicting professional basketball maneuvers, rhythmic gymnastic performances featuring a ball apparatus, and horse races. In each of these domains, 3D motion capture is arduous, and yet, MAS generates diverse and realistic 3D sequences. Unlike the Score Distillation approach, which optimizes each sample by repeatedly applying small fixes, our method uses a sampling process that was constructed for the diffusion framework. As we demonstrate, MAS avoids common issues such as out-of-domain sampling and mode-collapse. https://guytevet.github.io/mas-page/},
  keywords={Computer vision;Three-dimensional displays;Tracking;Face recognition;Noise reduction;Pipelines;Data acquisition;Motion;Motion generation;Generative models;Gen AI;Motion synthesis;Animation;Human motion},
  doi={10.1109/CVPR52733.2024.00192},
  ISSN={2575-7075},
  month={June},}@ARTICLE{10591977,
  author={Novak, Erik and Bizjak, Luka and Mladenić, Dunja and Grobelnik, Marko},
  journal={IEEE Access}, 
  title={Evaluating Text Generation Model Performance by Combining Semantic Meaning and Word Order}, 
  year={2024},
  volume={12},
  number={},
  pages={95265-95277},
  abstract={Modern text generation metrics use semantic representations of words to assess the quality of a text generation model without considering the fluency of the generated text. This paper proposes a novel text generation metric that combines adequacy and fluency to measure the quality of the generated text. When computing the final score using optimal transport, the metric considers semantic meaning and word order. We evaluate the metric on text translation data sets consisting of 20 language pairs from various language families and scripts. Using a novel statistic for measuring word order sensitivity, we analyze its adequacy-based performance using Pearson’s r and Kendall’s  $\tau $  correlation coefficients and their sensitivity to fluency-related modifications. Results show that the proposed metric is the most sensitive to fluency-related changes among all top-performing embedding-based metrics, which were found to be relatively invariant to variations in word order. The proposed metric’s overall adequacy-based performance is lower than the best embedding-based metric but higher than the n-gram matching metrics. Our code is publicly available on GitHub (https://github.com/eriknovak/metric-OPWScore) under the BSD-2-Clause license.},
  keywords={Measurement;Semantics;Task analysis;Sensitivity;Deep learning;Machine learning;Natural language processing;Performance evaluation;Text processing;Text detection;Software development management;Computational modeling;Deep learning;machine learning;machine translation;natural language processing;performance evaluation},
  doi={10.1109/ACCESS.2024.3426082},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10660009,
  author={Deng, Junyan},
  booktitle={2024 2nd International Conference on Mechatronics, IoT and Industrial Informatics (ICMIII)}, 
  title={Research on AI-Driven Virtual Character Modeling Technology through UV Seagull Algorithm}, 
  year={2024},
  volume={},
  number={},
  pages={249-254},
  abstract={In the era of AI-driven virtual character modeling technology, UV Seagull Algorithm (UVSA), as an innovative integrated technology solution, creatively integrates UV mapping and reverse UV mapping with Seagull optimization algorithm to effectively solve the problem of fidelity and efficiency of virtual character construction in the meta-universe environment. In the core of 3D modeling, although the UV mapping process is indispensable, it is often accompanied by bad effects such as texture distortion and distortion, which limits the real visual experience of virtual characters. For this reason, UVSA has a unique approach, using the seagull optimization algorithm derived from the natural seagull cluster foraging behavior principle, which has a strong global search ability and flexible processing of complex problems. In the practical application of UVSA, the 3D model is initially expanded to the 2D plane through the standard UV mapping to form the UV coordinate layout, and then the seagull optimization algorithm is used to deeply optimize it, targeted to eliminate texture distortion and optimize texture distribution, in order to pursue the most ideal UV layout scheme. After optimization, UVSA uses reverse UV mapping technology to accurately restore the optimized texture map to the surface of the 3D model, making the virtual character present unprecedented highly realistic texture details and clear and delicate appearance texture. Thanks to this, UVSA not only greatly improves the visual authenticity and viewing quality of virtual characters in the meta-universe environment, but also greatly improves the overall efficiency of modeling and rendering, and opens up a new technical path for many industries, including virtual reality, game development, film and television production, and virtual social communication. It can be said that the emergence of UVSA is not only a major breakthrough in existing modeling technology, but also provides a strong and practical technical support and innovative ideas for the development of virtual character creation in the future meta-universe, creating a solid technical cornerstone for the construction of high-precision virtual characters in the meta-universe era, and effectively promotes the continuous innovation and development of related industries. It also opens the door to more possibilities.},
  keywords={Solid modeling;Technological innovation;Three-dimensional displays;TV;Heuristic algorithms;Computational modeling;Layout;AI drive;seagull optimization algorithm;virtual characters},
  doi={10.1109/ICMIII62623.2024.00052},
  ISSN={},
  month={June},}@ARTICLE{9311211,
  author={Kurisaki, Kazuma and Kawamoto, Kazuhiko},
  journal={IEEE Access}, 
  title={Animating Cloud Images With Flow Style Transfer}, 
  year={2021},
  volume={9},
  number={},
  pages={3269-3277},
  abstract={We propose a method for animating static images using a generative adversarial network (GAN). Given a source image depicting a cloud image and a driving video sequence depicting a moving cloud image, our framework generates a video in which the source image is animated according to the driving sequence. By inputting the source image and optical flow of the driving video into the generator, a video is generated that is conditioned by the optical flow. The optical flow enables the application of the captured motion of clouds in the source image. Further, we experimentally show that the proposed method is more effective than the existing methods for animating a keypoint-less video (in which the keypoints cannot be explicitly determined) such as a moving cloud image. Furthermore, we show an improvement in the quality of the generated video due to the use of optical flow in the video reconstruction.},
  keywords={Optical imaging;Generators;Gallium nitride;Training;Animation;Image color analysis;Generative adversarial networks;Image animation;video generation;generative adversarial networks;optical flow},
  doi={10.1109/ACCESS.2020.3048160},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10141186,
  author={M, Venkatraman and R, Surendran},
  booktitle={2023 2nd International Conference on Applied Artificial Intelligence and Computing (ICAAIC)}, 
  title={Design and Implementation of Smart Hydroponics Farming for Growing Lettuce Plantation under Nutrient Film Technology}, 
  year={2023},
  volume={},
  number={},
  pages={1514-1521},
  abstract={Smart hydroponics farming is a modern technique for growing plants in nutrient-rich water rather than soil. The Nutrient Film Technology is a hydroponic system that circulates a thin film of nutrient-rich water over the roots of the plants, allowing for optional nutrient and oxygen absorption. The lettuce varieties that can thrive under NFT and are suitable for hydroponic cultivation. Automation robotics and IoT have enabled farmers to monitor all variations in the plant, root zone, and environment using smart hydroponics. The findings of this study are presented in the design of real-time operating systems based on microcontrollers. Robotics in hydroponic systems, additional technologies in hydroponic systems, and automated drip irrigation in conjunction with hydroponic systems; expert system-based automation system; automated Smart hydroponics nutrition plants system; smart hydroponic management and monitoring system for an intelligent smart hydroponic system using internet of things and web technology; deep neural network-based fault detection in hydroponics lettuce plantation being g hydroponic smart lettuce is a promising technology for producing high-quality, sustainable lettuce in cities and other areas where traditional agriculture is difficult or impractical. The obtains simulation result on could base Environment with IoT disclose superior performance.},
  keywords={Deep learning;Cloud computing;Automation;Neural networks;Hydroponics;Predictive models;Robot sensing systems;IoT sensor;real-time data acquisition;automated farming;smart spinach farming microcontroller;neural network robotics deep neural Network;Long Short Term Memory},
  doi={10.1109/ICAAIC56838.2023.10141186},
  ISSN={},
  month={May},}@INPROCEEDINGS{9589847,
  author={He, Junyi and Ma, Qian and Zhang, Meng and Huang, Jianwei},
  booktitle={2021 19th International Symposium on Modeling and Optimization in Mobile, Ad hoc, and Wireless Networks (WiOpt)}, 
  title={Optimal Fresh Data Sampling and Trading}, 
  year={2021},
  volume={},
  number={},
  pages={1-8},
  abstract={Data freshness, measured by Age of information (AoI), is becoming an increasingly significant metric for data valuation. However, most existing data trading markets ignore the impact of such a metric. In this paper, we study a fresh data market, where users with heterogeneous valuations for AoI stochastically arrive over time. The platform decides data sampling (which affects the AoI) and pricing policies (to the users), to maximize its profit. We consider three types of pricing policies with increasing flexibility, i.e., a uniform pricing policy, a dual pricing policy, and a dynamic pricing policy. The joint data sampling and pricing optimization is a non-smooth mixed integer programming problem, which is challenging to solve. Despite the difficulty, we derive the closed-form solutions of the optimal data sampling policies and pricing policies for all three cases. Our analysis yields several interesting practical insights. First, the optimal data prices decrease in the unit sampling cost and increase in the users’ arrival rate. Second, for all three pricing policies, the equal-spacing data sampling policy is optimal. Third, numerical results show that the optimal dual pricing policy significantly outperforms the optimal uniform pricing policy. Specifically, the optimal dual pricing policy produces up to 280% of the profit that is achieved by the optimal uniform pricing policy.},
  keywords={Measurement;Integer programming;Costs;Law enforcement;Wireless networks;Pricing;Information age;Fresh data market;age of information;data sampling and pricing},
  doi={10.23919/WiOpt52861.2021.9589847},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9397196,
  author={Negi, Alok and Kumar, Krishan and Chauhan, Prachi and Rajput, R.S.},
  booktitle={2021 International Conference on Computing, Communication, and Intelligent Systems (ICCCIS)}, 
  title={Deep Neural Architecture for Face mask Detection on Simulated Masked Face Dataset against Covid-19 Pandemic}, 
  year={2021},
  volume={},
  number={},
  pages={595-600},
  abstract={The dangerous COVID-19 (SARS-CoV-2) is rising steadily and globally, with more than 72,851,747 confirmed cases observed to WHO including 1,643,339 deaths till 17 December 2020. The country’s economy is now almost fully halted, people are stuck up and investment becomes deteriorating. So, this is turning to worry of the government for a development and health. Health organizations are often desperate for evolving decision-making innovations to overcome this viral virus and encourage people to receive rapid and effective responses in real-time. Thus, it is important to create auto-mechanisms as a preventive shield to ensure healthy humanity against SARS-CoV-2. Advanced analytics methods and other strategies could also empower researchers, learners and the pharmaceutical industry to acknowledge the hazardous COVID-19 and speed it up care procedures by efficiently testing vast volumes of research data. The prevention method consequence is being used to effectively manage, calculate, forecast and monitor current infected people and future potential cases. Therefore, we proposed CNN and VGG16 based deep learning models to incorporate and enforce AI-based precautionary measures to detect the face mask on Simulated Masked Face Dataset (SMFD). This technique is capable of recognizing masked and unmasked faces to help monitor safety breaches, facilitate the use of face masks, and maintain a secure working atmosphere.},
  keywords={COVID-19;Pandemics;Face recognition;Biological system modeling;Atmospheric modeling;Monitoring;Testing;CNN;Deep Learning;Data Augmentation;Face Mask Detection;Simulated Masked Face Dataset (SMFD);VGG 16;WHO},
  doi={10.1109/ICCCIS51004.2021.9397196},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{9212240,
  author={Subetha, T and Khilar, Rashmita and Sahoo, Sarat Kumar},
  booktitle={2020 International Conference on Computational Intelligence for Smart Power System and Sustainable Energy (CISPSSE)}, 
  title={An Early Prediction and Detection of Alzheimer's Disease: A Comparative Analysis on Various Assistive Technologies}, 
  year={2020},
  volume={},
  number={},
  pages={1-5},
  abstract={Alzheimer's disease (AD) is a leading form of Dementia which has recently gained a large attention in neuroimaging techniques. The symptoms are very slow and it affects the daily routine of a human being. AD is not an old age disease; it also affects people of different age. The early stage of the disease is a mild memory loss followed by degradation in the conversation and communication of a patient. The current treatments have no solution to stop the disease but early diagnosis will reduce the severity of the disease and help the patients to live a quality life. Research says that the count of individuals affected with AD will duple in next 20 upcoming years. In this paper, a systematic review on Dementia leading to Alzheimer's disease is performed using various approaches for diagnosis of AD. Various analysis and evaluation techniques performed on recent work for the early detection of AD using various approaches of machine learning, IOT, Artificial Intelligence, etc is also reviewed. This paper also discusses about the future research directions and challenges in handling Alzheimer's data. Though, the analysis on techniques produces a promising prediction, the evaluations are done only for a variety of pathologically unproven data sets. Different imaging modalities are also applied which cannot be evaluated to make a fair comparison among them.},
  keywords={Neuroimaging;Systematics;Wearable computers;Imaging;Machine learning;Assistive technologies;Power systems;Alzheimer's disease (AD);Dementia;Machine Learning;IOT;Neuroimaging techniques},
  doi={10.1109/CISPSSE49931.2020.9212240},
  ISSN={},
  month={July},}@INPROCEEDINGS{10882512,
  author={Jain, Muskan and Sharma, Ranjana},
  booktitle={2024 13th International Conference on System Modeling & Advancement in Research Trends (SMART)}, 
  title={Comparative Analysis Yolov5 and Yolov8 for Vehicle Classification}, 
  year={2024},
  volume={},
  number={},
  pages={728-734},
  abstract={The research describes a system it use adaptive background reduction and object tracking to count vehicles on the highways and roads. Background subtraction that adapts, picture vehicle counting, segmentation, and vehicle tracking are its four primary phases of operation. Video streams from stationary cameras placed on roads and highways are used. This system's precise vehicle tracking and counting is meant to improve traffic surveillance. Its capacity to efficiently count automobiles and produce extremely accurate findings are among its key qualities. The study analyses traffic recordings for vehicle detection, classification, and counting using sort algorithms based on artificial intelligence. Vehicles in three classes-cars, trucks, buses-were identified and categorised with an average accuracy of using YOLOv5 and YOLOv8, a deep learning technique. After detection, the number of passing vehicles was counted using the SORT algorithm, which yielded an average accuracy rate of 95%. Based on the experimental results, it is possible to successfully recognise, classify, and count vehicles in flowing traffic films by utilising the YOLOv5 and YOLOv8 to SORT algorithms.},
  keywords={YOLO;Deep learning;Accuracy;Roads;Surveillance;Traffic control;Streaming media;Classification algorithms;Automobiles;Streams;Vehicle Classification;Accuracy;Vehicle Count;SORT;Yolov5;Yolov8},
  doi={10.1109/SMART63812.2024.10882512},
  ISSN={2767-7362},
  month={Dec},}@INPROCEEDINGS{10702094,
  author={Zambrano, Jorge Luis Veloz and Cedeño, Andrea Katherine Alcívar and Escobar, Jean Carlos Palma and Mera, Ader Frederich Suárez},
  booktitle={2024 Tenth International Conference on eDemocracy & eGovernment (ICEDEG)}, 
  title={Immersive Virtual Reality for the Preservation of Cultural Heritage}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This document focuses on designing, developing and implementing an immersive scenario based on the Hojas Jaboncillo Museum in the parish of Portoviejo - Ecuador. The main objective is to create a virtual gallery using technologies to improve the user experience in immersive environments. During the research, various technologies associated with the metaverse were explored, which led to the identification of 3D modelling tools to shape virtual environments and tools to create animations and interactions between objects. The importance of hardware was highlighted to take advantage of the features of virtual reality. The study addresses the resolution of practical problems in cultural preservation and the improvement of the visitor experience, this is carried out through quantitative, applied and experimental research, using descriptive analysis of the data. Additionally, strategies were considered to incorporate non-visual elements, such as sounds, to increase realism and user immersion. These elements were applied to create a virtual gallery with realistic objects and models to improve the visitor experience. In summary, by implementing virtual reality technologies, 3D modelling and artificial intelligence, it was possible to develop a virtual environment that offers an immersive and accessible experience, regardless of the user’s location.},
  keywords={Solid modeling;Visualization;Three-dimensional displays;Shape;Education;User interfaces;User experience;Cultural differences;Object recognition;Artificial intelligence;virtual reality;immersive;3D modeling;interactive;museum},
  doi={10.1109/ICEDEG61611.2024.10702094},
  ISSN={2573-1998},
  month={June},}@ARTICLE{10918862,
  author={Qu, Jing and Bu, Lingguo and Chen, Zhongxin and Jin, Yalu and Zhao, Lei and Zhu, Shantong and Guo, Fenghe},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={ArmVR: Innovative Design Combining Virtual Reality Technology and Mechanical Equipment in Stroke Rehabilitation Therapy}, 
  year={2025},
  volume={31},
  number={5},
  pages={2288-2298},
  abstract={The rising incidence of stroke has created a significant global public health challenge. The immersive qualities of virtual reality (VR) technology, along with its distinct advantages, make it a promising tool for stroke rehabilitation. To address this challenge, developing VR-based upper limb rehabilitation systems has become a critical research focus. This study developed and evaluated an innovative ArmVR system that combines VR technology with rehabilitation hardware to improve recovery outcomes for stroke patients. Through comprehensive assessments, including neurofeedback, pressure feedback, and subjective feedback, the results suggest that VR technology has the potential to positively support the recovery of cognitive and motor functions. Different VR environments affect rehabilitation outcomes: forest scenarios aid emotional relaxation, while city scenarios better activate motor centers in stroke patients. The study also identified variations in responses among different user groups. Normal users showed significant changes in cognitive function, whereas stroke patients primarily experienced motor function recovery. These findings suggest that VR-integrated rehabilitation systems possess great potential, and personalized design can further enhance recovery outcomes, meet diverse patient needs, and ultimately improve quality of life.},
  keywords={Training;Stroke (medical condition);Limbs;Hardware;Medical treatment;Functional near-infrared spectroscopy;Three-dimensional printing;Couplings;Servomotors;Pressure sensors;Virtual Reality;Mechanical Device;fNIRS;Stroke;Immersive Applications;Gamified Therapy},
  doi={10.1109/TVCG.2025.3549561},
  ISSN={1941-0506},
  month={May},}@ARTICLE{10107764,
  author={Mittal, Mayank and Yu, Calvin and Yu, Qinxi and Liu, Jingzhou and Rudin, Nikita and Hoeller, David and Yuan, Jia Lin and Singh, Ritvik and Guo, Yunrong and Mazhar, Hammad and Mandlekar, Ajay and Babich, Buck and State, Gavriel and Hutter, Marco and Garg, Animesh},
  journal={IEEE Robotics and Automation Letters}, 
  title={Orbit: A Unified Simulation Framework for Interactive Robot Learning Environments}, 
  year={2023},
  volume={8},
  number={6},
  pages={3740-3747},
  abstract={We present Orbit, a unified and modular framework for robot learning powered by Nvidia Isaac Sim. It offers a modular design to easily and efficiently create robotic environments with photo-realistic scenes and high-fidelity rigid and deformable body simulation. With Orbit, we provide a suite of benchmark tasks of varying difficulty– from single-stage cabinet opening and cloth folding to multi-stage tasks such as room reorganization. To support working with diverse observations and action spaces, we include fixed-arm and mobile manipulators with different physically-based sensors and motion generators. Orbit allows training reinforcement learning policies and collecting large demonstration datasets from hand-crafted or expert solutions in a matter of minutes by leveraging GPU-based parallelization. In summary, we offer an open-sourced framework that readily comes with 16 robotic platforms, 4 sensor modalities, 10 motion generators, more than 20 benchmark tasks, and wrappers to 4 learning libraries. With this framework, we aim to support various research areas, including representation learning, reinforcement learning, imitation learning, and task and motion planning. We hope it helps establish interdisciplinary collaborations in these communities, and its modularity makes it easily extensible for more tasks and applications in the future.},
  keywords={Robots;Orbits;Task analysis;Robot sensing systems;Sensors;Deformable models;Physics;Software tools for benchmarking and reproducibility;machine learning for robot control;deep learning for visual perception;simulation and animation},
  doi={10.1109/LRA.2023.3270034},
  ISSN={2377-3766},
  month={June},}@INPROCEEDINGS{10430509,
  author={Bankira, Dula and Banik, Debajyoty and Dash, Satya Ranjan and Nayak, Smriti},
  booktitle={2023 OITS International Conference on Information Technology (OCIT)}, 
  title={Automatic Language Detection for Low Resource Ho Language}, 
  year={2023},
  volume={},
  number={},
  pages={898-902},
  abstract={In recent years, social media networking has grown into an amazing improvement in our everyday ways of life. As its popularity grew, more people of all ages began to take advantage of these increasing phenomena. Generally, we convey information or sent text messages to others using different scripts of the language, which is a challenging task to classify the language. Due to the lack of training datasets for low-resource language, it is difficult to detect. In this paper, we have taken Ho language, which is low resource language. The Ho and Odia, both languages are written in the same script i.e. in Odia. The main objective of this paper is to identify Odia and Ho language using different algorithms such as Logistic Regression, Gaussian Naive Bayes, Decision Tree and Random Forest. The paper also states that Precision, Recall, and F-Score were all used as evaluation measures.},
  keywords={Training;Logistic regression;Social networking (online);Classification algorithms;Object recognition;Task analysis;Random forests;Language Detection;Low resource Language;Odia and Ho Language;Logistic Regression;Gaussian Naive Bayes;Decision Tree and Random Forest},
  doi={10.1109/OCIT59427.2023.10430509},
  ISSN={},
  month={Dec},}@ARTICLE{10511285,
  author={Zeng, Linzhou and Liao, Xuewen and Ma, Zhangfeng and Jiang, Hao and Chen, Zhen},
  journal={IEEE Internet of Things Journal}, 
  title={UAV-to-UAV MIMO Systems Under Multimodal Nonisotropic Scattering: Geometrical Channel Modeling and Outage Performance Analysis}, 
  year={2024},
  volume={11},
  number={15},
  pages={26266-26278},
  abstract={An arbitrary-elevation two-sphere reference model is utilized to mimic the unmanned aerial vehicle (UAV) air-to-air fading channels. The model considers the Line-of-Sight (LoS), the single-bounced transmit (SBT), the single-bounced receive (SBR), and the double-bounced (DB) rays. Based on this model, the closed-form expression of the space–time correlation function (ST-CF) is obtained for the first time under the widely used assumption of von Mises–Fisher (vMF) distributed scatterers. To further improve the model’s adaptability to realistic scattering environments, the distribution of the scatterers is generalized from a single unimodal vMF density into a mixture that can possess multimodality. Using the single-vMF ST-CF, the ST-CF under the mixture is also written in closed form. Corresponding to the reference channel model, both the deterministic and the stochastic simulation models are provided, which yield consistent results with the respective derived expressions. This validates the correctness of the suggested closed-form ST-CFs. Moreover, a detailed analysis of the outage probability and the outage capacity is reported, which offers revealing insights into the behaviors of the system performance with respect to change of some key model parameters under multimodal distributions of the scatterers.},
  keywords={Scattering;Autonomous aerial vehicles;Channel models;Atmospheric modeling;Vehicular ad hoc networks;Stochastic processes;Geometry-based stochastic model (GBSM);space–time correlation function (ST-CF);UAV-to-UAV (U2U) channel modeling and simulation;von Mises–Fisher (vMF) distribution},
  doi={10.1109/JIOT.2024.3395524},
  ISSN={2327-4662},
  month={Aug},}@ARTICLE{9359746,
  author={Shuja, Junaid and Humayun, Mohammad Ali and Alasmary, Waleed and Sinky, Hassan and Alanazi, Eisa and Khan, Muhammad Khurram},
  journal={IEEE Sensors Journal}, 
  title={Resource Efficient Geo-Textual Hierarchical Clustering Framework for Social IoT Applications}, 
  year={2021},
  volume={21},
  number={22},
  pages={25114-25122},
  abstract={The Social Internet of Things (SIoT) paradigm incorporates social networking concepts with the Internet of Things (IoT) solutions to support novel services. The massive amount of data (big data) produced by SIoT necessitates efficient information processing frameworks to exploit social relationships and comprehend actionable information from real-world observations. Data from AI-enabled sensors (AIS) is typically geo-tagged, thus demanding geo-textual processing for information retrieval and analysis. Social media applications are the main source of geo-textual data as mobile users connect with millions of posts daily. The processing of big geo-textual data requires resource-efficient algorithms and frameworks. Clustering algorithms are often applied to geo-textual data to examine spatial, textual, and temporal information for event detection, sentiment analysis, and search query response. Clustering algorithms on big data are resource-hungry requiring comparisons among all data points to calculate similarity and distance metrics. Existing hybrid clustering techniques execute algorithms collectively on geo-textual data resulting in a enormous footprint for big data. We propose a resource-efficient clustering framework for AIS that hierarchically performs geo-textual clustering without significantly lowering the clustering quality. The proposed framework achieves substantial time and memory efficiency while reducing the overall resource requirements for constrained end-user and edge devices compared to the standard hybrid geo-textual clustering framework. Moreover, we augment the research work by developing open-source scripts for both hierarchical and hybrid clustering frameworks.},
  keywords={Sensors;Artificial intelligence;Social networking (online);Big Data;Task analysis;Internet of Things;Clustering algorithms;Clustering;geo-textual;machine learning;resource efficiency;social IoT},
  doi={10.1109/JSEN.2021.3060953},
  ISSN={1558-1748},
  month={Nov},}@ARTICLE{9507270,
  author={Cilia, Nicole D. and D’Alessandro, Tiziana and De Stefano, Claudio and Fontanella, Francesco and Molinara, Mario},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={From Online Handwriting to Synthetic Images for Alzheimer's Disease Detection Using a Deep Transfer Learning Approach}, 
  year={2021},
  volume={25},
  number={12},
  pages={4243-4254},
  abstract={Early diagnosis of neurodegenerative disorders, such as Alzheimer's Disease (AD), is very important to reduce their effects and to improve both quality and life expectancy of patients. In this context, it is generally agreed that handwriting is one of the first skills altered by the onset of AD. For this reason, the analysis of handwriting and the study of its alterations has become of great interest in order to formulate the diagnosis as soon as possible. A fundamental aspect for the use of these techniques is the definition of effective features, which allows the system to distinguish the natural alterations of handwriting due to age, from those caused by neurodegenerative disorders. Starting from these considerations, the aim of our study is to verify whether the combined use of both shape and dynamic features allows a decision support system to improve performance for AD diagnosis. To this purpose, starting from a database of on-line handwriting samples, we generated for each of them an off-line synthetic color image, where the color of each elementary trait encodes, in the three RGB channels, the dynamic information associated with that trait. To verify the role played by dynamic information, we also generated simple binary images, containing only shape information. Finally, we exploited the ability of Convolutional Neural Network (CNN) to automatically extract features on both color and binary images. The experimental results have confirmed that dynamic information allows a performance improvement with respect to the binary images.},
  keywords={Feature extraction;Artificial intelligence;Decision support systems;Deep learning;Transfer learning;Alzheimer's disease;Artificial intelligence;decision support systems;deep learning;handwriting analysis;Alzheimer's disease},
  doi={10.1109/JBHI.2021.3101982},
  ISSN={2168-2208},
  month={Dec},}@INPROCEEDINGS{10692314,
  author={Raut, Umesh and Galchhaniya, Prathmesh and Nehete, Anish and Shinde, Rohan and Bhoite, Avaneesh},
  booktitle={2024 2nd World Conference on Communication & Computing (WCONF)}, 
  title={Unity ML-Agents: Revolutionizing Gaming Through Reinforcement Learning}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={At the vanguard of AI, Reinforcement Learning (RL) is transforming sectors and pushing the limits of human-computer interaction. In the world of gaming, RL has become a powerful force that presents unheard-of chances to improve user experiences, have an impact on game creation, and even transform the gaming industry. Even while players are immersed in well constructed worlds and challenges through gaming, the strict and scripted style of traditional game design has its drawbacks. Gamers frequently want for dynamic, erratic, and adaptable encounters that can compete with those provided by live opponents. Here is where RL steps in, bringing with it the power to create intelligent agents that can interact with virtual surroundings to learn, adapt, and change. This study explores the relationship between RL and gaming, looking into how RL techniques are being used to revitalize this multibillion-dollar sector. The paper explores the core ideas of reinforcement learning and reveals the mechanisms underlying this paradigm. We explore the nuances of RL algorithms and techniques, with a focus on the gaming industry, enabling developers to create non-player characters (NPCs) who pose distinct and customized challenges to players.},
  keywords={Industries;Human computer interaction;Force;Dynamics;Reinforcement learning;Games;Transforms;Intelligent agents;Artificial intelligence;Reinforcement Learning;Artificial Intelligence;MLAgents;Unity;Blender;Gaming;Non-Player Characters},
  doi={10.1109/WCONF61366.2024.10692314},
  ISSN={},
  month={July},}@INPROCEEDINGS{10085594,
  author={Bhaidana, Hetal and Paikaray, Divya},
  booktitle={2023 International Conference on Artificial Intelligence and Smart Communication (AISC)}, 
  title={PET Imaging for Alzheimer's Neuroanatomical Disease Diagnosis}, 
  year={2023},
  volume={},
  number={},
  pages={1406-1410},
  abstract={The standard for local assessment of nuclear brain scans information still involves manually determining the volumes of interest (VOIs). A range of program solutions for rapid recognition of neuroanatomical features were created because this method is laborious & operator based. We tested 4 automated VOI identification techniques (Free Surfer, HERMES Brass & two PMOD approaches) throughout this study compare to traditional approach because the performance & quality of those technologies have not been thoroughly studied in the analysis of amyloidosis PET information. In a recent medical trial, we obtained florbetaben cerebral PET & MRI information from 10 sufferers with suspected Alzheimer's dementia (AD) & ten age similarly healthy controls (HCs).The 4 automatic processes and the human definition of VOIs on the information were both used. For every VOI, standardised uptake value ratios (SUVRs) were computed using the cerebellum cortex as a reference region. Utilizing Mann-Whitney-U testing, SUVR assessments among ADs & HCs were made, & significance value (Cohen's d) were determined. According to Pearson's testing, the SUVRs of automated VOIs and traditionally calculated VOIs were associated.A substantial change between ADs and HCs was seen in the composites frontal cortex SUVRs produced by arbitrarily specified VOIs (p=00.0100, d=01.530). The same was true for the 4 computational methods that were examined, which had correlation coefficients ranging from 01.380 to 01.620. In a variety of brain regions, the SUVRs of the machine produced VOIs as well as the drawn VOIs significantly correlated, with local variations in the strength of these relationships. For each of the development applications that were assessed, the lateral temporal VOI demonstrated the highest obtaining accurate (r=0.82 to r=0.95, p0.001).The software packages under evaluation have a potentiality to replace the existing conventional practise of physically defining VOIs in the processing of -amyloid PET information.},
  keywords={Correlation coefficient;Software packages;Magnetic resonance imaging;Process control;Distance measurement;Medical diagnosis;Alzheimer's disease;Alzheimer's disea;PET;β-amyloid;neuroanatomical;Florbetaben},
  doi={10.1109/AISC56616.2023.10085594},
  ISSN={},
  month={Jan},}@ARTICLE{10546982,
  author={Zhou, Xiao and Balachandra, Akshara R. and Romano, Michael F. and Peter Chin, Sang and Au, Rhoda and Kolachalama, Vijaya B.},
  journal={IEEE Access}, 
  title={Adversarial Learning for MRI Reconstruction and Classification of Cognitively Impaired Individuals}, 
  year={2024},
  volume={12},
  number={},
  pages={83169-83182},
  abstract={Game theory-inspired deep learning using a generative adversarial network provides an environment to competitively interact and accomplish a goal. In the context of medical imaging, most work has focused on achieving single tasks such as improving image resolution, segmenting images, and correcting motion artifacts. We developed a dual-objective adversarial learning framework that simultaneously 1) reconstructs higher quality brain magnetic resonance images (MRIs) that 2) retain disease-specific imaging features critical for predicting progression from mild cognitive impairment (MCI) to Alzheimer’s disease (AD). We obtained 3-Tesla, T1-weighted brain MRIs of participants from the Alzheimer’s Disease Neuroimaging Initiative (ADNI, N=342) and the National Alzheimer’s Coordinating Center (NACC, N =190) datasets. We simulated MRIs with missing data by removing 50% of sagittal slices from the original scans (i.e., diced scans). The generator was trained to reconstruct brain MRIs using the diced scans as input. We introduced a classifier into the GAN architecture to discriminate between stable (i.e., sMCI) and progressive MCI (i.e., pMCI) based on the generated images to facilitate encoding of disease-related information during reconstruction. The framework was trained using ADNI data and externally validated on NACC data. In the NACC cohort, generated images had better image quality than the diced scans (Structural similarity (SSIM) index:  $0.553 \pm 0.116$  versus  $0.348 \pm 0.108$ ). Furthermore, a classifier utilizing the generated images distinguished pMCI from sMCI more accurately than with the diced scans (F1-score:  $0.634 \pm 0.019$  versus  $0.573 \pm 0.028$ ). Competitive deep learning has potential to facilitate disease-oriented image reconstruction in those at risk of developing Alzheimer’s disease.},
  keywords={Magnetic resonance imaging;Image reconstruction;Biomedical imaging;Generative adversarial networks;Alzheimer's disease;Generators;Adversarial machine learning;Image reconstruction;generative adversarial network;magnetic resonance imaging;Alzheimer’s disease},
  doi={10.1109/ACCESS.2024.3408840},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10939807,
  author={Benjamin, Minu Inba Shanthini Watson and Maithili, K and Chandralekha, E and Gowtham, D. and Reddy, Salla Anand Kumar and Teja, Kota Dharma},
  booktitle={2024 Asian Conference on Intelligent Technologies (ACOIT)}, 
  title={Multi-Model Deep Learning Fusion for Improved Alzheimer’s Disease Classification with MRI and Cognitive Data}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Given its increasing impact and enormous global societal impact, Alzheimer’s disease (AD) presents a serious issue in the healthcare industry. Effective therapies and management techniques for AD depend on early detection and a precise diagnosis. On the other hand, traditional diagnostic approaches frequently depend on expensive imaging methods and arbitrary clinical judgments, which causes delays in diagnosis and less than ideal results. By utilizing MRI scans and handwriting samples, the suggested strategy embraces the ability of multi-modal data integration to offer a novel perspective to AD prediction. A non-invasive and economical method of identifying minor motor and cognitive problems suggestive of early-stage $A D$ is handwriting analysis, whereas MRI offers important insights into the structural brain abnormalities linked to AD. To rigorously pre-process and extract significant features from MRI and handwriting data, state-of-the-art deep learning techniques are used. A multimodal neural network architecture is then fed these features for combined analysis and prediction. Accuracy rates of $\mathbf{8 8 \%}$ for handwriting data and $\mathbf{9 0} \%$ for MRI images are attained by each independently trained model. A unified classifier is then used to aggregate the outputs of different models and refine the categorization through the addition of denser layers A remarkable $\mathbf{9 7 \%}$ accuracy on the test set is achieved by this combined model, which considerably improves diagnostic accuracy. The technique provides a comprehensive approach to AD prediction by combining structural and functional information from MRI with handwriting data, enabling early detection and individualized treatment plans. In order to create robust and trustworthy diagnostic tools, the results emphasize how crucial it is to integrate many data modalities and use deep learning approaches.},
  keywords={Deep learning;Accuracy;Magnetic resonance imaging;Data integration;Feature extraction;Motors;Data models;Alzheimer's disease;Biological neural networks;Resilience;(Alzheimer’s disease;Deep learning;handwriting analysis;MRI;Multi-modal data integration)},
  doi={10.1109/ACOIT62457.2024.10939807},
  ISSN={},
  month={Sep.},}@ARTICLE{8847372,
  author={Xie, Dehua and Liu, Shuaicheng and Wang, Yinglong and Zhu, Shuyuan and Zeng, Bing},
  journal={IEEE Access}, 
  title={View-Consistent Intrinsic Decomposition for Stereoscopic Images}, 
  year={2019},
  volume={7},
  number={},
  pages={140355-140366},
  abstract={In this paper, we focus on the intrinsic image decomposition problem for stereoscopic image pairs. The existing methods cannot be applied directly to decompose stereoscopic images, as it often produces inconsistent reflectance (albedo) and 3D artifacts after the decomposition. We propose a straightforward yet effective framework that enables a high-quality decomposition for stereoscopic pairs. First, retinex-based constraints are employed to coarsely classify the observed image gradients into two categories that are caused by reflectance changes and illumination variations, respectively. Second, reflectance-consistent constraints are added to control the reflectance consistency between the left and right views. Since this problem is highly ill-posed, we further analyze local and non-local image textures regularized by super-pixels within and across two views to reduce reflectance ambiguity. Lastly, absolute-scale constraints are employed to normalize the decomposition results. Extensive experiments on the real-world stereoscopic images and synthetic stereoscopic images reveal that our method can readily achieve high-quality decomposition performance.},
  keywords={Stereo image processing;Image decomposition;Videos;Lighting;Task analysis;Surface treatment;Shape;Intrinsic image decomposition;reflectance;shading;stereoscopic image},
  doi={10.1109/ACCESS.2019.2943516},
  ISSN={2169-3536},
  month={},}@ARTICLE{9992234,
  author={Atoche-Enseñat, R. and Pérez, E. and Hernández-Benítez, A. and Balam, A. and Estrada-López, Johan J. and Vázquez-Castillo, J. and Aviles, F. and Castillo-Atoche, A.},
  journal={IEEE Sensors Journal}, 
  title={A Smart Tactile Sensing System Based on Carbon Nanotube/Polypropylene Composites for Wearable Applications}, 
  year={2023},
  volume={23},
  number={3},
  pages={2948-2955},
  abstract={Recent advances in nanomaterials render the possibility of fabricating tactile sensors suitable for electronic skin, haptic interfaces, and biomedical applications. Furthermore, the problem of performing complex inertial measurements generated during the tactile process of polymer composites can be tackled using artificial intelligence (AI). However, the implementation of AI-based signal processing on embedded devices still represents an open area of opportunity for the design of the next generation of smart wearable sensor systems. A novel nanostructured smart tactile sensing system for wearable applications is proposed, using a 3-D-printed structure with embedded electronic devices. The highly sensitive piezoresistive tactile sensor is based on multiwall carbon nanotube/polypropylene (MWCNT/PP) composites. The integration of electronic circuits for signal processing of an artificial neural network (NN) on a digital controller unit improves the tactile interpretation in the wearable embedded device. Experiments show that the pressure classification results on MWCNT/PP composites with 98% accuracy.},
  keywords={Sensors;Tactile sensors;Nanocomposites;Intelligent sensors;Wearable sensors;Sensor systems;Piezoresistance;Carbon nanotube (CNT)/polypropylene (PP) composite;intelligent tactile classification;piezoresistive tactile sensor;smart wearable sensor},
  doi={10.1109/JSEN.2022.3229232},
  ISSN={1558-1748},
  month={Feb},}@ARTICLE{9373917,
  author={Song, Tengfei and Liu, Suyuan and Zheng, Wenming and Zong, Yuan and Cui, Zhen and Li, Yang and Zhou, Xiaoyan},
  journal={IEEE Transactions on Affective Computing}, 
  title={Variational Instance-Adaptive Graph for EEG Emotion Recognition}, 
  year={2023},
  volume={14},
  number={1},
  pages={343-356},
  abstract={The individual differences and the dynamic uncertain relationships among different electroencephalogram (EEG) regions are essential factors that limit EEG emotion recognition. To address these issues, in this article, we propose a variational instance-adaptive graph method (V-IAG) that simultaneously captures the individual dependencies among different EEG electrodes and estimates the underlying uncertain information. Specifically, we employ two branches, i.e., instance-adaptive branch and variational branch, to construct the graph. Inspired by the attention mechanism, the instance-adaptive branch generates the graph based on the input so as to characterize the individual dependencies among EEG channels. The variational branch generates the probabilistic graph, which quantifies the uncertainties. We combine these two types of graphs to extract more discriminative features. To present more precise graph representation, we propose a new operation named the multi-level and multi-graph convolution operation, which aggregates the features of EEG channels from different frequencies with different graphs. Furthermore, we design the graph coarsening and employ the sparse constraint to obtain more robust features. We conduct extensive experiments on three widely-used EEG emotion recognition databases, i.e., SJTU emotion EEG dataset (SEED), multi-modal physiological emotion recognition dataset (MPED) and DREAMER. The results demonstrate that the proposed model achieves the-state-of-the-art performance.},
  keywords={Electroencephalography;Emotion recognition;Feature extraction;Brain modeling;Time-frequency analysis;Electrodes;Uncertainty;EEG emotion recognition;graph neural network;variational inference},
  doi={10.1109/TAFFC.2021.3064940},
  ISSN={1949-3045},
  month={Jan},}@INPROCEEDINGS{10430635,
  author={Hirishikesh, P and Yaswanth, MVS and A, Helen Victoria},
  booktitle={2023 OITS International Conference on Information Technology (OCIT)}, 
  title={Speech to Lip Sync generation using Deep learning Algorithm}, 
  year={2023},
  volume={},
  number={},
  pages={426-431},
  abstract={The emerging growth of artificial intelligence (AI) technology created a way for many innovative developments. Speech to lip synchronization (STLS) is one of the key requirement in applications related to film making, voice modulation, video creation etc. The identification of speaking face synchronized with the voice need to be done accurately to improve the quality of the video. Many existing systems face the problem while imposing the new audio into the existing video files. The movement of lips dynamically changes according to the speaking faces. To solve the missing synchronization problem of existing videos to retrieve the original quality from the video input, the proposed system is focused on creating accurate lip synchronization model using Deep SyncNet (DSN) using Deep learning convolution architecture. The timing accuracy of the video synchronization extensively improve the quality of the video and demands real time experience from the video footage. Detection of facial variations without extracting the features are particularly challenging. The proposed system considers the existing challenges like misclassification, delayed synchronization and evaluated the SyncNet achieved the accuracy of 95% on lip synchronization with labelled dataset.},
  keywords={Deep learning;Visualization;Lips;Streaming media;Feature extraction;Synchronization;Faces;Deep learning;Audio analysis;Speech conversion;Data augmentation;Audio processing},
  doi={10.1109/OCIT59427.2023.10430635},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10841789,
  author={Elhagry, Ahmed and El Saddik, Abdulmotaleb},
  booktitle={2024 IEEE Conference on Telepresence}, 
  title={Text-to-Metaverse: Integrating Advanced Text-to-PointCloud Techniques for Enhanced 3D Scene Generation}, 
  year={2024},
  volume={},
  number={},
  pages={197-202},
  abstract={This paper presents a novel approach to generating metaverse environments directly from textual descriptions by integrating advanced text-to-pointcloud techniques into the text-to-metaverse pipeline. The proposed system replaces conventional text understanding and design script components with a more efficient and accurate pipeline, enhancing the overall generation process. Our methodology leverages natural language processing for entity and relation extraction, which are then converted into structured scene descriptions. These descriptions guide a generative shape engine to produce 3D objects and scenes, which are subsequently rendered into immersive metaverse environments. Experimental evaluations demonstrate significant improvements in both efficiency and quality of the generated environments compared to the baseline model. The integration of text-to-pointcloud techniques ensures a higher fidelity in object representation and scene coherence, addressing limitations in existing metaverse generation methods. This work paves the way for more interactive and dynamic virtual environments, offering substantial advancements for applications in gaming, virtual reality, and remote collaboration.},
  keywords={Solid modeling;Three-dimensional displays;Telepresence;Metaverse;Shape;Pipelines;Collaboration;Coherence;Natural language processing;Engines},
  doi={10.1109/Telepresence63209.2024.10841789},
  ISSN={},
  month={Nov},}@ARTICLE{10634300,
  author={Oh, Hyungrock and Xiang, Yang and Redondo, Fernando Garcia and Gupta, Mohit Kumar and Perumkunnil, Manu and Bardon, Marie Garcia and Dhiman, Amit and Gowda, Sathisha Nanjunde and Walke, Amey and Fantini, Andrea and Yasin, Farrukh and Kar, Gouri Sankar and Hellings, Geert and Dehaene, Wim},
  journal={IEEE Transactions on Electron Devices}, 
  title={Design Space Exploration of FeRAM Bit Cell for DRAM Application}, 
  year={2024},
  volume={71},
  number={9},
  pages={5380-5387},
  abstract={HfOx-based ferroelectric random access memories (FeRAMs) have been proposed as a promising candidate to further dynamic random access memory (DRAM) scaling. This article presents a bitcell design space exploration of HfZrOx-based FeRAM based on a 2T1C testbench representative of a 64-kb 1T1C subarray at 40-nm CMOS technology. We first explore the impact of ferroelectric capacitor (FeCAP) sizing on the read sensing margin (SM) and speed with eight different blocks in the subarray, supported by a hardware-calibrated FeCAP compact model. We identify the capacitance ratio ( ${C} _{\text {R}}$ ) between the bitline parasitic capacitance ( ${C} _{\text {BL}}$ ) and the FeCAP capacitance ( ${C} _{\text {FE}}$ ) as the critical design parameter for bitcell SM optimization, with a maximum  ${C} _{\text {R}}$  of 41 permitted for the given FeCAP technology. Furthermore, we investigate the impact of FeCAP sizing on ferro-grain granularity (FGG)-induced variability. Our findings clarify that SM variability worsens with increasing FeCAP size but does not significantly affect the readability overall. Additionally, we examine the consequences of FeCAP sizing on disturbance effects during write operations, concluding that larger FeCAPs help mitigate write disturbances by reducing voltage transfer to half-selected (HS) cells.},
  keywords={Random access memory;Nonvolatile memory;Ferroelectric films;Iron;Computer architecture;Voltage;Microprocessors;1T1C;2T1C;bitline parasitic capacitance (CBL);dynamic random access memory (DRAM);ferroelectric capacitor (FeCAP) capacitance (CFE);FeCAP;ferroelectric random access memories (FeRAMs)},
  doi={10.1109/TED.2024.3435630},
  ISSN={1557-9646},
  month={Sep.},}@INPROCEEDINGS{10253881,
  author={Nhu, Anh and Phan, Hieu and Liu, Chang and Feng, Xianglong},
  booktitle={2023 IEEE International Performance, Computing, and Communications Conference (IPCCC)}, 
  title={A Comprehensive Defense Approach Targeting The Computer Vision Based Cheating Tools in FPS Video Games}, 
  year={2023},
  volume={},
  number={},
  pages={168-177},
  abstract={Video games is one of the most popular multimedia forms and generate higher profits than the traditional film industry. In the meantime, with the advances of deep learning, computer vision algorithms have become more powerful for analyzing the video content and have been applied in the FPS video games as an advanced cheating tools, which have taken the video games industry by storm. Such algorithms, including the object detection and human pose estimations, could analyze and understand the video content in each frame and further help the player to automatically identify and aim at the enemies with extremely fast reaction. Compared to the classic cheating tools, computer-vision-based cheating tools are harder to detect and defend against because they do not need to manipulate the software or the system but purely simulate how a well trained and skilled human gamer plays the video game. In this paper, we propose a proactive and comprehensive defense approach, which generates perturbations that are not perceptible to humans yet can still mislead the computer vision algorithms. More specifically, this comprehensive approach includes two parts, the defense approach aims to fail the computer vision-based cheating tools to detect the in-game characters while the penalty approach aims to fool the computer vision-based cheating tools to detect the fake regions as in-game characters, which not only worsen the cheating experience but also serve as a trigger for detecting the cheating behavior. In this work, we first implement the object detection based cheating tools as the evaluation environment. Then, we implement our proposed defense, penalty and comprehensive approaches and evaluate the performance with four popular video games. The results show that our comprehensive approach obtains a high success rate with minor impact to user experience quality.},
  keywords={Video games;Computer vision;Storms;Perturbation methods;Software algorithms;Object detection;Streaming media;Video Game;AI;Computer Vision;Cheating Tools;Adversarial Attack},
  doi={10.1109/IPCCC59175.2023.10253881},
  ISSN={2374-9628},
  month={Nov},}@INPROCEEDINGS{9688164,
  author={Li, Man and Maalla, Allam and Liu, Sanhua},
  booktitle={2021 IEEE 2nd International Conference on Information Technology, Big Data and Artificial Intelligence (ICIBA)}, 
  title={Research on Recommendation System Using Big Data Based on Deep Learning}, 
  year={2021},
  volume={2},
  number={},
  pages={919-923},
  abstract={According to the recommendation algorithm based on deep learning, this article will verify the validity of the recommendation model through Item2vec and DeepFM models. To analyze the relationship between historical user behavior data and the users of the product are interested in, the Spark SQL scripts can be run according to statistical analysis methods, and generate the training set and test set, which is needed by train the model, and build predictive models, and get the collection of products that each user is interested in and improve the prediction effect through model optimization. Experimental verification and analysis show that the recommendation system can handle massive amounts of user and product data. It can also extract features from these data for training automatically, which is conducive to improving the quality and efficiency of users' shopping decisions. we first complete feature extraction based on the processed data set. At present, the most used feature extraction method is feature extraction based on artificial experience and statistical methods. However, because the actual application scenarios of the recommendation system are often more complicated, we used Spark SQL scripts to extract features in experiments. First, extract the experimental data from the distributed database, and use the workflow scheduling script to generate the data set required for model training and testing.},
  keywords={Training;Deep learning;Distributed databases;Predictive models;Big Data;Feature extraction;Data models;Big Data Technology;Deep Learning;Personalized Recommendation;Recommendation Algorithm;Offline Mining;Real-Time Mining},
  doi={10.1109/ICIBA52610.2021.9688164},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9804589,
  author={Horro, Marcos and Pouchet, Louis-Noël and RodríDguez, Gabriel and Touriño, Juan},
  booktitle={2022 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS)}, 
  title={MARTA: Multi-configuration Assembly pRofiler and Toolkit for performance Analysis}, 
  year={2022},
  volume={},
  number={},
  pages={79-89},
  abstract={Benchmarking to characterize specific software or hardware features is an error-prone, arduous and repetitive task. Designing a specialized experimental setup frequently requires writing new scripts or ad-hoc programs in order to properly exhibit interesting performance effects, using code changes and hardware events measurements. These artifacts may have limited reusability for subsequent experiments, since they are dependent on specific problems and, in some cases, platforms. To improve productivity and reproducibility of such experiments, which are often investigative in nature, we introduce MARTA: a fully customizable toolkit that aims to increase productivity by generating benchmark templates, compiling them, and profiling the regions of interest (RoI) specified using hardware events, and performing static code analysis. MARTA can also be applied on existing code regions of interest, it only requires to write a simple configuration file. In an orthogonal dimension, the system is able to run various statistical analyses on the measurements collected. MARTA uses data mining and machine learning or AI-based techniques for classification and regression, automatically extracting the features of the experimental setup which have the most impact on performance or whichever other metric of interest, given a large set of experiments and dimensions to consider. These post-processing tasks are valuable for deriving knowledge from experiments and are not included in most profiling tools. We also provide a set of cases of study to illustrate the ability of MARTA to conveniently create a reliable and reproducible setup for high-performance computing experiments, investigating three vastly different performance effects on modern processors.},
  keywords={Productivity;Codes;Benchmark testing;Writing;Feature extraction;Hardware;Software;profiling;benchmarking;micro-benchmarking;performance analysis;compiler characterization},
  doi={10.1109/ISPASS55109.2022.00008},
  ISSN={},
  month={May},}@ARTICLE{9781426,
  author={Gohari, Adel and Ahmad, Anuar Bin and Rahim, Ruzairi Bin Abdul and Supa’at, A. S. M. and Abd Razak, Shukor and Gismalla, Mohammed Salih Mohammed},
  journal={IEEE Access}, 
  title={Involvement of Surveillance Drones in Smart Cities: A Systematic Review}, 
  year={2022},
  volume={10},
  number={},
  pages={56611-56628},
  abstract={Drones, or unmanned aerial vehicles (UAVs), are among the most beneficial and emerging technologies, with a wide range of applications that can support the sustainability concerns of smart cities and ultimately improve citizens’ quality of life. The goals of this systematic review were to explore the involvement of surveillance drones in smart cities in terms of application status, application areas, proposed models, and characteristics of drones. We conducted this systematic review based on the preferred reporting items for systematic reviews and meta-analyzes (PRISMA) guidelines. We systematically searched the Web of Science and Scopus for journal articles and conference papers written in English and published up to August 2021. Of the 323 records identified, 43 met the inclusion criteria. Findings showed that surveillance drones were used in seven distinct research fields (transportation, environment, infrastructure, object or people detection, disaster management, data collection, and other applications). Air pollution and traffic monitoring were the dominant application areas. The majority of reviewed models were based on the application of rotary-wing single-drones with the camera as the aerial sensor. Reviewed models showed that the adoption of a single or multiple UAVs, either as a stand-alone technology or integrated with other technologies (e.g., internet of things, wireless sensor networks, convolutional neural networks, artificial intelligence, machine learning, computer vision, cloud computing, web applications), can offer efficient and sustainable solutions compared to conventional surveillance methods. This review can benefit academic researchers and practitioners.},
  keywords={Smart cities;Drones;Surveillance;Systematics;Monitoring;Autonomous aerial vehicles;Statistics;Applications;drone;smart city;surveillance;sensor;review},
  doi={10.1109/ACCESS.2022.3177904},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9494483,
  author={Rodriguez-Lozano, Francisco Javier and Gámez-Granados, Juan Carlos and Banos, Oresti and Alcalá-Fdez, Jesús and Soto-Hidalgo, Jose Manuel},
  booktitle={2021 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)}, 
  title={An approach to bridge the gap between ubiquitous embedded devices and JFML: A new module for Internet of Things}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={Internet of Things enables sensors and actuators to share heterogeneous data between different devices. Such data can be used to create intelligent systems to control diverse structures available in houses, cities, or industrial environments among others. In this context, one of the most used approaches to handle these intelligent systems is based on Fuzzy Rule-Based Systems (FRBS) due to their suitability for addressing complex data and managing their imprecision. However, most of the current developments in this area are usually ad-hoc solutions limited by the intercommunication between FRBS and IoT devices. This results into significant challenges in reusing these solutions to solve latent problems. To bridge this gap, a new module for the open source library JFML is proposed to offer a complete implementation of an IoT infrastructure to develop intelligent IoT solutions based on the IEEE std 1855–2016. Moreover, a case study with real IoT devices is presented to showcase the use of the proposed module.},
  keywords={Temperature sensors;Performance evaluation;Actuators;Temperature distribution;Protocols;Urban areas;Libraries},
  doi={10.1109/FUZZ45933.2021.9494483},
  ISSN={1558-4739},
  month={July},}@INPROCEEDINGS{10633604,
  author={Otieno, Denish Omondi and Abri, Faranak and Siami-Namini, Sima and Namin, Akbar Siami},
  booktitle={2024 IEEE 48th Annual Computers, Software, and Applications Conference (COMPSAC)}, 
  title={The Accuracy of Domain Specific and Descriptive Analysis Generated by Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={1739-1746},
  abstract={Large language models (LLMs) have attracted considerable attention as they are capable of showcasing impressive capabilities generating comparable high-quality responses to human inputs. LLMs, can not only compose textual scripts such as emails and essays but also executable programming code. Contrary, the automated reasoning capability of these LLMs in performing statistically-driven descriptive analysis, particularly on user-specific data and as personal assistants to users with limited background knowledge in an application domain who would like to carry out basic, as well as advanced statistical and domain-specific analysis is not yet fully explored. More importantly, the performance of these LLMs has not been compared and discussed in detail when domain-specific data analysis tasks are needed. Additionally, the use of LLMs in isolation is often at times insufficient for creating powerful applications and the real potential comes when LLMs are combined with other sources of computation such as LangChain. This study, consequently, explores whether LLMs can be used as generative AI-based personal assistants to users with minimal background knowledge in an application domain infer key data insights. To demonstrate the performance of the LLMs, the study reports a case study through which descriptive statistical analysis, as well as Natural Language Processing (NLP) based investigations, are performed on a number of phishing emails with the objective of comparing the accuracy of the results generated by LLMs to the ones produced by analysts. The experimental results show that LangChain and the Generative Pre-trained Transformer (GPT-4) excel in numerical reasoning tasks i.e., temporal statistical analysis, achieve competitive correlation with human judgments on feature engineering tasks while struggle to some extent on domain specific knowledge reasoning, where domain-specific knowledge is required.},
  keywords={Knowledge engineering;Accuracy;Statistical analysis;Large language models;Transformers;Cognition;Natural language processing;Large Language Models;LangChain;Generative Pre-trained Transformer;Natural Language Processing;Phishing Emails},
  doi={10.1109/COMPSAC61105.2024.00274},
  ISSN={2836-3795},
  month={July},}@INPROCEEDINGS{9431927,
  author={Junaedi, Hartarto},
  booktitle={2021 3rd East Indonesia Conference on Computer and Information Technology (EIConCIT)}, 
  title={Multi Camera Positioning Behaviour Based On A Director Style Using Fuzzy Logic for Machinima}, 
  year={2021},
  volume={},
  number={},
  pages={151-155},
  abstract={The role of computer technology in the world of cinematography is getting widely. One of the supporting technologies is Machinima. Machinima is a system that uses 3D graphics rendering technology real time to produce a virtually cinematic product. In the process of making a cinematic product like a film, the camera positioning play an very important role. In the real world there is a director who will directing the cameramen to place the camera manually according to specific view point and behavior. This research proposes an intelligent multi behavior of cinematographic camera where the camera will be place automatically in accordance a behavior directorial style. By doing the appropriate camera positioning then a film will have different impact to audience. For positioning of the camera will be based on fuzzy logic. This research proves that an artificial intelligence engine for camera can be made for positioning the camera based on director's style. From the test result is obtained that the system can implement multi behavior cameras in machinima using fuzzy logic.},
  keywords={Fuzzy logic;Graphics;Three-dimensional displays;Cinematography;Cameras;Rendering (computer graphics);Real-time systems;Fuzzy Logic;Machinima;Camera Positioning;Multi Behavior Camera},
  doi={10.1109/EIConCIT50028.2021.9431927},
  ISSN={},
  month={April},}@ARTICLE{9520216,
  author={Hoda, Rashina},
  journal={IEEE Transactions on Software Engineering}, 
  title={Socio-Technical Grounded Theory for Software Engineering}, 
  year={2022},
  volume={48},
  number={10},
  pages={3808-3832},
  abstract={Grounded Theory (GT), a sociological research method designed to study social phenomena, is increasingly being used to investigate the human and social aspects of software engineering (SE). However, being written by and for sociologists, GT is often challenging for a majority of SE researchers to understand and apply. Additionally, SE researchers attempting ad hoc adaptations of traditional GT guidelines for modern socio-technical (ST) contexts often struggle in the absence of clear and relevant guidelines to do so, resulting in poor quality studies. To overcome these research community challenges and leverage modern research opportunities, this paper presents Socio-Technical Grounded Theory (STGT) designed to ease application and achieve quality outcomes. It defines what exactly is meant by an ST research context and presents the STGT guidelines that expand GT's philosophical foundations, provide increased clarity and flexibility in its methodological steps and procedures, define possible scope and contexts of application, encourage frequent reporting of a variety of interim, preliminary, and mature outcomes, and introduce nuanced evaluation guidelines for different outcomes. It is hoped that the SE research community and related ST disciplines such as computer science, data science, artificial intelligence, information systems, human computer/robot/AI interaction, human-centered emerging technologies (and increasingly other disciplines being transformed by rapid digitalisation and AI-based augmentation), will benefit from applying STGT to conduct quality research studies and systematically produce rich findings and mature theories with confidence.},
  keywords={Guidelines;Data collection;Software engineering;Tools;Systematics;Sociology;Encoding;Socio-technical grounded theory;STGT;grounded theory;GT;software engineering;research method;theory;theory development;qualitative research;data analysis;guidelines;evaluation},
  doi={10.1109/TSE.2021.3106280},
  ISSN={1939-3520},
  month={Oct},}@INPROCEEDINGS{9628966,
  author={Ayad, Anfal and Hammal, Youcef},
  booktitle={2021 International Conference on Networking and Advanced Systems (ICNAS)}, 
  title={An Efficient Authenticated Group Key Agreement Protocol for Dynamic UAV Fleets in Untrusted Environments}, 
  year={2021},
  volume={},
  number={},
  pages={1-8},
  abstract={Unmanned aerial vehicle (UAV) fleets are the focus of various nations nowadays. Thus, it is expected to witness an explosion of reliability and safety critical UAV-based applications. Moreover, the recent surge of research on applied artificial intelligence and the industry advancement encourage the use of cooperative UAV fleets that offer potential collaborations even between UAVs from different organizations. The untrusted nature of the operation environments in addition to the high level of criticality of such applications require stringent secure protocols. There have been several security protocol proposals to ensure authentication, confidentiality and integrity, yet the overhead generated by these solutions and their impact on performance still severely hamper UAV endurance. In this paper, we propose to tackle the problem of secure communications within dynamic UAV fleets in open public networks using a pairing free Certificateless-Authenticated Group Key Agreement (CL-AGKA) scheme with constant rounds that meets efficiency and strong security. The formal security validation of the proposed protocol has been done by using Automated Validation of Internet Security Protocols and Applications tool (AVISPA). The aforementioned tool revealed that the proposed protocol is resilient against several attacks. More important, the computation cost has been significantly reduced thanks to the elimination of the expensive pairing operations and to the integration of the signature scheme into the key agreement to build one efficient algorithm.},
  keywords={Protocols;Organizations;Tools;Autonomous aerial vehicles;Safety;Security;Reliability;UAVs;CL-AGKA;AVISPA;privacy;authentication},
  doi={10.1109/ICNAS53565.2021.9628966},
  ISSN={},
  month={Oct},}@ARTICLE{10388323,
  author={Jain, Garima and Kumar, Arun and Bhat, Shahid Ahmad},
  journal={IEEE Access}, 
  title={Recent Developments of Game Theory and Reinforcement Learning Approaches: A Systematic Review}, 
  year={2024},
  volume={12},
  number={},
  pages={9999-10011},
  abstract={In the ever-changing world of decision-making, when game theory and reinforcement learning(RL) come together, they create a fascinating combination that shows a new way to solve complex problems in many fields. The combination of game theory and RL is a powerful convergence that opens up a hopeful new frontier for dealing with complex decision-making problems in many different fields. Research on the convergence of game theory and RL has shown to be beneficial, providing essential insights into challenging decision-making issues in various disciplines. This study investigates the recent developments of game theory and RL approaches through a systematic review and highlights the significance of game theory in boosting reinforcement algorithms and increasing the interaction of autonomous vehicles, safeguarding edge caching, and more. It offers a thorough account of the developments at the confluence of game theory and RL. The reviewed papers mainly focus on broad themes and address three important research questions: the impact of game theory on multi-agent reinforcement learning (MARL), the significant contributions of game theory to RL, and the significant impact areas. Following the methodology, search outcomes, and study areas is a discussion on game theory-related terminology, followed by study findings. The review’s conclusions offer ideas for further study and open research questions. The importance of game theory in advancing MARL, the potential of game theory in promoting RL strategies, and the opportunities for combining game theory and RL in cutting-edge fields like mobile edge caching and cyber-physical systems(CPS) are all emphasized in the conclusion. This review article advances our knowledge of the theoretical underpinnings and real-world applications of game theory and RL, laying the groundwork for future improvements in decision-making techniques and algorithms.},
  keywords={Game theory;Reinforcement learning;Behavioral sciences;Autonomous vehicles;Terminology;Table lookup;Multi-agent systems;Decision making;Cache storage;Game theory;reinforcement learning;multi-agent reinforcement learning;decision-making;autonomous vehicles;edge caching;cyber-physical systems},
  doi={10.1109/ACCESS.2024.3352749},
  ISSN={2169-3536},
  month={},}@ARTICLE{10328771,
  author={Wu, Jieping and Huang, Junsong and Yang, Xiaoqin and Su, Piqiang and Zou, Jiahao and Yu, Wenping and Wang, Ziqiang},
  journal={IEEE Access}, 
  title={Design of Wood Moisture Assessment and Detection Sensors Based on Spoof Surface Plasmon Polaritons}, 
  year={2023},
  volume={11},
  number={},
  pages={135575-135582},
  abstract={Accurate moisture content detection is crucial for maintaining the quality and value of wood, as it can prevent shrinkage and swelling. The microwave method is a non-destructive, contactless detection technique for objects, which has been widely studied. This article presents a method for detecting moisture content in wood using Spoof surface plasmon polaritons (SSPPs) and a detachable sensor structure. The sensor can load removable label wood blocks to achieve detection of moisture content in various types of wood. Simulation experiment results demonstrate that the sensor has a fixed cut-off frequency when the label block is fixed. The cut-off frequency decreases if the moisture content of tested is higher than that of the label block, indicating that the proposed method is effective for screening wood that does not meet moisture content standards, on the contrary, the cut-off frequency does not generate offsets. The proposed detection method and system are feasible, and this research has practical applications in the field of wood processing.},
  keywords={Sensors;Microwave theory and techniques;Permittivity;Cutoff frequency;Surface waves;Electromagnetic scattering;Surface plasmons;Moisture measurement;Cut-off frequency;microwave transmission method;spoof surface plasmon polaritons (SSPPs);wood moisture content},
  doi={10.1109/ACCESS.2023.3336812},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10543787,
  author={Talha, Abdul and Dhanasree, Ch. and Divya, E. and Prabhas, Kandagatla Srikar and Syed Abudhagir, U},
  booktitle={2024 10th International Conference on Communication and Signal Processing (ICCSP)}, 
  title={Performance Evaluation of Deep Learning Models for Alzheimer’s Disease Detection}, 
  year={2024},
  volume={},
  number={},
  pages={317-322},
  abstract={Alzheimer's disease (AD) presents as a neurodegenerative condition characterized by dementia, impacting cognitive function, memory, and behavior. Swift identification is crucial for effective intervention and better patient outcomes. This research aims to tackle this urgent need by harnessing deep learning techniques to advance early AD detection. By merging magnetic resonance imaging (MRI) with advanced deep learning algorithms, the objective is to create a precise, non-invasive approach for early AD diagnosis. The primary goal is to uncover new features and significantly boost the accuracy of AD detection. The method involves examining convolutional neural networks alongside MRI scans to reveal patterns indicative of AD progression. Notably, the proposed model achieves impressive evaluation metrics: 99.19% accuracy, 0.023% loss, 99.08% f1-score, and 99.11% precision. This endeavor seeks to demonstrate substantial advancements in AD detection accuracy compared to existing methods. Through this interdisciplinary approach, the aim is to drive progress in early AD diagnosis, ultimately leading to more effective interventions and enhanced quality of life for those impacted by this challenging condition accuracy compared to existing methods.},
  keywords={Deep learning;Performance evaluation;Magnetic resonance imaging;Merging;Signal processing algorithms;Signal processing;Feature extraction;Deep learning;image classification;Alzheimer’s Disease;A Convolutional Neural Network;Magnetic Resonance Imaging},
  doi={10.1109/ICCSP60870.2024.10543787},
  ISSN={2836-1873},
  month={April},}@INPROCEEDINGS{8999111,
  author={AlQahtani, Amal and Kayi, Efsun and Diab, Mona},
  booktitle={2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA)}, 
  title={Understanding Cohesion in Writings and Speech of Schizophrenia Patients}, 
  year={2019},
  volume={},
  number={},
  pages={364-369},
  abstract={Schizophrenia is one of the mental disorders that impacts a person's thinking, speech, and actions. It can reduce a person's ability to process auditory information and make decisions. Analyzing this disorder correctly is important because it might help with different ways of reducing its negative effects on its patients. Linguists and psychiatrists have been investigating language impairments and speech disorder in people with schizophrenia disorder which can be challenging. In this study, we attempt to address this issue by analyzing linguistic features i.e. cohesion in the writings and speech scripts of schizophrenia patients. Our results show that using referential cohesion with text easability or situation model features provides the best performance for speech whereas for writing dataset, readability or a combination of situation model and readability yield the best performance.},
  keywords={Linguistics;Writing;Coherence;Tools;Mental disorders;Syntactics;Standards;Schizophrenia;Machine-Learning-Algorithms;Binary-Classification;Coherence;Cohesion;Coh-Metrix},
  doi={10.1109/ICMLA.2019.00068},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10365931,
  author={Zhou, Tong and Chen, Xuhang and Shen, Yanyan and Nieuwoudt, Martin and Pun, Chi-Man and Wang, Shuqiang},
  booktitle={2023 IEEE International Symposium on Product Compliance Engineering - Asia (ISPCE-ASIA)}, 
  title={Generative AI Enables EEG Data Augmentation for Alzheimer’s Disease Detection Via Diffusion Model}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Electroencephalography (EEG) is a non-invasive method to measure the electrical activity of the brain and can be regarded as an effective means of diagnosing Alzheimer’s disease (AD). However, The diagnosis of AD based on EEG often encounters the problem of data scarcity. For deep learning models, data scarcity problems lead to overfitting of the model, making it impossible to build effective, highly accurate, and stable models. Data augmentation is often used as an effective means to solve the problem of data scarcity. In this paper, we propose a diffusion models-based EEG data augmentation framework (Diff-EEG). The proposed framework Vector Quantized Variational autoencoders(VQ-VAE) and guided diffusion models to learn the distribution of limited EEG dataset, thereby generating high-quality artificially synthesized EEG data to supplement the dataset. Finally, the result of experiments demonstrate that our proposed method can generate high-quality artificial EEG data, which can effectively improve the performance of AD diagnosis models.},
  keywords={Continuous wavelet transforms;Vector quantization;Electric variables measurement;Brain modeling;Data augmentation;Feature extraction;Electroencephalography;EEG augmentation;Brain disorder;diffusion models;Brain-computer interface},
  doi={10.1109/ISPCE-ASIA60405.2023.10365931},
  ISSN={2831-3410},
  month={Nov},}@INPROCEEDINGS{10039758,
  author={George, Godwin and Rajan, Rajeev},
  booktitle={2022 IEEE 19th India Council International Conference (INDICON)}, 
  title={A FAISS-based Search for Story Generation}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Stories have the power to change human perspectives and have applications in game development and film making. An intelligent system can generate appropriate stories for a set of keywords. We aim to build a system capable of getting stories by providing keywords as input. The stories must have a relation with the input keyword. We experimented with the ROCStory dataset. The preprocessed data are encoded using a sentence transformer, called msmarco-distilbert-base-prod-v3. We relied on a search approach based on Facebook AI Similarity Search (FAISS) to generate appropriate stories. The output story has been converted to audio via pyttsx3. The performance of the proposed model is compared with that of the sentence transformer paraphrase-MiniLM-L6-v2 approach. We made a subjective evaluation. The results show that the proposed approach outperforms the baseline method.},
  keywords={Social networking (online);Games;Transformers;Search problems;Intelligent systems;Story generation;Search;text-to-speech conversion;FAISS;Sentence transformers;natural language processing},
  doi={10.1109/INDICON56171.2022.10039758},
  ISSN={2325-9418},
  month={Nov},}@INPROCEEDINGS{10665168,
  author={Brantley, Angela and Herbert, Katherine G. and Anu, Vaibhav K. and Hagiwara, Sumi and Robila, Stefan A. and Wang, Jason T.L.},
  booktitle={2024 IEEE Integrated STEM Education Conference (ISEC)}, 
  title={Understanding Space Weather Through Storytelling Data Visualization}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={Many students have difficulty understanding graphs. It may not be that they are not interested in what can be learned from a graph, rather how information is presented in a graph can be confusing. The project will focus on utilizing graphic design principles to create visual representations that effectively communicate the complex and nature of space weather. Through the incorporation of scientific data and research on solar activities, students will employ design elements such as layout, color theory, typography, and illustration to represent the various aspects of solar weather. The primary goal of this project is to create a simpler way to communicate information using visuals to understand the effect of solar activities on our planet. By merging scientific knowledge with creative design skills, students are encouraged to create informative and visually compelling materials such as infographics, posters, animations, and interactive digital media through an app. These visual representations will aim to clarify the causes, consequences, and predictive measures related to solar weather events.},
  keywords={Visualization;Navigation;Image color analysis;Merging;Layout;Data visualization;Collaboration;Artificial Intelligence;Data Visualization;Graph literacy;Space weather;Storytelling},
  doi={10.1109/ISEC61299.2024.10665168},
  ISSN={2473-7623},
  month={March},}@INPROCEEDINGS{10723544,
  author={Xie, Xin and Cui, Rongyu and Fan, Long and Yang, Xiaoli},
  booktitle={2024 4th International Conference on Big Data Engineering and Education (BDEE)}, 
  title={Large Language Models Enhanced Client Simulation and Feedback System for Insurance Advisors}, 
  year={2024},
  volume={},
  number={},
  pages={7-12},
  abstract={Traditionally, training insurance advisors to improve their sales skills has been challenging. This has often involved static methods such as script memorization and workshops, which lack personalization and fail to adequately replicate real-world client interactions. To address this issue, we developed an innovative training system that utilizes large language models (LLMs) to create intelligent agents that simulate difficult client interactions and provide evaluative feedback. Our system comprises three agents: two that simulate difficult client scenarios in telephone and face-to-face settings, and one that functions as an evaluator, providing feedback and suggestions for improvement. We collected and annotated over 1,000 real sales interaction recordings to train these agents, creating a comprehensive dataset. The system was tested with 50 insurance advisors, resulting in significant improvements in sales success rates, client satisfaction scores, advisor confidence levels, and response times compared to traditional training methods. This study underscores the effectiveness of LLMs in providing personalized, realistic, and immediate training experiences, highlighting their potential to revolutionize training methodologies in the insurance industry.},
  keywords={Training;Large language models;System performance;Insurance;System integration;Telephone sets;Data models;Recording;Time factors;Intelligent agents;Large Language Models;Insurance Advisor Training;Intelligent Tutoring Systems;Customer Interaction Simulation;AI in Finance;Large Language Models},
  doi={10.1109/BDEE63226.2024.00009},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10889367,
  author={Wang, Luoyu and Tao, Yitian and Yang, Qing and Liang, Yan and Liu, Siwei and Shi, Hongcheng and Shen, Dinggang and Zhang, Han},
  booktitle={ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Revolutionizing Disease Diagnosis with simultaneous functional PET/MR and Deeply Integrated Brain Metabolic, Hemodynamic, and Perfusion Networks}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Simultaneous functional PET/MR (sf-PET/MR) presents a cutting-edge multimodal neuroimaging technique. It provides an unprecedented opportunity for concurrently monitoring and integrating multifaceted brain networks built by spatiotemporally covaried metabolic activity, neural activity, and cerebral blood flow (perfusion). Albeit high scientific/clinical values, short in hardware accessibility of PET/MR hinders its applications, let alone modern AI-based PET/MR fusion models. Our objective is to develop a clinically feasible AI-based disease diagnosis model trained on comprehensive sf-PET/MR data with the power of, during inferencing, allowing single modality input (e.g., PET only) as well as enforcing multimodal-based accuracy. To this end, we propose MX-ARM, a multimodal MiXture-of-experts Alignment and Reconstruction Model. It is modality detachable and exchangeable, allocating different multi-layer perceptrons dynamically ("mixture of experts") through learnable weights to learn respective representations from different modalities. Such design will not sacrifice model performance in uni-modal situation. To fully exploit the inherent complex and nonlinear relation among modalities while producing fine-grained representations for uni-modal inference, a modal alignment module is utilized to line up a dominant modality (e.g., PET) with representations of auxiliary modalities (MR). We further adopt multimodal reconstruction to promote the quality of learned features. Experiments on precious multimodal sf-PET/MR data for Mild Cognitive Impairment diagnosis showcase the efficacy of MX-ARM toward clinically feasible precision medicine.},
  keywords={Accuracy;Precision medicine;Signal processing;Brain modeling;Resonance;Hemodynamics;Spatiotemporal phenomena;Medical diagnosis;Speech processing;Image reconstruction;Positron Emission Tomography (PET);Magnetic Resonance Imaging (MRI);Alzheimer’s disease (AD);brain connectome;early diagnosis and modal alignment},
  doi={10.1109/ICASSP49660.2025.10889367},
  ISSN={2379-190X},
  month={April},}@ARTICLE{10078389,
  author={Turner, Stephen W. and Karakus, Murat and Guler, Evrim and Uludag, Suleyman},
  journal={IEEE Access}, 
  title={A Promising Integration of SDN and Blockchain for IoT Networks: A Survey}, 
  year={2023},
  volume={11},
  number={},
  pages={29800-29822},
  abstract={The state of computer network technologies has continually advanced at a rapid pace. Software Defined Networking (SDN) and Blockchain (BC) have emerged as complementary technologies providing support that facilitates greater security and greater network performance for many domains of application, including the Internet of Things (IoT) ecosystem, ideally resulting in an improvement to our collective quality of life. The proliferation of IoT devices is driven by a wide variety of use cases and by their ubiquitous availability. When combined with the emergence of SDN and BC, this environment presents rich opportunities for various emerging research efforts and provides a motivation for this paper. Here, we present a comprehensive survey of the studies in which BC and SDN have been integrated into the IoT ecosystem, referred to hereafter as BC-enabled Software-Defined IoT (BC-SDIoT). The paper first discusses the motivations and drivers for integrating BC-enabled SDN and BC-SDIoT, as well as their benefits and drawbacks. Second, we categorize the relevant studies according to six key implementation objectives and ideas that combine BC, SDN, and IoT technologies to create smart, secure, and effective frameworks: Security, computing paradigms (edge and fog computing), trust management, access control & authentication, privacy, and networking. In the corresponding sections, we present the categories (i.e., problem domains) of the aforementioned novel taxonomy and discuss related studies (i.e., solutions) in depth. Finally, we outline potential major challenges, open issues, and future prospects that require further research attention and intensive endeavors for complete and ground-breaking frameworks to broaden newer research domains in BC-SDIoT. This survey paper may serve as a fruitful primer for the reader investigating the exploitation of BC in SDN and IoT ecosystems.},
  keywords={Internet of Things;Security;Blockchains;Organizations;Ecosystems;Trust management;Taxonomy;Blockchain;IoT;SDN;survey;BC-SDIoT},
  doi={10.1109/ACCESS.2023.3260777},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9458931,
  author={Myrtakis, Nikolaos and Tsamardinos, Ioannis and Christophides, Vassilis},
  booktitle={2021 IEEE 37th International Conference on Data Engineering (ICDE)}, 
  title={PROTEUS: Predictive Explanation of Anomalies}, 
  year={2021},
  volume={},
  number={},
  pages={1967-1972},
  abstract={Numerous algorithms have been proposed for detecting anomalies (outliers, novelties) in an unsupervised manner. Unfortunately, it is not trivial, in general, to understand why a given sample (record) is labelled as an anomaly and thus diagnose its root causes. We propose the following reduced-dimensionality, surrogate model approach to explain detector decisions: approximate the detection model with another one that employs only a small subset of features. Subsequently, samples can be visualized in this low-dimensionality space for human understanding. To this end, we develop PROTEUS, an AutoML pipeline to produce the surrogate model, specifically designed for feature selection on imbalanced datasets. The PROTEUS surrogate model can not only explain the training data, but also the out-of-sample (unseen) data. In other words, PROTEUS produces predictive explanations by approximating the decision surface of an unsupervised detector. PROTEUS is designed to return an accurate estimate of out-of-sample predictive performance to serve as a metric of the quality of the approximation. Computational experiments confirm the efficacy of PROTEUS to produce predictive explanations for different families of detectors and to reliably estimate their predictive performance in unseen data. Unlike several ad-hoc feature importance methods, PROTEUS is robust to high-dimensional data.},
  keywords={Measurement;Conferences;Pipelines;Training data;Data visualization;Detectors;Feature extraction;Anomaly Explanation;Predictive Explanation;Anomaly Interpretation;Explainable AI},
  doi={10.1109/ICDE51399.2021.00185},
  ISSN={2375-026X},
  month={April},}@INPROCEEDINGS{10526013,
  author={Velkumar, K and Chokkalingam, Bala Subramanian and Solairaj, Dr A and Vignesh, L.S},
  booktitle={2023 International Conference on New Frontiers in Communication, Automation, Management and Security (ICCAMS)}, 
  title={Alzheimer’s disease detection using Multi Atlas Segmentation based on Temporal Group Sparse Regression}, 
  year={2023},
  volume={1},
  number={},
  pages={1-13},
  abstract={Imaging genomics stands as a valuable approach for identifying potential genetic factors associated with Alzheimer’s disease (AD) within genomic and imaging datasets. Most existing techniques in imaging genomics employ a linear model to investigate the connection between quantitative traits (QTs) derived from brain imaging and genetic data (single nucleotide polymorphisms). This method often fails to consider the connections between clusters of Quantitative Traits (QTs) and Single Nucleotide Polymorphisms (SNPs), as well as the complex interactions which involves longitudinal imaging quantitative traits and Single Nucleotide Polymorphisms. In order to tackle these constraints, we introduce a fresh approach named Temporal Group Sparsity Regression and Additive Model (TGSRAM). This pioneering technique strives to reveal associations between longitudinal imaging QTs and SNPs, with the objective of pinpointing potential biomarkers for Alzheimer’s Disease (AD). Our approach seeks to offer solutions to these challenges. Furthermore, we introduce an alternative methodology termed multi-atlas-based morphometry in our study. This methodology assesses morphometric representations of the same image across numerous atlas spaces. By generating representations from various atlases, we harness supplementary insights to distinguish between different groups and mitigate the adverse impacts stemming from registration errors. In practice, each subject under investigation undergoes registration to multiple atlases, from which adaptive regional features are extracted. Subsequently, a correlation and relevance-based approach is employed to collectively select features from diverse atlases. This is followed by the ultimate classification step using the hybrid support vector machine (HSVM).},
  keywords={Support vector machines;Neuroimaging;Correlation;Imaging;Genomics;Feature extraction;Data models;QT;T-GSRAM;AD;HSVM},
  doi={10.1109/ICCAMS60113.2023.10526013},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9840649,
  author={Mehmed, Ayhan and Čaušević, Aida and Steiner, Wilfried and Punnekkat, Sasikumar},
  booktitle={2022 IEEE Zooming Innovation in Consumer Technologies Conference (ZINC)}, 
  title={Early Concept Evaluation of a Runtime Monitoring Approach for Safe Automated Driving}, 
  year={2022},
  volume={},
  number={},
  pages={53-58},
  abstract={Being used in key features, such as sensing and intelligent path planning, Artificial Intelligence (AI) has become an inevitable part of automated vehicles (AVs). However, their usage in the automotive industry always comes with a “label” that questions their impact on the overall AV safety. This paper focuses on the safe deployment of AI-based AVs. Among the various ways for ensuring the safety of AI-based AVs is to monitor the safe execution of the system responsible for automated driving (i.e., Automated Driving System (ADS)) at runtime (i.e., runtime monitoring). Most of the research done in the past years focused on verifying whether the path or trajectory generated by the ADS does not immediately collide with objects on the road. However, as we will show in this paper, there are other unsafe situations that do not immediately result in a collision but the monitor should check for them. To build our case, we have looked into the National Highway Traffic Safety Administration (NHTSA) database of 5.9 million police-reported light-vehicle accidents and categorized these accidents into five main categories of unsafe vehicle operations. Furthermore, we have performed a high-level evaluation of the runtime monitoring approach proposed in [1], by estimating what percentage of the total population of 5.9 million of unsafe operations the approach would be able to detect. Lastly, we have performed the same evaluation on other existing runtime monitoring approaches to make a basic comparison of their diagnostic capabilities.},
  keywords={Runtime;Roads;Time measurement;Safety;Trajectory;Artificial intelligence;Vehicle dynamics},
  doi={10.1109/ZINC55034.2022.9840649},
  ISSN={},
  month={May},}@INPROCEEDINGS{8683727,
  author={Kong, Qiuqiang and Xu, Yong and Iqbal, Turab and Cao, Yin and Wang, Wenwu and Plumbley, Mark D.},
  booktitle={ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Acoustic Scene Generation with Conditional Samplernn}, 
  year={2019},
  volume={},
  number={},
  pages={925-929},
  abstract={Acoustic scene generation (ASG) is a task to generate waveforms for acoustic scenes. ASG can be used to generate audio scenes for movies and computer games. Recently, neural networks such as SampleRNN have been used for speech and music generation. However, ASG is more challenging due to its wide variety. In addition, evaluating a generative model is also difficult. In this paper, we propose to use a conditional SampleRNN model to generate acoustic scenes conditioned on the input classes. We also propose objective criteria to evaluate the quality and diversity of the generated samples based on classification accuracy. The experiments on the DCASE 2016 Task 1 acoustic scene data show that with the generated audio samples, a classification accuracy of 65.5% can be achieved compared to samples generated by a random model of 6.7% and samples from real recording of 83.1%. The performance of a classifier trained only on generated samples achieves an accuracy of 51.3%, as opposed to an accuracy of 6.7% with samples generated by a random model.},
  keywords={acoustic scene generation;SampleRNN;recurrent neural network;generative model},
  doi={10.1109/ICASSP.2019.8683727},
  ISSN={2379-190X},
  month={May},}@INPROCEEDINGS{9939271,
  author={Halilaj, Lavdim and Luettin, Juergen and Henson, Cory and Monka, Sebastian},
  booktitle={2022 IEEE Fifth International Conference on Artificial Intelligence and Knowledge Engineering (AIKE)}, 
  title={Knowledge Graphs for Automated Driving}, 
  year={2022},
  volume={},
  number={},
  pages={98-105},
  abstract={Automated Driving (AD) datasets, when used in combination with deep learning techniques, have enabled significant progress on difficult AD tasks such as perception, trajectory prediction and motion planning. These datasets represent the content of driving scenes as captured by various sensors, including cameras, RADAR, and LiDAR, along with 2D/3D annotations of traffic participants. Such datasets, however, often fail to capture and to represent the spatial, temporal, functional, and semantic relations between entities in a scene. This lack of knowledge leads to a shallow understanding of the true complexity and dynamics inherent in a driving scene. In this paper, we argue that a knowledge graph based representation of driving scenes, that provides a richer structure and semantics, will lead to further improvements in automated driving. Towards this goal, we developed a layered architecture and ontologies for specific automated driving datasets and a fundamental ontology of shared concepts. We also built knowledge graphs (KG) for three different AD datasets. We perform an analysis w.r.t. information contained in the AD KGs and outline how the additional semantic information contained in the KGs could improve the performance of different AD tasks. Moreover, example queries are provided to retrieve relevant information that can be exploited for augmenting the AD pipelines. All artefacts needed for reproducability purposes are provided via a Dropbox folder11shorturl.at/iwyCV - we will go through an internal approval process for making all artefacts publicly available. We removed our internal namespaces of reused ontologies, because of confidentiality and to provide self-contained ontologies. As the original datasets are under specific licences we can not publish the KGs themselves, but we provided the scripts to generate them.},
  keywords={Knowledge engineering;Training;Semantics;Pipelines;Training data;Ontologies;Trajectory;Knowledge Graphs;Automated Driving Datasets;Ontologies},
  doi={10.1109/AIKE55402.2022.00023},
  ISSN={2831-7203},
  month={Sep.},}@INPROCEEDINGS{10447380,
  author={Chung, Yoonjin and Lee, Junwon and Nam, Juhan},
  booktitle={ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={T-Foley: A Controllable Waveform-Domain Diffusion Model for Temporal-Event-Guided Foley Sound Synthesis}, 
  year={2024},
  volume={},
  number={},
  pages={6820-6824},
  abstract={Foley sound, audio content inserted synchronously with videos, plays a critical role in the user experience of multimedia content. Recently, there has been active research in Foley sound synthesis, leveraging the advancements in deep generative models. However, such works mainly focus on replicating a single sound class or a textual sound description, neglecting temporal information, which is crucial in the practical applications of Foley sound. We present T-Foley, a Temporal-event-guided waveform generation model for Foley sound synthesis. T-Foley generates high-quality audio using two conditions: the sound class and temporal event feature. For temporal conditioning, we devise a temporal event feature and a novel conditioning technique named Block-FiLM. T-Foley achieves superior performance in both objective and subjective evaluation metrics and generates Foley sound well-synchronized with the temporal events. Additionally, we showcase T-Foley’s practical applications, particularly in scenarios involving vocal mimicry for temporal event control. We show the demo on our companion website.1},
  keywords={Measurement;Streaming media;Signal processing;Controllability;User experience;Acoustics;Usability;Foley Sound Synthesis;Controllable Sound Generation;General Audio Synthesis;Waveform Domain Diffusion},
  doi={10.1109/ICASSP48485.2024.10447380},
  ISSN={2379-190X},
  month={April},}@ARTICLE{10064160,
  author={Hussain, Muhammad Ishfaq and Rafique, Muhammad Aasim and Kim, Joonmo and Jeon, Moongu and Pedrycz, Witold},
  journal={IEEE Transactions on Neural Systems and Rehabilitation Engineering}, 
  title={Artificial Proprioceptive Reflex Warning Using EMG in Advanced Driving Assistance System}, 
  year={2023},
  volume={31},
  number={},
  pages={1635-1644},
  abstract={A frequent cause of auto accidents is disregarding the proximal traffic of an ego-vehicle during lane changing. Presumably, in a split-second-decision situation we may prevent an accident by predicting the intention of a driver before her action onset using the neural signals data, meanwhile building the perception of surroundings of a vehicle using optical sensors. The prediction of an intended action fused with the perception can generate an instantaneous signal that may replenish the driver’s ignorance about the surroundings. This study examines electromyography (EMG) signals to predict intention of a driver along perception building stack of an autonomous driving system (ADS) in building an advanced driving assistant system (ADAS). EMG are classified into left-turn and right-turn intended actions and lanes and object detection with camera and Lidar are used to detect vehicles approaching from behind. A warning issued before the action onset, can alert a driver and may save her from a fatal accident. The use of neural signals for intended action prediction is a novel addition to camera, radar and Lidar based ADAS systems. Furthermore, the study demonstrates efficacy of the proposed idea with experiments designed to classify online and offline EMG data in real-world settings with computation time and the latency of communicated warnings.},
  keywords={Vehicles;Electromyography;Automobiles;Sensors;Accidents;Laser radar;Cameras;Intended action prediction;ADAS;ADS;EMG;intelligent vehicle;intelligent transportation},
  doi={10.1109/TNSRE.2023.3254151},
  ISSN={1558-0210},
  month={},}@ARTICLE{10804108,
  author={Chen, Jiao and He, Jiayi and Chen, Fangfang and Lv, Zuohong and Tang, Jianhua and Jia, Yunjian},
  journal={IEEE Internet of Things Journal}, 
  title={Empowering IoT-Based Autonomous Driving via Federated Instruction Tuning With Feature Diversity}, 
  year={2025},
  volume={12},
  number={6},
  pages={6095-6108},
  abstract={Integrating large language models (LLMs) with the Internet of Things (IoT) offer great potential for enhancing vehicle personalization and adaptability in autonomous driving (AD), particularly in open-world scenarios. However, the increasing scarcity of high-quality public data poses a challenge, which could hinder the progress of LLMs in AD. To address this, we propose a novel approach, federated instruction tuning (FIT), that leverages federated learning (FL) to enable collaborative training of a shared model across multiple data owners without sharing raw data, thereby preserving privacy and mitigating data scarcity. Complementing FIT, we introduce a feature diversity (FD) strategy that enriches visual and textual diversity and significantly expands AD data by generating new instruction-following data across key dimensions, such as time, weather, and occlusion. Extensive experiments using LLaMA-Adapter as the base model and four FL methods validate the effectiveness of the FIT framework and the FD strategy. Our analysis also compares LLMs ranging from 1.1 to 7B parameters, with results evaluated using GPT score, demonstrating the potential of FIT in AD. Our findings suggest that FIT and FD can support intelligent network operation and optimization in IoT, benefiting both the AD and artificial intelligence (AI) industries.},
  keywords={Data models;Internet of Things;Training;Autonomous vehicles;Tuning;Decision making;Adaptation models;Visualization;Sensors;Data privacy;Autonomous driving (AD);federated learning (FL);instruction tuning;Internet of Things (IoT);large language models (LLMs)},
  doi={10.1109/JIOT.2024.3518615},
  ISSN={2327-4662},
  month={March},}@ARTICLE{10128120,
  author={Eyobu, Odongo Steven and Edwinah, Kamwesigye},
  journal={IEEE Access}, 
  title={A Deep Learning-Based Routing Approach for Wireless Mesh Backbone Networks}, 
  year={2023},
  volume={11},
  number={},
  pages={49509-49518},
  abstract={Optimal routing decisions are key in communication network environments to minimize bottlenecks such as traffic congestion and limited bandwidth. Routing in wireless mesh backbone networks is the focus of this study given that they are popular particularly for providing broadband connectivity to a huge number of users accessing and transmitting multimedia data hence are susceptible to communication-oriented bottlenecks. Existing routing solutions are mainly optimistic approaches. These mainly depend on link states, distance and hop counts which present a routing generalization bottleneck especially in huge wireless mesh networks because it is difficult to get the entire footprint of the network. Simply put, it is very difficult to determine an optimal route in a huge wireless mesh network (WMN) with dynamic network conditions. Since deep learning has a strong generalization ability. In this paper, a deep learning-based routing approach is proposed with the goal of ensuring a defined optimal quality of service (QoS) in a WMN. In order to achieve the study purpose, a wireless mesh network simulation environment is built and a network data feature set is orchestrated to generate a data set used to train a Long short Term Memory (LSTM)-based deep learning model that estimates the route with the optimal QoS. The generated data set is validated by training other learning models including the Multilayer Perceptron (MLP), Logistic Regression (LR) and Random Forest (RF). Our results show that the routes selected by the LSTM-based model provides the best packet delivery ratio (PDR) and throughput. Our results further show that the learning models (MLP, LR, RF) also provide better PDR and throughput compared to the traditional Ad-hoc On-demand Distance Vector (AODV) routing protocol.},
  keywords={Routing;Quality of service;Wireless communication;Routing protocols;Deep learning;Throughput;Delays;Wireless mesh networks;Deep learning;optimal route and wireless mesh network},
  doi={10.1109/ACCESS.2023.3277431},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10574705,
  author={Rani, S. Swapna and Mudigonda, Aditya and Hemanth, S V and Sundararajan, P.N. and Reddy, G. Vinoda and Amirthayogam, G.},
  booktitle={2024 3rd International Conference on Artificial Intelligence For Internet of Things (AIIoT)}, 
  title={Deep Learning based vehicle image detection using Yolo V5 with Region-Based Convolutional Neural Network}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Detecting and classifying vehicles is a modern technology with numerous uses. Administration and regulation of traffic is one of the primary uses. Projects utilizing image processing to prevent traffic accidents heavily rely on vehicle monitoring and detection. Monitoring and recording human movement in surveillance situations require the ability to follow moving objects. Considering its significance, it provides a valuable image processing-based vehicle detection technique—a vehicle tracking and detection system based on images. The recently released high-resolution road vehicle dataset supports deep learning-based vehicle detection and monitoring on the Python platform. It includes over 100 well-defined pictures taken from movies from various locations. This data is produced using a range of image processing methods. The most recent iteration of the YOLO model, the v5 model, was employed for detection. R-CNN is additionally utilized for model detection. The four stages in the Region-Based Convolutional Neural Network (RCNN) process are preprocessing, segmentation, feature selection, and classification. The first step is identifying moving vehicles accurately. Preprocessing the original image is necessary. This enhances the image’s quality, valuable information extracted, or unwanted areas cropped out. Segmentation is the second step. The region’s borders are established, and the entire image is divided into numerous smaller areas using a threshold. The vehicle image’s most pertinent aspects or characteristics (features) that aid in precise detection are found in the third stage, feature selection. A region-based convolutional neural network (RCNN) is employed to determine the categorization. The Yolov5 method can be used to identify and categorize items. The Region-based Convolutional Neural Network (RCNN) approach enhances accuracy and temporal complexity over current segmentation algorithms.},
  keywords={YOLO;Deep learning;Image segmentation;Accuracy;Surveillance;Transportation;Transforms;vehicles;Yolov5;feature selection;segmentation;Region-Based Convolutional Neural Network (RCNN);information;accuracy},
  doi={10.1109/AIIoT58432.2024.10574705},
  ISSN={},
  month={May},}@ARTICLE{9998054,
  author={Zhang, Zhiwei and Zhong, Yuhang and Guo, Junlong and Wang, Qianhao and Xu, Chao and Gao, Fei},
  journal={IEEE Robotics and Automation Letters}, 
  title={Auto Filmer: Autonomous Aerial Videography Under Human Interaction}, 
  year={2023},
  volume={8},
  number={2},
  pages={784-791},
  abstract={The advance of unmanned aerial vehicles (UAVs) has enabled customers and directors to film from the air. However, operating the drone to produce desired videos upon a moving object is hard to achieve. This letter proposes an autonomous aerial videography system that integrates customized shots and drone dynamics. We design a user-friendly interface for the operator to create the desired shot in real-time. The shot information is then transmitted to the kinodynamic path search process, in which a safe shooting path will be evaluated. Later, feasible regions and safe flight corridors are constructed for safety and visibility. Finally, a joint optimization is carried out to generate the trajectory of the quadrotor and the gimbal to maintain the required image composition. Extensive simulation and real-world experiments validate the effectiveness of our method. The supplementary video1 presents the results.},
  keywords={Drones;Videos;Cameras;Robots;Quadrotors;Planning;Safety;Aerial systems: applications;human-aware motion planning;aerial systems: perception and autonomy},
  doi={10.1109/LRA.2022.3231828},
  ISSN={2377-3766},
  month={Feb},}@ARTICLE{8718672,
  author={Zhou, Dongsheng and Feng, Xinzhu and Yi, Pengfei and Yang, Xin and Zhang, Qiang and Wei, Xiaopeng and Yang, Deyun},
  journal={IEEE Access}, 
  title={3D Human Motion Synthesis Based on Convolutional Neural Network}, 
  year={2019},
  volume={7},
  number={},
  pages={66325-66335},
  abstract={Human motion synthesis technology has a very important position in computer animation, and it is widely used in medicine, film and television, motion analysis, games, and other related fields. The synthesis of human motion is the virtual of the action of the characters in the real world, the authenticity of the action, and the natural smoothness is especially important to the user’s experience. Due to the complexity of human structure, how to generate a high-quality movement is a challenging task. The data used in this paper are all 3D human motion data in BioVision Hierarchical (BVH) format, which can be captured by optical, inertial, mechanical or other video-based motion capture devices. In this paper, first, a three-layer convolutional neural network was used to output mapping in the hidden unit of the input motion capture data. Then, a one-dimensional convolution auto-encoder was connected; meanwhile, the bone length constraint, position constraint, and trajectory constraint were added. It repaired the non-inertial joints of motion data and removed the motion artifacts. To achieve the synthesis of the two motions, we extracted the style transformation in the motion, added style and content constraints, and finally output the motion. To verify the feasibility of the algorithm, we obtained the animation effect of the synthesized motion by testing the input motion. The experimental results show that the motions synthesized by the proposed algorithm not only look natural smooth in visual effect but also reduce the time consumed by about 42.6% compared with the existing algorithms.},
  keywords={Hidden Markov models;Data models;Convolutional neural networks;Animation;Motion segmentation;Deep learning;Three-dimensional displays;Convolutional neural network;convolution auto-encoder;human motion capture data;motion synthesis},
  doi={10.1109/ACCESS.2019.2917609},
  ISSN={2169-3536},
  month={},}@ARTICLE{10504424,
  author={Pahk, Jinu and Park, Seongjeong and Shim, Jungseok and Son, Sungho and Lee, Jungki and An, Jinung and Lim, Yongseob and Choi, Gyeungho},
  journal={IEEE Robotics and Automation Letters}, 
  title={Lane Segmentation Data Augmentation for Heavy Rain Sensor Blockage Using Realistically Translated Raindrop Images and CARLA Simulator}, 
  year={2024},
  volume={9},
  number={6},
  pages={5488-5495},
  abstract={Lane segmentation and Lane Keeping Assist System (LKAS) play a vital role in autonomous driving. While deep learning technology has significantly improved the accuracy of lane segmentation, real-world driving scenarios present various challenges. In particular, heavy rainfall not only obscures the road with sheets of rain and fog but also creates water droplets on the windshield or lens of the camera that affects the lane segmentation performance. There may even be a false positive problem in which the algorithm incorrectly recognizes a raindrop as a road lane. Collecting heavy rain data is challenging in real-world settings, and manual annotation of such data is expensive. In this research, we propose a realistic raindrop conversion process that employs a contrastive learning-based Generative Adversarial Network (GAN) model to transform raindrops randomly generated using Python libraries. In addition, we utilize the attention mask of the lane segmentation model to guide the placement of raindrops in training images from the translation target domain (real Rainy-Images). By training the ENet-SAD model using the realistically Translated-Raindrop images and lane ground truth automatically extracted from the CARLA Simulator, we observe an improvement in lane segmentation accuracy in Rainy-Images. This method enables training and testing of the perception model while adjusting the number, size, shape, and direction of raindrops, thereby contributing to future research on autonomous driving in adverse weather conditions.},
  keywords={Rain;Image segmentation;Training;Mathematical models;Generative adversarial networks;Data augmentation;Computer vision;Robot vision systems;Computer vision for automation;data sets for robotic vision;simulation and animation},
  doi={10.1109/LRA.2024.3390587},
  ISSN={2377-3766},
  month={June},}
