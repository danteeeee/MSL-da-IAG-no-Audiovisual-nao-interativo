@INPROCEEDINGS{10656825,
  author={Liu, Yujian and Zhang, Yang and Jaakkola, Tommi and Chang, Shiyu},
  booktitle={2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Correcting Diffusion Generation Through Resampling}, 
  year={2024},
  volume={},
  number={},
  pages={8713-8723},
  abstract={Despite diffusion models' superior capabilities in modeling complex distributions, there are still non-trivial distributional discrepancies between generated and ground-truth images, which has resulted in several notable problems in image generation, including missing object errors in text-to-image generation and low image quality. Existing methods that attempt to address these problems mostly do not tend to address the fundamental cause behind these problems, which is the distributional discrepancies, and hence achieve sub-optimal results. In this paper, we propose a particle filtering framework that can effectively ad-dress both problems by explicitly reducing the distributional discrepancies. Specifically, our method relies on a set of ex-ternal guidance, including a small set of real images and a pre-trained object detector, to gauge the distribution gap, and then design the resampling weight accordingly to correct the gap. Experiments show that our methods can effectively correct missing object errors and improve image quality in various image generation tasks. Notably, our method outperforms the existing strongest baseline by 5% in object occurrence and 1.0 in FID on MS-COCO. Our code is available at https://github.com/UCSB-NLP-Chang/diffusion_resampling.git.},
  keywords={Image quality;Computer vision;Image synthesis;Filtering;Computational modeling;Text to image;Detectors;image generation;diffusion model;particle filtering},
  doi={10.1109/CVPR52733.2024.00832},
  ISSN={2575-7075},
  month={June},}@INPROCEEDINGS{10053146,
  author={Zhao, Jianjun and Chen, Yimin and Li, Xinyan},
  booktitle={2022 International Conference on Cloud Computing, Big Data and Internet of Things (3CBIT)}, 
  title={Word-level Textual Adversarial Attack Method Based On Differential Evolution Algorithm}, 
  year={2022},
  volume={},
  number={},
  pages={29-34},
  abstract={Deep neural networks are now widely used, but adversarial attack methods against deep neural networks are also proliferating, posing a significant security risk to deep learning. Adversarial attacks expose shortcomings of neural network, and for text it is also more challenging. Because text is discrete and cannot be optimized directly using gradients like images. Some existing word-level textual adversarial attack methods have achieved good performance, but there are still problems that the generated text is not of high enough quality or semantic bias. In this paper, we propose a model that combine the sememe-based word substitution method with the improved differential evolution algorithm to solve above problems. We have made a series of improvements to the differential evolution algorithm, including the use of dynamic cross-rates and scaling factors to enhance the search capability of the algorithm. The Metropolis criterion is also introduced to enhance the algorithm’s ability to explore the adversarial examples in the potential space. As a black-box attack method, the algorithm can attack without knowing the model’s interior. We tested the attack effectiveness of the model on benchmark datasets by attacking two victim models (BERT and BiLSTM). The experimental results shows that our model has higher attack success rate and higher quality of the adversarial examples than the baseline methods.},
  keywords={Deep learning;Cloud computing;Heuristic algorithms;Computational modeling;Neural networks;Semantics;Natural languages;natural language processing;textual adversarial attack;black box attack;artificial intelligence security;differential evolution algorithm},
  doi={10.1109/3CBIT57391.2022.00015},
  ISSN={},
  month={Oct},}@ARTICLE{10066260,
  author={Sharadqh, Ahmed A. M. and Hatamleh, Hazem Abdel Majid and Alnaser, As’ad Mahmoud As’ad and Saloum, Said S. and Alawneh, Tareq A.},
  journal={IEEE Access}, 
  title={Hybrid Chain: Blockchain Enabled Framework for Bi-Level Intrusion Detection and Graph-Based Mitigation for Security Provisioning in Edge Assisted IoT Environment}, 
  year={2023},
  volume={11},
  number={},
  pages={27433-27449},
  abstract={Internet of Things (IoT) is an emerging technology and its applications are flattering amidst many users, as it makes everything easier. As a consequence of its massive growth, security and privacy are becoming crucial issues where the IoT devices are perpetually vulnerable to cyber-attacks. To overcome this issue, intrusion detection and mitigation is accomplished which enhances the security in IoT networks. In this paper, we proposed Blockchain entrenched Bi-level intrusion detection and graph based mitigation framework named as HybridChain-IDS. The proposed work embrace four sequential processes includes time-based authentication, user scheduling and access control, bi-level intrusion detection and attack graph generation. Initially, we perform time-based authentication to authenticate the legitimate users using NIK-512 hashing algorithm, password and registered time are stored in Hybridchain which is an assimilation of blockchain and Trusted Execution Environment (TEE) which enhances data privacy and security. After that, we perform user scheduling using Cheetah Optimization Algorithm (COA) which reduces the complexity and then the access control is provided to authorized users by smart contract by considering their trust and permission level. Then, we accomplish bi-level intrusion detection using ResCapsNet which extracts sufficient features and classified effectively. Finally, risk of the attack is evaluated, and then the attacks graphs are generated by employing Enhanced k-nearest neighbor (KNN) algorithm to identify the attack path. Furthermore, the countermeasures are taken based on the attack risk level and the attack graph is stored in Hybridchain for eventual attack prediction. The implementation of this proposed work is directed by network simulator of NS-3.26 and the performance of the proposed HybridChain-IDS is enumerated based on various performance metrics.},
  keywords={Security;Internet of Things;Intrusion detection;Feature extraction;Network security;Blockchains;Authentication;IoT network security;hybrid chain;access control;intrusion detection system (IDS);attack graph generation;deep learning method},
  doi={10.1109/ACCESS.2023.3256277},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10866538,
  author={Menezes, Julian and G, Maheswari and S, Shiraj and M, Lakshmi Narasimha Rao and N, Deepak},
  booktitle={2024 1st International Conference on Sustainable Computing and Integrated Communication in Changing Landscape of AI (ICSCAI)}, 
  title={NLP-Powered Recommendation Engine with Flask Interface}, 
  year={2024},
  volume={},
  number={},
  pages={1-12},
  abstract={This project revolves around the development of a sophisticated Movie Recommendation Engine, propelled by the transformative impact of digitalization on the entertainment industry. The era of personalized, on-demand viewing experiences necessitates a solution to the paradox of choice faced by users amidst the vast content landscape. The Movie Recommendation Engine addresses this challenge, driven by the vision of creating a seamless and enjoyable viewing experience through personalized recommendations. The project goes beyond conventional recommendation algorithms, embracing a holistic approach to content discovery that introduces users to hidden gems and lesser-known titles within their preferred genres. Leveraging Natural Language Processing (NLP) technologies, the engine deciphers user preferences through sentiment analysis, ensuring nuanced insights from textual data. The deployment phase involves a Streamlit interface for an interactive user experience, showcasing personalized recommendations and fostering user engagement. The project's scope encompasses diverse cinematic tastes, promising a comprehensive solution for a global audience.},
  keywords={Training;Sentiment analysis;Accuracy;Entertainment industry;Propulsion;Motion pictures;User experience;Engines;Recommender systems;Testing;Movie Recommendation Engine;Digitalization;Personalized Viewing;Natural Language Processing (NLP);Streamlit Interface},
  doi={10.1109/ICSCAI61790.2024.10866538},
  ISSN={},
  month={July},}@INPROCEEDINGS{8847944,
  author={Canaan, Rodrigo and Togelius, Julian and Nealen, Andy and Menzel, Stefan},
  booktitle={2019 IEEE Conference on Games (CoG)}, 
  title={Diverse Agents for Ad-Hoc Cooperation in Hanabi}, 
  year={2019},
  volume={},
  number={},
  pages={1-8},
  abstract={In complex scenarios where a model of other actors is necessary to predict and interpret their actions, it is often desirable that the model works well with a wide variety of previously unknown actors. Hanabi is a card game that brings the problem of modeling other players to the forefront, but there is no agreement on how to best generate a pool of agents to use as partners in ad-hoc cooperation evaluation. This paper proposes Quality Diversity algorithms as a promising class of algorithms to generate populations for this purpose and shows an initial implementation of an agent generator based on this idea. We also discuss what metrics can be used to compare such generators, and how the proposed generator could be leveraged to help build adaptive agents for the game.},
  keywords={Games;Color;Generators;Sociology;Statistics;Measurement;Artificial intelligence},
  doi={10.1109/CIG.2019.8847944},
  ISSN={2325-4289},
  month={Aug},}@ARTICLE{10107475,
  author={Qiu, Yiqin and Tian, Hui and Li, Haizhou and Chang, Chin-Chen and Vasilakos, Athanasios V.},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={Separable Convolution Network With Dual-Stream Pyramid Enhanced Strategy for Speech Steganalysis}, 
  year={2023},
  volume={18},
  number={},
  pages={2737-2750},
  abstract={Steganography based on fixed codebook has become one of the most important branches of speech steganography due to its high imperceptibility and having the largest available carrier space. As its countermeasure technique, this paper presents a novel steganalysis method based on separable convolution network (SepSteNet) with dual-stream pyramid enhanced strategy (DPES). Specifically, to better acquire discriminative representations, we design the pulse-aware separable block to capture the pulse correspondence along independent levels of pulse positions, where the pulse-aware excitation module is plugged to avoid noisy clue accumulation by adaptively emphasizing the salient part. Moreover, the global attending block is introduced to enhance correspondence features through calculating global responses at distinct subframes. In addition, to eliminate the negative impact of sample content, DPES is leveraged to incorporate cross-domain coherence features by the inverted connected dual-stream branches. With the original and calibration speech samples, two branches enable the correspondence of two detection feature domains to interact with each other to generate coherence features independent of sample content, thereby improving the detection performance. The performance of the presented method is comprehensively evaluated and compared with the state of the arts. The experimental results demonstrate that the presented method significantly outperforms the existing ones. Furthermore, DPES is shown to be a general enhancement strategy that can effectively improve the performance of the existing deep neural network for speech steganalysis. The source code for this work is publicly available on https://github.com/BarryxxZ/SepSteNetwithDPES.},
  keywords={Feature extraction;Calibration;Convolution;Steganography;Speech coding;Coherence;Neural networks;Steganalysis;separable convolution;pulse position;dual-stream network;calibration},
  doi={10.1109/TIFS.2023.3269640},
  ISSN={1556-6021},
  month={},}@INPROCEEDINGS{10939891,
  author={Mahar, Alap and Verma, Pushpneel and Singh, Ajit},
  booktitle={2025 First International Conference on Advances in Computer Science, Electrical, Electronics, and Communication Technologies (CE2CT)}, 
  title={Detection of Quality Deep Fake Images and Videos Using Customised Convolutional Neural Networks}, 
  year={2025},
  volume={},
  number={},
  pages={620-625},
  abstract={Due to advancements in artificial intelligence there are numerous deep fake images and video collections are available on the Internet and social media. The primary aim of the study is to analyse the deep fake images and videos since the quality is constantly improving a novel method was developed for accurate detection of quality deep fakes. The suggested approach uses a customised convolutional neural network (CNN) technique that uses facial landmark detection to extract structured data from photos and video frames before feeding it into the methods of CNN. The customised CNN model is augment-based CNN for generation of fake images and fake data. Involves about 260 films from the data set in which 202 images are made up while others were real images. About 300 videos are used in which 250 videos are fake and 50 were real the proposed model achieved the accuracy of 95.58% and 0.97 AUC score that outperforms the existing models like MLP-CNN and CNN. Additionally, the method succeeds with greater accuracy then the conventional models like DST -Net, VGG 16 Efficient Net. This research study's primary goal is to create a new CNN learning method for identifying high-quality deep fake photos and videos.},
  keywords={Deepfakes;Accuracy;Social networking (online);Films;Vectors;Encoding;Spatial databases;Convolutional neural networks;Overfitting;Testing;deep fake images;video collections;customised CNN;facial landmark;Accurate;detection},
  doi={10.1109/CE2CT64011.2025.10939891},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10323845,
  author={Kumar, Shubham and Chauhan, Yogesh Singh and Amrouch, Hussam},
  booktitle={2023 IEEE/ACM International Conference on Computer Aided Design (ICCAD)}, 
  title={Invited Paper: Ultra-Efficient Edge AI Using FeFET-based Monolithic 3D Integration}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Monolithic three-dimensional (M3D) integration signifies a notable technological leap by providing solutions of high density and energy efficiency, particularly for ultra-efficient edge AI solutions. Among emerging technologies, ferroelectric thin-film transistors (FeTFTs) have attracted substantial interest due to their potential in neuromorphic computing and their compatibility with back-end-of-the-line (BEOL) fabrication processes. Nevertheless, the challenge of M3D integrated circuits lies in elevated temperatures resulting from limited heat dissipation across various stacked tiers, subsequently exerting adverse effects on system reliability. In this work, we explore how compute-in-memory (CIM) architectures can be realized using BEOL FeTFT to accelerate deep learning applications. We demonstrate how generated temperature impacts the reliability and ultimately degrade the inference accuracy. To achieve that, we have modified the open-source “3D+NeuroSim” framework to introduce FeTFT and then employed it to estimate the key figures of merit, such as throughput, power density, area, etc. Then, we perform a comprehensive thermal analysis for the simulated M3D architecture to explore how the DNN accuracy will be impacted due to the generated heat. We also demonstrate how FeTFT devices can be accurately modeled using TCAD simulations and how run-time variability (due to temperature effects) and design-time variability (due to process variation) impact the reliability of FeTFT transistors.},
  keywords={Performance evaluation;Heating systems;Temperature;Neuromorphic engineering;Computer architecture;Energy efficiency;Transistors},
  doi={10.1109/ICCAD57390.2023.10323845},
  ISSN={1558-2434},
  month={Oct},}@INPROCEEDINGS{10607225,
  author={Noor, Nur Qamarina Mohd and Zabidi, Azlee and Jaya, Mohd Izham Bin Mohd and Ler, Tan Jia},
  booktitle={2024 IEEE Symposium on Industrial Electronics & Applications (ISIEA)}, 
  title={Performance Comparison between Generative Adversarial Networks (GAN) Variants in Generating Anime/Comic Character Images - A Preliminary Result}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={In recent years, the popularity and demand for digital animation, specifically anime characters, has brought significant challenges and opportunities for the world of computer graphics and artificial intelligence. This research dives deep into the comprehensive exploration of two well-known Generative Adversarial Networks (GANs)— Deep Convolutional Generative Adversarial Network (DCGAN) and CycleGAN, — with a specific focus on anime character generation. GANs, consisting of a generator and discriminator, operate in a feedback loop to create and evaluate synthetic data. This research will identify challenges within each GAN model and develop objectives to address these challenges. Both of GAN models were mainly executed in the Google Colab environment to optimize the GPU-accelerated runtime. The dataset is sourced from publicly accessible anime image repositories and both GAN models will be evaluated using Fréchet Inception Distance (FID) and Inception Score (IS). FID compares the distribution of generated images with the distribution of a set of real images (“ground truth”) while IS only evaluates the distribution of generated images. Together, they provide a comprehensive evaluation of a GAN's performance. In the realm of anime character generation, achieving authenticity and diversity is crucial.},
  keywords={Feedback loop;Runtime;Character generation;Computer graphics;Generative adversarial networks;Generators;Internet;GAN;FID;IS;DCGAN;CycleGAN},
  doi={10.1109/ISIEA61920.2024.10607225},
  ISSN={2472-7660},
  month={July},}@INPROCEEDINGS{10187731,
  author={Doval Amiri, Parvin Ahmadi and Pierre, Samuel},
  booktitle={2023 19th International Conference on Wireless and Mobile Computing, Networking and Communications (WiMob)}, 
  title={A Soft Voting Classification Model for Network Traffic Prediction in VANET/V2X}, 
  year={2023},
  volume={},
  number={},
  pages={231-236},
  abstract={Vehicular network services in the smart cities generate enormous data by vehicular road users, which is a critical challenge. Network traffic leads to a negative impact on safety applications. AI techniques are a promising solution to address network traffic in VANETs with V2X data. In this paper, we propose a soft voting classification model, which consists of hybrid supervised machine learning algorithms to predict traffic in the network. We evaluate the prediction performance of five well-known machine learning models and the proposed model based on various classification evaluation metrics. The simulation results show that the proposed network traffic prediction model performs better than other considered machine learning models in terms of accuracy (0.94%), time consumption (12.25 seconds) and AUROC (0.907) that proves its stability.},
  keywords={Measurement;Wireless communication;Simulation;Transportation;Telecommunication traffic;Machine learning;Predictive models;Vehicular ad-hoc networks;artificial intelligence;ensemble learning;network traffic prediction;machine learning;intelligent transportation system},
  doi={10.1109/WiMob58348.2023.10187731},
  ISSN={2160-4894},
  month={June},}@ARTICLE{10107396,
  author={Bulut, Ahmet and Mahmoud, Abdelrahman},
  journal={IEEE Access}, 
  title={Generating Campaign Ads & Keywords for Programmatic Advertising}, 
  year={2023},
  volume={11},
  number={},
  pages={43557-43565},
  abstract={Experimenting with different ads and keywords is usual practice in search marketing. Advertisers pause underperforming keywords and ads of a search campaign, and replace them with better alternatives. Therefore, new ads and keywords need to be produced easily for effective campaign management. We built GeNN for generating campaign ads and keywords programmatically. GeNN is based on language modeling. Using the existing keywords of a campaign as input, our GPT-2 based generator created novel keywords of good quality with a high number of expected clicks and conversions according to the forecast data provided by Google’s keyword planner. Using the product landing page and sample ad copies as input, our GPT-2 based summarizer was able to generate production-ready ads. One of the ads that was tested for two weeks in a real search campaign had a CTR of 6% and converted real users. Finally, we compared GeNN’s ad performance with a recent method based on two encoder-decoder RNNs being used in parallel; GeNN outperformed this method.},
  keywords={Transformers;Java;Generators;Web pages;Advertising;Uniform resource locators;Deep learning;Text processing;Deep learning;search marketing;text generation},
  doi={10.1109/ACCESS.2023.3269505},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10489758,
  author={Shen, Juan and Mariano, Vladimir Y.},
  booktitle={2023 5th International Conference on Robotics, Intelligent Control and Artificial Intelligence (RICAI)}, 
  title={Topic Mining of Alzheimer's Disease Field Based on BERTopic}, 
  year={2023},
  volume={},
  number={},
  pages={1039-1043},
  abstract={Alzheimer's disease is the most common progressive neurodegenerative disease in clinical practice, and it is also one of the main causes of disability and death in the elderly. Alzheimer's disease has become a major brain disease that seriously endangers the health of the elderly and affects the sustainable development of society and economy. As the number of people with Alzheimer's disease (AD) rises, the research on AD continues to heat up. Exploring the topic of literature research on Alzheimer's disease is intended to better sort out the research in this field. In this paper, the topic modeling method of BERTopic was applied to the literature on Alzheimer's disease research from 2000 to 2019, to identify the main research directions in this field, and to analyze the changing trend of topic intensity. Twenty research topics in this area were finally identified, and research on amyloid beta and tau was found to have declined significantly since 2016. In addition, this paper also evaluated and compared the quality of topic extraction of two models, LDA and BERTopic, and verified that the accuracy and effectiveness of topic mining results of Alzheimer's disease research based on BERTopic were superior to those generated by LDA model.},
  keywords={Heating systems;Analytical models;Biological system modeling;Market research;Alzheimer's disease;Older adults;Sustainable development;Alzheimer's disease;BERTopic;Deep learning;Topic mining},
  doi={10.1109/RICAI60863.2023.10489758},
  ISSN={},
  month={Dec},}@ARTICLE{10106124,
  author={Duan, Puhong and Kang, Xudong and Ghamisi, Pedram and Li, Shutao},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Hyperspectral Remote Sensing Benchmark Database for Oil Spill Detection With an Isolation Forest-Guided Unsupervised Detector}, 
  year={2023},
  volume={61},
  number={},
  pages={1-11},
  abstract={Oil spill detection has attracted increasing attention in recent years, since marine oil spill accidents severely affect environments, natural resources, and the lives of coastal inhabitants. Hyperspectral remote sensing images provide rich spectral information which is beneficial for the monitoring of oil spills in complex ocean scenarios. However, most of the existing approaches are based on supervised and semi-supervised frameworks to detect oil spills from hyperspectral images (HSIs), which require a massive amount of effort to annotate a certain number of high-quality training sets. In this study, we make the first attempt to develop an unsupervised oil spill detection method based on isolation forest (iForest) for HSIs. First, a Gaussian statistical model is designed to remove the bands corrupted by severe noise. Then, kernel principal component analysis (KPCA) is employed to reduce the high dimensionality of the HSIs. Next, the probability of each pixel belonging to one of the classes of seawater and oil spills is estimated with the iForest, and a set of pseudolabeled training samples is automatically produced using the clustering algorithm on the detected probability. Finally, an initial detection map can be obtained by performing the support vector machine (SVM) on the dimension-reduced data, and the initial detection result is further optimized with the extended random walker (ERW) model so as to improve the detection accuracy of oil spills. Experiments on hyperspectral oil spill database (HOSD) created by ourselves demonstrate that the proposed method obtains superior detection performance with respect to other state-of-the-art detection approaches. We will make HOSD and our developed library for oil spill detection publicly available at https://github.com/PuhongDuan/HOSD to further promote this research topic.},
  keywords={Oils;Hyperspectral imaging;Synthetic aperture radar;Training;Forestry;Spatial resolution;Monitoring;Extended random walker (ERW);hyperspectral image (HIS);isolation forest (iForest);oil spill detection},
  doi={10.1109/TGRS.2023.3268944},
  ISSN={1558-0644},
  month={},}@INPROCEEDINGS{10361199,
  author={Chen, Yuxiang},
  booktitle={2023 2nd International Conference on Data Analytics, Computing and Artificial Intelligence (ICDACAI)}, 
  title={Design and Implementation of Virtual Library Based on VR}, 
  year={2023},
  volume={},
  number={},
  pages={551-555},
  abstract={In history, many writers have written many books, such as Erich Maria Remarque’s “Im Westen nichts Neues”. Modern people cannot imagine what happened on the battlefields of World War I, so when modern readers read novels from long ago, they always question the author. This game was created to address the problem of paper book substitution. The main purpose of this game is to put readers into a specific era, and to understand the historical background and the plot of the book by interacting with npcs (non-player character) and models in the game, so that readers can experience different ages and regions, so as to understand the central idea of the book. The game is developed with unity, with c# as the scripting language, and blender and unity asset as the model source. The game contains an interactive user interface, simulated physics systems and different environments. The content of the game includes the scenes in the famous book and the background of the author’s era.},
  keywords={Data analysis;Education;Games;User interfaces;Libraries;C# languages;History;VR;library;game;interface;famous book},
  doi={10.1109/ICDACAI59742.2023.00110},
  ISSN={},
  month={Oct},}@ARTICLE{9628110,
  author={Lee, Sangwon and Liu, Ling and Choi, Wonik},
  journal={IEEE Access}, 
  title={Iterative Translation-Based Data Augmentation Method for Text Classification Tasks}, 
  year={2021},
  volume={9},
  number={},
  pages={160437-160445},
  abstract={A well-known limitation of existing rule-based text augmentation is that it cannot be applied to other languages because it depends on grammatical and structural characteristics. Moreover, most text Generative Adversarial Networks (GAN) are unstable in training due to inefficient generator optimization and rely on maximum likelihood pre-training. This paper addresses the above problems by proposing a novel augmentation method with a Sentence Generator (SG) and Sentence Discriminator (SD) for Iterative Translation-based Data Augmentation (ITDA). This paper makes three original contributions. First, the ITDA SG is designed to provide universal multiple-language support by generating comprehensive augmented sentences through serial and parallel iterations of an existing translator, such as Google Translate. Second, given that the quality of the generated sentences varies depending on the translation combination or the type of sentence, the ITDA addresses this issue using a discriminator to achieve sentence augmentation, which can select high-quality augmented data using a text classifier. Third, the ITDA can perform sentence augmentation for 109 different languages using discriminators based on text classifiers trained for a specific language or type of data set. Extensive experiments are conducted to evaluate the efficacy of the ITDA using a Convolutional Neural Network (CNN), Bidirectional Long Short-Term Memory (BiLSTM), CNN-BiLSTM, and self-attention. The results demonstrate that when the ITDA is applied to 480 sentence classification tasks, the average accuracy increases by 4.24%.},
  keywords={Internet;Data models;Generators;Decoding;Text categorization;Task analysis;Convolutional neural networks;Deep learning;data augmentation;natural language processing;text classification},
  doi={10.1109/ACCESS.2021.3131446},
  ISSN={2169-3536},
  month={},}@ARTICLE{9075175,
  author={Ai, Zhuang and Luktarhan, Nurbol and Zhao, Yuxin and Tang, Chaofei},
  journal={IEEE Access}, 
  title={WS-LSMR: Malicious WebShell Detection Algorithm Based on Ensemble Learning}, 
  year={2020},
  volume={8},
  number={},
  pages={75785-75797},
  abstract={To solve the problem that the features produced by hidden means, such as code obfuscation and compression, in encrypted malicious WebShell files are not the same as those produced by non-encrypted files, a WebShell attack detection algorithm based on ensemble learning is proposed. First, this algorithm extracted the feature vocabulary of the unigrams and 4-grams based on opcode; subsequently, the 4-gram feature word weights were obtained according to the calculated Gini coefficient of the unigram feature words and used to select the features, which will be selected again based on the Gini coefficient of the 4-gram feature words. Consequently, a feature vocabulary that can detect encrypted and unencrypted WebShell files was constructed. Second, in order to improve the adaptability and accuracy of the detection method, an ensemble detection model called WS-LSMR, consisting of a Logistic Regression, Support Vector Machine, Multi-layer Perceptron and Random Forest, was constructed. The model uses a weighted voting method to determine the WebShell classification. This experiment demonstrated that compared with the traditional single WebShell detection algorithm, the recall rate and accuracy rate improved to 99.14% and 94.28%, respectively, which proves that this method has better detection performance.},
  keywords={Feature extraction;Machine learning algorithms;Forestry;Trojan horses;Training;Adaptation models;Prediction algorithms;Ensemble learning;information entropy;WebShell},
  doi={10.1109/ACCESS.2020.2989304},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10655765,
  author={Yue, Tongtian and Cheng, Jie and GUo, Longteng and Dai, Xingyuan and Zhao, Zijia and He, Xingjian and Xiong, Gang and Lv, Yisheng and Liu, Jing},
  booktitle={2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={SC- Tune: Unleashing Self-Consistent Referential Comprehension in Large Vision Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={13073-13083},
  abstract={Recent trends in Large Vision Language Models (LVLMs) research have been increasingly focusing on ad-vancing beyond general image understanding towards more nuanced, object-level referential comprehension. In this paper, we present and delve into the self-consistency ca-pability of LVLMs, a crucial aspect that reflects the mod-els' ability to both generate informative captions for spe-cific objects and subsequently utilize these captions to ac-curately re-identify the objects in a closed-loop process. This capability significantly mirrors the precision and reli-ability of fine- grained visual-language understanding. Our findings reveal that the self-consistency level of existing LVLMs falls short of expectations, posing limitations on their practical applicability and potential. To address this gap, we introduce a novel fine-tuning paradigm named Self-Consistency Tuning (SC-Tune). It features the syn-ergistic learning of a cyclic describer-locator system. This paradigm is not only data-efficient but also exhibits gener-alizability across multiple LVLMs. Through extensive ex-periments, we demonstrate that SC- Tune significantly ele-vates performance across a spectrum of object-level vision-language benchmarks and maintains competitive or im-proved performance on image-level vision-language bench-marks. Both our model and code will be publicly available at https://github.com/ivattyue/SC-Tune.},
  keywords={Training;Computer vision;Codes;Computational modeling;Focusing;Benchmark testing;Market research},
  doi={10.1109/CVPR52733.2024.01242},
  ISSN={2575-7075},
  month={June},}@ARTICLE{10500817,
  author={Khalid, Hina and Aslam, Muhammad},
  journal={IEEE Access}, 
  title={Automating the Evaluation of Urdu Handwriting for Novice Writers With Localized Feedback}, 
  year={2024},
  volume={12},
  number={},
  pages={70357-70376},
  abstract={Handwriting is one of the basic skills crucial in communication and early childhood development. It plays a major role in the psychomotor and cognitive growth of children. Therefore, it is required to devise interesting and modern ways to teach this skill. A handwriting tutoring system designed to teach Urdu transcription engagingly and efficiently can help to solve this problem. Essential to these teaching systems is the quality evaluation module that analyzes and evaluates the quality of transcription based on legibility and writing process and provides feedback to the writer. This feedback can not only help the young students to improve and identify their mistakes but can also help to repair the handwriting skills of any individual wanting to improve their transcription abilities. The existing handwriting evaluation methods are either designed for Arabic writing style, or those designed for Urdu need more comprehensive feedback on the quality of handwriting. Therefore, it is the need of time to develop a technology-assisted educational system for teaching Urdu handwriting that evaluates and provides intelligent feedback to the learners. In this work, we have proposed an innovative model for evaluating different aspects of Urdu handwriting and providing qualitative and quantitative feedback. The system takes on real-time writing samples, and its transcription profiler module then individually evaluates six aspects of handwriting, including legibility, shape formation, the direction of writing, proportion with the baseline, count, and order of strokes. Based on the evaluation, the feedback generator module provides overall feedback and detects mistakes made while writing. A machine learning-based hybrid architecture is constructed that combines spatio-temporal and structural features to do a quality analysis of each aspect of the transcript. The contribution of this work is twofold: first, to develop a standard for evaluating the quality of Urdu handwriting or any cursive writing script, and second, to create an architecture that relies on machine learning-based models to provide detailed and intelligent feedback while learning handwriting. The system’s performance is verified by comparing it with the test data evaluated by real teachers. It achieved an average of 97% accuracy among all character classes in all handwriting aspects. The results show that the system is effective in identifying and correcting mistakes, thus helping individuals seeking to improve their handwriting skills.},
  keywords={Writing;Education;Kinematics;Standards;Visualization;Computer aided analysis;Machine learning;Handwriting recognition;Computer-aided language learning (CALL);handwriting quality evaluation;machine learning;Urdu handwriting},
  doi={10.1109/ACCESS.2024.3389748},
  ISSN={2169-3536},
  month={},}@ARTICLE{9220880,
  author={Mao, Yan and Fan, Zixuan and Mao, Hua and He, Wu},
  journal={IEEE Access}, 
  title={Asymmetric Intimacy Based Positive Emotions Contagion Peer Public Safety Evacuation Behavior}, 
  year={2020},
  volume={8},
  number={},
  pages={185253-185265},
  abstract={Behavioral simulation plays an important role in many scenarios, such as emergency evacuation and public safety. The importance of public security in modern life can be seen in the epidemic outbreak in 2020. In particular, the epidemic can affect people's psychology and emotions and change people's behavior. Therefore, how to effectively improve people's positive emotions in a panic has become an urgent problem. In social relations, most behaviors are produced by peer interaction. To simulate the interactions among peers more realistically, this paper studies the diversity and efficiency of evacuation behaviors from the trust of peers, the strength of social relations and empathy. First, a general framework of peer relationships is constructed based on asymmetric intimacy, including the relationship between intimacy relationship modeling. Then, the problem of the dynamic formation of peer groups is studied by employing the calculation method of asymmetric intimacy. The effect of positive emotion transmission mechanism on peer interaction behaviors is explored through asymmetric intimacy. Finally, the companion behaviors of the peers in several scenarios are simulated. The proposed method is compared with different emotion contagion models and the behavioral simulation models. Experimental results show that the positive emotions contagion of the peer behavior simulation method can concrete the macro group behavior and effectively simulate the peer group in an evacuation. The simulation effects are diverse and efficient.},
  keywords={Computational modeling;Solid modeling;Analytical models;Psychology;Safety;Adaptation models;Cognition;Behavioral simulation;emergency evacuation;asymmetric intimacy;positive emotion transmission mechanism;emotion contagion},
  doi={10.1109/ACCESS.2020.3030339},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10581614,
  author={Liu, Renjie and Hu, Binghui and Liu, Guangyuan and Qiao, Yinghao},
  booktitle={2024 5th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT)}, 
  title={Facial Expression Generation Based on Multi-Scale Mixed Attention}, 
  year={2024},
  volume={},
  number={},
  pages={1349-1352},
  abstract={Facial expression generation involves creating facial images with specific expressions using computational methods and finds extensive applications in face editing, film production, and data augmentation. The advent of Generative Adversarial Networks (GANs) has led to significant advancements in facial expression generation. However, images generated by these methods often suffer from issues such as overlap and blurriness, resulting in a lack of realism. To address these challenges, this paper introduces a Multi-scale Mixed Attention Generative Adversarial Network (MMA-GAN) aimed at producing high-quality facial expression images. The proposed MMA-GAN incorporates global residual connections at the beginning and end of the generator to preserve skin color and ignore irrelevant background content. Additionally, a multi-scale mixed attention module is integrated within the generator to adaptively learn features of key regions, thereby enhancing the learning of critical areas in the images. Experiments conducted on the publicly available AffectNet dataset validate the effectiveness of the MMA-GAN model. Results indicate that MMA-GAN outperforms related methods in both qualitative assessments and quantitative analysis metrics.},
  keywords={Seminars;Measurement;Statistical analysis;Lighting;Production;Generative adversarial networks;Generators;generative adversarial network(GAN);expression generation;attention mechanism},
  doi={10.1109/AINIT61980.2024.10581614},
  ISSN={},
  month={March},}@INPROCEEDINGS{10655474,
  author={Tang, Junshu and Zeng, Yanhong and Fan, Ke and Wang, Xuheng and Dai, Bo and Chen, Kai and Ma, Lizhuang},
  booktitle={2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Make-It-Vivid: Dressing Your Animatable Biped Cartoon Characters from Text}, 
  year={2024},
  volume={},
  number={},
  pages={6243-6253},
  abstract={Creating and animating 3D biped cartoon characters is crucial and valuable in various applications. Compared with geometry, the diverse texture design plays an important role in making 3D biped cartoon characters vivid and charming. Therefore, we focus on automatic texture design for cartoon characters based on input instructions. This is challenging for domain-specific requirements and a lack of high-quality data. To address this challenge, we propose Make-It-Vivid, the first attempt to enable high-quality texture generation from text in UV space. We prepare a detailed text-texture paired data for 3D characters by using vision-question-answering agents. Then we customize a pretrained text-to-image model to generate texture map with template structure while preserving the natural 2D image knowledge. Furthermore, to enhance fine-grained details, we propose a novel adversarial learning scheme to shorten the domain gap between original dataset and realistic texture domain. Extensive experiments show that our approach outperforms current texture generation methods, resulting in efficient character texturing and faithful generation with prompts. Besides, we showcase various applications such as out of domain generation and texture stylization. We also provide an efficient generation system for automatic text-guided textured character generation and animation.},
  keywords={Training;Geometry;Computer vision;Three-dimensional displays;Semantics;Text to image;Production;Texture generation;diffusion model},
  doi={10.1109/CVPR52733.2024.00597},
  ISSN={2575-7075},
  month={June},}@ARTICLE{9775164,
  author={Xue, Tao and Zhang, Yun and Wang, Xiao and Ning, Shuya and Jiang, Ming},
  journal={IEEE Electron Device Letters}, 
  title={Stable Metal-Insulator-Metal Electron Source Based on Porous Alumina}, 
  year={2022},
  volume={43},
  number={7},
  pages={1129-1132},
  abstract={A Metal-Insulator-Metal electron source containing porous or barrier-type alumina was fabricated. The impacts of rapid thermal processing on electron emission characteristics were studied. The electron source based on porous type alumina film has good heat dissipation and generates more stable conducting paths due to its unique porous structure, which is less prone to negative resistance effect. Additionally, A self-planarization effect occurs at the top electrode after rapid heat treatment, which enables more electrons to escape. As a result, the device’s electron emission current and stability have been significantly increased.},
  keywords={Electron sources;Electron emission;Gold;Thermal stability;Resistance;Temperature measurement;Stability analysis;Metal-insulator-metal;electron emission;negative resistance effect;self-planarization},
  doi={10.1109/LED.2022.3175203},
  ISSN={1558-0563},
  month={July},}@ARTICLE{9399430,
  author={Li, Dejian and Qi, Wenqian and Sun, Shouqian},
  journal={IEEE Access}, 
  title={Facial Landmarks and Expression Label Guided Photorealistic Facial Expression Synthesis}, 
  year={2021},
  volume={9},
  number={},
  pages={56292-56300},
  abstract={Facial expression manipulation plays an increasingly important role in the field of computer graphics and has been widely used in generating facial animations. However, it is still a very challenging task as it needs full understanding of the input face and very depending on the facial appearance. In this paper, we present an end-to-end generative adversarial network for facial expression synthesis. Given the facial landmarks and the expression label of a target image, our method automatically generates a corresponding expression facial image with the identity information and facial details well preserved. Both qualitative and quantitative experiments are conducted on the CK+ and Oulu-CASIA datasets. Experimental results show that our method has the compelling perceptual results even there exist large differences in facial shapes for unseen subjects.},
  keywords={Generative adversarial networks;Faces;Gallium nitride;Generators;Two dimensional displays;Three-dimensional displays;Shape;Facial expression synthesis;generative adversarial networks},
  doi={10.1109/ACCESS.2021.3072057},
  ISSN={2169-3536},
  month={},}@ARTICLE{10538385,
  author={Lips, Thomas and De Gusseme, Victor-Louis and Wyffels, Francis},
  journal={IEEE Robotics and Automation Letters}, 
  title={Learning Keypoints for Robotic Cloth Manipulation Using Synthetic Data}, 
  year={2024},
  volume={9},
  number={7},
  pages={6528-6535},
  abstract={Assistive robots should be able to wash, fold or iron clothes. However, due to the variety, deformability and self-occlusions of clothes, creating robot systems for cloth manipulation is challenging. Synthetic data is a promising direction to improve generalization, but the sim-to-real gap limits its effectiveness. To advance the use of synthetic data for cloth manipulation tasks such as robotic folding, we present a synthetic data pipeline to train keypoint detectors for almost-flattened cloth items. To evaluate its performance, we have also collected a real-world dataset. We train detectors for both T-shirts, towels and shorts and obtain an average precision of 64% and an average keypoint distance of 18 pixels. Fine-tuning on real-world data improves performance to 74% mAP and an average distance of only 9 pixels. Furthermore, we describe failure modes of the keypoint detectors and compare different approaches to obtain cloth meshes and materials. We also quantify the remaining sim-to-real gap and argue that further improvements to the fidelity of cloth assets will be required to further reduce this gap. The code, dataset and trained models are available here.},
  keywords={Synthetic data;Detectors;Semantics;Flexible printed circuits;Deformable models;Robot vision systems;Visualization;Data sets for robotic vision;deep learning for visual perception;simulation and animation},
  doi={10.1109/LRA.2024.3405335},
  ISSN={2377-3766},
  month={July},}@INPROCEEDINGS{9949293,
  author={Han, Yichen and Li, Ya and Gao, Yingming and Xue, Jinlong and Wang, Songpo and Yang, Lei},
  booktitle={2022 IEEE 24th International Workshop on Multimedia Signal Processing (MMSP)}, 
  title={A Keypoint Based Enhancement Method for Audio Driven Free View Talking Head Synthesis}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Audio driven talking head synthesis is a challenging task that attracts increasing attention in recent years. Although existing methods based on 2D landmarks or 3D face models can synthesize accurate lip synchronization and rhythmic head pose for arbitrary identity, they still have limitations, such as the cut feeling in the mouth mapping and the lack of skin highlights. The morphed region is blurry compared to the surrounding face. A Keypoint Based Enhancement (KPBE) method is proposed for audio driven free view talking head synthesis to improve the naturalness of the generated video. Firstly, existing methods were used as the backend to synthesize intermediate results. Then we used keypoint decomposition to extract video synthesis controlling parameters from the backend output and the source image. After that, the controlling parameters were composited to the source keypoints and the driving keypoints. A motion field based method was used to generate the final image from the keypoint representation. With keypoint representation, we overcame the cut feeling in the mouth mapping and the lack of skin highlights. Experiments show that our proposed enhancement method improved the quality of talking-head videos in terms of mean opinion score.},
  keywords={Head;Three-dimensional displays;Lips;Mouth;Streaming media;Skin;Synchronization;talking head generation;speech driven animation},
  doi={10.1109/MMSP55362.2022.9949293},
  ISSN={2473-3628},
  month={Sep.},}@ARTICLE{9334976,
  author={Choi, Myungjin and Wi, Jeong A and Kim, Taehyeong and Kim, Youngbin and Kim, Chang-Hun},
  journal={IEEE Access}, 
  title={Learning Representation of Secondary Effects for Fire-Flake Animation}, 
  year={2021},
  volume={9},
  number={},
  pages={17620-17630},
  abstract={This paper proposes a new data-driven neural network-based fire-flake simulation model. Our model trains a neural network using precomputed fire simulation data. The trained neural network model generates fire flakes in appropriate locations and infers their velocity to make them appear natural to their surroundings. The neural network model consists of a fire-flake generator and a velocity modifier. The fire-flake generator uses the velocity, temperature, and density fields of the precomputed fire simulation as inputs to determine the locations at which natural fire flakes would be generated. The velocity modifier takes the velocity field of the precomputed fire simulation as input and infers the velocity of the generated fire flakes so that they appear natural relative to the flame motions and surroundings. Our method adopts a neural network to efficiently improve the fire-flake simulation, enhancing the performance while maintaining the visual quality. Our model is approximately three times faster than the traditional fire-flake model. In particular, our model is 30 times faster in the velocity modification step. Our method is also easier to implement than the existing physically based fire-flake simulation method and can reduce the time spent by artists and developers on their applications.},
  keywords={Neural networks;Data models;Computational modeling;Generators;Mathematical model;Machine learning;Drag;Fire-flake simulation;visual effect;visual simulation;machine learning;supervised learning},
  doi={10.1109/ACCESS.2021.3054061},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10655899,
  author={Liu, Hanchao and Zhan, Xiaohang and Huang, Shaoli and Mu, Tai-Jiang and Shan, Ying},
  booktitle={2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Programmable Motion Generation for Open-Set Motion Control Tasks}, 
  year={2024},
  volume={},
  number={},
  pages={1399-1408},
  abstract={Character animation in real-world scenarios necessitates a variety of constraints, such as trajectories, keyframes, interactions, etc. Existing methodologies typically treat single or a finite set of these constraint(s) as separate control tasks. These methods are often specialized, and the tasks they address are rarely extendable or customizable. We categorize these as solutions to the close-set motion control problem. In response to the complexity of practical motion control, we propose and attempt to solve the open-set motion control problem. This problem is characterized by an open and fully customizable set of motion control tasks. To address this, we introduce a new paradigm, programmable motion generation. In this paradigm, any given motion control task is broken down into a combination of atomic constraints. These constraints are then programmed into an error function that quantifies the degree to which a motion sequence adheres to them. We utilize a pretrained motion generation model and optimize its latent code to minimize the error function of the generated motion. Consequently, the generated motion not only inherits the prior of the generative model but also satisfies the requirements of the compounded constraints. Our experiments demonstrate that our approach can generate high-quality motions when addressing a wide range of unseen tasks. These tasks encompass motion control by motion dynamics, geometric constraints, physical laws, interactions with scenes, objects or the character's own body parts, etc. All of these are achieved in a unified approach, without the need for ad-hoc paired training data collection or specialized network designs. During the programming of novel tasks, we observed the emergence of new skills beyond those of the prior model. With the assistance of large language models, we also achieved automatic programming. We hope that this work will pave the way for the motion control of general AI agents.},
  keywords={Motion planning;Computer vision;Large language models;Computational modeling;Semantics;Dynamics;Training data},
  doi={10.1109/CVPR52733.2024.00139},
  ISSN={2575-7075},
  month={June},}@INPROCEEDINGS{8783988,
  author={Verma, Dinesh and Bertino, Elisa and de Mel, Geeth and Melrose, John},
  booktitle={2019 IEEE International Conference on Smart Computing (SMARTCOMP)}, 
  title={On the Impact of Generative Policies on Security Metrics}, 
  year={2019},
  volume={},
  number={},
  pages={104-109},
  abstract={Policy based Security Management in an accepted practice in the industry, and required to simplify the administrative overhead associated with security management in complex systems. However, the growing dynamicity, complexity and scale of modern systems makes it difficult to write the security policies manually. Using AI, we can generate policies automatically. Security policies generated automatically can reduce the manual burden introduced in defining policies, but their impact on the overall security of a system is unclear. In this paper, we discuss the security metrics that can be associated with a system using generative policies, and provide a simple model to determine the conditions under which generating security policies will be beneficial to improve the security of the system. We also show that for some types of security metrics, a system using generative policies can be considered as equivalent to a system using manually defined policies, and the security metrics of the generative policy based system can be mapped to the security metrics of the manual system and vice-versa.},
  keywords={Measurement;Computer security;Security management;Manuals;Grammar;Access control},
  doi={10.1109/SMARTCOMP.2019.00037},
  ISSN={},
  month={June},}@INPROCEEDINGS{9936832,
  author={Ho, Wan-Er and Ong, Lee-Yeng and Leow, Meng-Chew},
  booktitle={2022 IEEE International Conference on Artificial Intelligence in Engineering and Technology (IICAIET)}, 
  title={Blended QR Code for Digital Advertising}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Quick Response (QR) code has been widely used in everyone's daily lives for advertising purpose. This is a new norm lifestyle for worldwide customers during the pandemic and post-pandemic. Due to the dull appearance of traditional QR code, blended QR code is created by overlaying an advertisement with a QR code to strengthen the advertising effectiveness. Creating pleasant visibility of blended QR codes can catch the attention of customers and thus able to further engage with them. However, the direct embedding of a traditional QR code with its black and white modules will negatively affect the advertising impact when the advertisement is distorted. Hence, these data modules are the major reason that affects the appearance and yet they are the most critical aspect of decoding capability. As a result, it is a challenge to identify the tradeoff between decoding capability and visual appearance. Therefore, this paper proposes an algorithm that manages the number of data modules and the size of each data module to increase the advertising impact. The proposed algorithm provides more weightage to the pixels that are closer to the center region of each module, which maintains the data on hold inside the modules. The performance comparison between advertisement visibility and decoding capability is presented to verify the robustness of the proposed algorithm.},
  keywords={Visualization;Pandemics;QR codes;Robustness;Decoding;Advertising;Artificial intelligence;Blended QR Code;center region;visual distortion;decoding capability;data module},
  doi={10.1109/IICAIET55139.2022.9936832},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10647842,
  author={Lin, Jian and Liu, Xueting and Li, Chengze and Xie, Minshan and Wong, Tien-Tsin},
  booktitle={2024 IEEE International Conference on Image Processing (ICIP)}, 
  title={SKETCH2MANGA: Shaded Manga Screening from Sketch with Diffusion Models}, 
  year={2024},
  volume={},
  number={},
  pages={2389-2395},
  abstract={While manga is a popular entertainment form, creating manga is tedious, especially adding screentones to the created sketch, namely manga screening. Unfortunately, there is no existing method that tailors for automatic manga screening, probably due to the difficulty in generating shaded high-frequency screentones of high-quality. Classic manga screening approaches generally require user input to provide screentone exemplars or a reference manga image. Recent deep learning models enable automatic generation by learning from a large-scale dataset. However, the state-of-the-art models still fail to generate high-quality shaded screentones due to the lack of a tailored model and high-quality manga training data. In this paper, we propose a novel sketch-to-manga framework that first generates a color illustration from the sketch and then generates a screentoned manga based on the intensity guidance. Our method significantly outperforms existing methods in generating high-quality manga with shaded high-frequency screentones.},
  keywords={Deep learning;Image color analysis;Training data;Entertainment industry;Diffusion models;Animation;Data models;manga generation;manga screening;sketch-to-manga},
  doi={10.1109/ICIP51287.2024.10647842},
  ISSN={2381-8549},
  month={Oct},}@ARTICLE{10685359,
  author={Kanthimathi, S.},
  journal={IEEE Access}, 
  title={Exploring Machine Learning Algorithms for Malicious Node Detection Using Cluster-Based Trust Entropy}, 
  year={2024},
  volume={12},
  number={},
  pages={137913-137925},
  abstract={Machine learning has, over the decades, ushered in a dramatic transformation across a range of sectors, including network security. Security experts agree that the potential of machine learning algorithms will be indispensable in detecting all kinds of attacks and maximize accuracy when compared to traditional detection methods. In Wireless ad hoc networks that monitor real-time systems, security remains a concern. Selective forwarding and Denial-of-Service (DoS) are the most common Wireless Sensor Network (WSN) security attacks, resulting in systems making incorrect decisions with negative consequences. Further, the dynamic nature of ad hoc networks creates security issues that hamper effective data communication. While numerous methods have been suggested in the literature to address these issues, there remains a gap for more robust solutions. This paper proposes a novel trust entropy model approach that applies machine learning to significantly improve network security. The proposed cluster-based trust entropy method avoids malicious nodes in routing and re-routing packets effectively along alternate paths. In addition, a new dataset is created from the network simulation results of the proposed method. This dataset serves as the base for applying machine learning algorithms, resulting in exceptionally high detection accuracy. This novel approach not only solves the security concerns, but also raises the standard for accuracy and reliability in Wireless Adhoc Networks.},
  keywords={Entropy;Ad hoc networks;Routing;Mobile computing;Accuracy;Open systems;Magnetic heads;Backpropagation;Neural networks;Random forests;Support vector machines;Back propagation neural networks;entropy;geographic routing;random forest;support vector machines},
  doi={10.1109/ACCESS.2024.3465843},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9922268,
  author={Meng, Linglong and Schaffer, Stefan and Wappenschmitt, Vincent},
  booktitle={2022 IEEE International Smart Cities Conference (ISC2)}, 
  title={A Connected Swarm Cycling System}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={Social group cycling shows a positive impact on facilitating urban cycling as a sustainable means of mobility while increasing cycling safety in urban areas [1]. We present a new urban mobility concept, Connected Swarm Cycling, that creates a group of people cycling together for a while in a common direction or destination. We assume that the concept of Swarm Cycling can significantly change the mobility behaviour of citizens and will be a building block of green mobility for sustainable cities in the future. Utilizing an OSRM11http://project-osrm.org/ routing service with support of trip intersection computing, the system inducts the cyclists into a cycling swarm. The swarms are formed automatically via peer-to-peer connection when cyclists come in proximity, and the information of the swarm and individual cyclist will be synchronized within the swarm via a Nearby Mesh Network. Supporting the implicit interaction within or between swarms, smart wearables are utilized to realize use cases like swarm member identification or signalling in case of merging or splitting of swarms. In this paper, we also present a technical description of our system, including the protocol and network model to support the coordination and synchronization within the swarms.},
  keywords={Mesh networks;Protocols;Social groups;Smart cities;Wearable computers;Merging;Routing;swarm cycling;sustainable mobility;implicit interaction},
  doi={10.1109/ISC255366.2022.9922268},
  ISSN={2687-8860},
  month={Sep.},}@INPROCEEDINGS{9887491,
  author={Sankalpa, Donthi and Ramesh, Jayroop and Zualkernan, Imran},
  booktitle={2022 IEEE International Conference on Industry 4.0, Artificial Intelligence, and Communications Technology (IAICT)}, 
  title={Using Generative Adversarial Networks for Conditional Creation of Anime Posters}, 
  year={2022},
  volume={},
  number={},
  pages={197-203},
  abstract={Japanese animation, known as anime, has become one of the most accessible forms of entertainment across globe. Recent advances in generative adversarial networks (GAN) and deep learning have contributed greatly to multiple interesting applications in the domain of anime, particularly in face generation, style transfer, and colorization. However, there are no existing implementations for generating composite anime posters with a genre accompaniment prompt. This work proposes a novel application of genre to anime poster generation conditioned on BERT-tokenized binary genre-tags of light-hearted or heavy-hearted categorized based on the thematic subject content of the medium. A dataset of 9,840 image with genre tags and synopses was constructed by scraping MyAnimeList. The conditional Deep Convolution GAN with Spectral Normalization produced the best posters, achieving the quantitative scores of FID: 90.17, average IS: 3.505, 1KNN with PSNR: 0.445 across inter-label discernability, and FID: 166.4, across genuine versus generated poster distinguishability. The primary contribution of this work is to present results outlining the feasibility of various GAN architectures in synthesizing controllable and complex composite anime posters. The larger implication of this project is to provide an introductory approach showing the promise of a creativity assistant for authors, artists, and animators, where they can simply enter a key phrase representing a concept they have in mind, to generate a baseline idea as an initial phase.},
  keywords={Training;Image quality;Deep learning;Image segmentation;Entertainment industry;Generative adversarial networks;Generators;Anime;Computer Generated Art;Deep Learning;Generative Adversarial Networks;Image Generation},
  doi={10.1109/IAICT55358.2022.9887491},
  ISSN={},
  month={July},}@INPROCEEDINGS{10085229,
  author={Jha, Anuradha and Vivek, V. and Gupta, Poonam and Joshi, Rutvij and Singh, Prabhdeep and Iyengar, N.Ch.Sriman Narayana},
  booktitle={2023 International Conference on Artificial Intelligence and Smart Communication (AISC)}, 
  title={Trust aware secure energy efficient hybrid protocol for MANET}, 
  year={2023},
  volume={},
  number={},
  pages={1105-1109},
  abstract={Transmitters (MANETs) are particularly appropriate for uses like special outings, satellite communications in regions with no radio electric grid, crises and things in the environment, as well as diagnostic interventions for the armed forces. Despite the fact that MANETs have evolved into infrastructure-free, soul, and quickly moveable wireless technologies. Privacy may be the key IoT weak point due to the frameworks' flexibility and the constantly changing node mobility. Due to this, it is especially susceptible to numerous assaults, such as software modification, tunneling, and espionage. On MANET, security threats are more serious than problems with the quality of service (QoS). Invasion monitoring, which alters your system to identify further breach holes, is therefore the best way to protect MANET privacy. The ability to detect intrusions is essential for providing protection and acting as an extra layer of restrictions. The loss of the node's energy source might also affect the cellular station's capacity to send messages, which is solely dependent on system life. As a result, the protocol was created and this connection was chosen as the best, most dependable way to extend the MANETs for travel. It is challenging to provide secure and energy-efficient routing in this sort of network due to its dynamic topology and resource limitations. To address the problems of energy safety and security, we provide a hybrid technique of cat slapped solo algorithms (C-SSA), which selects the finest leaps in route advancement. This approach would enable confidence secure efficient energy traveling in MANETs. Fuzzy clustering is utilized initially, and number of clusters (CHs) are selected according to the importance of recent, implicit, and direct trust. Also discovered were nodes depending on the trust threshold value. Even the CHs participate in wireless multi-hop routing, and the best routes are selected here based on lag, throughput, and connection throughout this context. This suggested hybrid algorithm determines the best routes in this context. The recommended method resulted in an energy need of 0.11m electron volts, a minimum duration of 0.005 msec, an understand and solve speed of 0.74 bps, a largest percentage for data packets of 0.99%, and a better detection rate of 90%. The proposed technique was compared to the existing ones containing and without the attack on selective packet skipping model.},
  keywords={Wireless communication;Privacy;Protocols;Quality of service;Routing;Ad hoc networks;Energy efficiency;Hybrid Protocol;MANET;Energy Efficient;Trust Aware},
  doi={10.1109/AISC56616.2023.10085229},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{10037286,
  author={Garde, Aditi and Suratkar, Shraddha and Kazi, Faruk},
  booktitle={2022 IEEE 1st International Conference on Data, Decision and Systems (ICDDS)}, 
  title={AI Based Deepfake Detection}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Advances in machine learning, especially following the 2014 release of Generative Adversarial Networks, have allowed techniques and methods to be used for nefarious ends. Generative Adversarial Networks can even create fake images and videos which appears to be real to human eyes. Generative Adversarial Networks can swap the faces of two different people. For film producers or graphic designers, this tool is quite useful. Face swapping has been done in movies to replace the real person's face with that of the actor. A computer-generated versions of actors Carrie Fisher and Peter Cushing have been featured in a movie named “Star Wars: The Rise of Skywalker” from the “Star wars” film series just like they appeared in the 1977 original, while other Marvel films have “de-aged” actors such as Michael Douglas and Robert Downey Jr. However, this has the potential to be misused. By producing ultra-realistic Deep Fake videos using various trailblazing machine learning techniques, felon are trying to harass, blackmail the innocents. It can also be used to induce political instability by disseminating erroneous information, which can cause communal, diplomatic, and violent outbreak with disastrous consequences. This gives rise to a significant menaces to security of the person as well as national defence, necessitating the development of automated methods for detecting deep fake videos. The eye blinking pattern in deepfaked videos is not formed as naturally as it should be due to the incapability of Generative Adversarial Networks. This will come in handy when constructing a deepfake detecting algorithm. The project uses an object's eye blinking pattern to determine whether or not a video is deepfaked.},
  keywords={Graphics;Deepfakes;Neural networks;Stars;Machine learning;Ear;Motion pictures;Deep-Fake;GANs;Deep Learning;Eye blinking;Convolutional Neural Networks;SVM},
  doi={10.1109/ICDDS56399.2022.10037286},
  ISSN={},
  month={Dec},}@ARTICLE{10243018,
  author={Gallardo-Cava, Roberto and Ortega-Delcampo, David and Guillen-Garcia, Julio and Palacios-Alonso, Daniel and Conde, Cristina},
  journal={IEEE Access}, 
  title={Creating Realistic Presentation Attacks for Facial Impersonation Step-by-Step}, 
  year={2023},
  volume={11},
  number={},
  pages={109257-109266},
  abstract={Presentation attacks are one of the many dangers facing law enforcement today. In addition, material science is constantly advancing and criminals, aware of this fact, are taking advantage of new composites to manufacture new artifacts that allow them to cross borders by breaching border control points. This article presents the creation of several presentation attacks using make-up, hyper-realistic latex, and prosthetic masks. It is worth noting that such attacks do not receive adequate attention, due to the difficulty in their elaboration. The work of professionals in the make-up sector is required. Each stage of processing is analyzed for any artifacts that would facilitate the detection of the attack, using a multispectral approach in the visible and thermal spectra. The methodology evaluates three different face recognition systems (FRS), the different stages of impersonation, i.e. when a specific part of the face such as nose, cheekbones, jaw, or eyes is incorporated. The results show that certain parts of the face improve impersonation and make it more difficult for the algorithms to detect possible impersonation. However, other parts of the face, such as the jaw, not only do not improve impersonation but also significantly worsen performance. Using OpenFace as an FRS example, which is one of the FRS employed in this research work, the bonafide comparison of the target yields a score of 0.304, while with the make-up attack before applying make-up to the jaw, it gives 0.291, and after applying make-up, it gives 0.421.},
  keywords={Face recognition;Prosthetics;Three-dimensional displays;Biometrics (access control);Law enforcement;Surveillance;Biometric systems;presentation attack construction;make-up attack;prosthetic mask attack;latex mask attack},
  doi={10.1109/ACCESS.2023.3313094},
  ISSN={2169-3536},
  month={},}@ARTICLE{10410895,
  author={Du, Wenxin and Xu, Wenqiang and Ren, Jieji and Yu, Zhenjun and Lu, Cewu},
  journal={IEEE Robotics and Automation Letters}, 
  title={TacIPC: Intersection- and Inversion-Free FEM-Based Elastomer Simulation for Optical Tactile Sensors}, 
  year={2024},
  volume={9},
  number={3},
  pages={2559-2566},
  abstract={Tactile perception stands as a critical sensory modality for human interaction with the environment. Among various tactile sensor techniques, optical sensor-based approaches have gained traction, notably for producing high-resolution tactile images. This letter explores gel elastomer deformation simulation through a physics-based approach. While previous works in this direction usually adopt the explicit material point method (MPM), which has certain limitations in force simulation and rendering, we adopt the finite element method (FEM) and address the challenges in mesh penetration and element inversion with incremental potential contact (IPC) method. As a result, we present a simulator named TacIPC, which can ensure numerically stable simulations while accommodating direct rendering and friction modeling. To evaluate TacIPC, we conduct four tasks: pseudo-image quality assessment, marker displacement prediction, slip-induced rotation prediction, and deformed geometry estimation. These tasks show its superior efficacy in reducing the sim-to-real gap. Our method can also seamlessly integrate with existing simulators.},
  keywords={Elastomers;Finite element analysis;Tactile sensors;Optical sensors;Deformation;Rendering (computer graphics);Optical imaging;Force and tactile sensing;simulation and animation},
  doi={10.1109/LRA.2024.3357030},
  ISSN={2377-3766},
  month={March},}@INPROCEEDINGS{10462885,
  author={Rahman, Rabi’Atul’Adawiyah Abdul and Mashor, Mohd Yusoff and Raof, Rafikha Aliana Binti A. and Hassan, Rosline and Mustafa, Nazahah Binti and Kanafiah, Siti Nurul Aqmariah Binti Mohd and Rahman, Khairul Shakir Bin Ab and Zulkeflee, Razan Hayati},
  booktitle={2023 International Workshop on Artificial Intelligence and Image Processing (IWAIIP)}, 
  title={Feature Targeted Image Enhancement for Acute Myeloid Leukemia}, 
  year={2023},
  volume={},
  number={},
  pages={359-364},
  abstract={Image enhancement is one of the pre-processing steps in various computer vision applications. The current image enhancement algorithm typically applies uniform enhancements across the entire image where this approach often falls short of accurately highlighting or enhancing the specific features due to the influence of the background color. Therefore, this paper proposes a feature-targeted image enhancement technique. Feature-targeted image enhancement (FTIE) algorithm is the improvement over the conventional technique. This method will only enhance the targeted feature instead of the entire image. Therefore, the targeted feature will be enhanced accurately without the influence of the background image. The FTIE method was done by extracting the target feature from the original images and then applying the enhancement method to that region only. Based on the 80 acute myeloid leukemia images, the proposed method showed a promising result, where the comparative analysis shows that the image produced from the proposed method surpasses other conventional methods in terms of structural similarity index (0.995), universal image quality index (0.996), peak signal-to-noise ratio (30.803), mean absolute error (0.002), correlation coefficient (0.997) and contrast enhancement-based image quality (1.743) values.},
  keywords={Image quality;Deep learning;Correlation coefficient;Visualization;PSNR;Image color analysis;Conferences;Feature targeted;Image enhancement;Acute myeloid leukemia},
  doi={10.1109/IWAIIP58158.2023.10462885},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9671219,
  author={Perera, Tavish and Kuganandamurthy, Lakshini and Ameen, Thilrash and Dassanayake, Thamali and Ganegoda, Devanshi},
  booktitle={2021 3rd International Conference on Advancements in Computing (ICAC)}, 
  title={SalFix: Solutions for Small Businesses Using Artificial Intelligence and Machine Learning}, 
  year={2021},
  volume={},
  number={},
  pages={467-472},
  abstract={Every large organization was a small business before. There are many businesses starting every day. Most of them are small businesses. Managing a business is always a challenge. The owners face lots of challenges when they engage with a business. Small business owners do not have enough knowledge about advertising or promoting a product. New owners do not know the trendiest product at present, and they need to know to sell which product to be profitable. Lack of communication with the customers will impact the customer base. These are the main problems that owners face. By introducing SalFix, these challenges can be conquered. SalFix is a web application that is suitable for current owners and new owners. SalFix uses Artificial Intelligence to generate automated ad images, predict what will happen to the business next year, predict which product is the trendiest. To improve customer communication, SalFix is embedded with a chatbot plugin that can be integrated into the small business’s website. SalFix can perform a SWOT analysis as well. Owners can use SalFix to fix their sales and boost their income. SalFix is a yearly subscription service and will provide more accurate results.},
  keywords={Costs;Computational modeling;Organizations;Machine learning;Booting;Chatbots;Advertising;Artificial Intelligence;Predict;Machine Learning;Web application;SWOT},
  doi={10.1109/ICAC54203.2021.9671219},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10961348,
  author={Dutta, Neha and Rani, Neetu and Shrimal, Vijay Mohan and Wadhwa, Manoj and Badoni, Parveen},
  booktitle={2024 International Conference on Emerging Technologies and Innovation for Sustainability (EmergIN)}, 
  title={Improving Educational Strategy by Integrating Digital Human into Classroom Dynamics}, 
  year={2024},
  volume={},
  number={},
  pages={18-23},
  abstract={The integration of AI based avatars also called digital humans are now being adopted in various educational sectors., which is itself a technological advancement or a beginning of a new era to interact with AI. These digital humans are sophisticated computer simulations that are designed and programmed in such a way that can adopt human emotions can answer in bringing the same required emotion so., that the conversation looks very natural. Unlike Chabot's, which can only communicate with static., pre-programmed scripts., AI avatars can have natural-sounding conversations with students. This makes them a significant advancement in educational technology. Users are able to ask questions in a variety of ways., and the avatars adapt their responses on the go., creating a dialogue that isn't limited by pre-defined inputs. This shift allows for a far more personalized engagement. Digital humans are highly proficient at providing tailored educational experiences. Unlike human instructors who must divide their attention among multiple students., a digital human can offer individualized one-on-one engagement tailored to each learner's pace., style., and needs. This feature is especially advantageous in promoting an all-encompassing educational setting that caters to a wide range of learning preferences and skills.},
  keywords={Technological innovation;Ethics;Emotion recognition;Oral communication;Educational technology;Digital humans;Stakeholders;Sustainable development;Standards;Robots;AI Avatars;Robots;AI/ML tools;Smart Classrooms},
  doi={10.1109/EmergIN63207.2024.10961348},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10192598,
  author={Sridevi, Kotari and Phijik, Battula and Helini, K. and Rajesh, G. and Rupa, Annam},
  booktitle={2023 8th International Conference on Communication and Electronics Systems (ICCES)}, 
  title={MANET’s Node Secure Mobility Predictions using Enhanced Adaptive Learning Techniques}, 
  year={2023},
  volume={},
  number={},
  pages={510-514},
  abstract={Predicting node mobility in dynamic environments is crucial to designing and implementing ad hoc networks. This study presents a filter-based computing approach. Each node's mobility prediction model predicts its neighbors' movements. It uses node spatial and temporal properties. This research suggests using reinforcement learning to increase model accuracy. The greeting message threshold determines the best neighbor node-finding strategy. HP-AODV and ROMSG are used to assess the paper's performance. The proposed welcome message broadcasting algorithm is far cheaper than others. It reduces neighbor node discovery errors. This strategy improves ad hoc wireless network quality. Mobility prediction model integration into the network layer is complex. However, application-level integration may improve routing protocol efficiency. The study develops a mobility prediction framework to anticipate a wireless device's future position reliably. The mobility prediction model is a sequence of discrete occurrences, such as a node's upcoming position, based on its present location. The research suggests using the AdaBoost algorithm and Markov model to increase accuracy. AdaBoost estimates model weight coefficients. The AdaBoost-produced multi-order Markov model beats conventional Markov models.},
  keywords={Adaptation models;Computational modeling;Wireless networks;Predictive models;Markov processes;Prediction algorithms;Routing;MANETS;Network Security;Machine Learnigng;HP-AODV;ROMSG},
  doi={10.1109/ICCES57224.2023.10192598},
  ISSN={},
  month={June},}@INPROCEEDINGS{10710994,
  author={Abasikeleş-Turgut, İpek},
  booktitle={2024 8th International Artificial Intelligence and Data Processing Symposium (IDAP)}, 
  title={Recent reputation-based security approaches for VANETs}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={One of the important problems of the February 6, 2023, Kahramanmaraş earthquake was those unexpected road blockages due to instantaneous congestion and disaster-related damage caused by forced changes in vehicle routes. Intelligent Transport Systems (ITS), which offer innovative methods to reduce accidents and prevent blockages by improving traffic management, play a vital role in academia and industry in today’s digital world. VANET, created using wireless communication technology between vehicles and roadside units and is an important component of ITS, provides infrastructure for many security-related and non-security applications for different traffic scenarios. However, the open communication nature of these networks makes them susceptible to attacks. It becomes necessary to take precautions against internal attacks, especially in disseminating emergency security-related messages. The inadequacy of cryptological approaches in internal attacks and their high computational complexity have led to the search for new security research in the literature. Reputation-based detection systems have become a popular solution for VANETs in recent years, both in terms of low computational cost and high attack resistance. In this study, recent reputation-based mechanisms designed for VANET in the literature are compared and examined based on various criteria such as design preferences, network parameters, and attack resistance. Thus, it is thought that this study will guide new studies to be conducted in this field in the future.},
  keywords={Resistance;Measurement;Wireless communication;Industries;System performance;Roads;Vehicular ad hoc networks;Social factors;Security;Resilience;trust;reputation;survey;VANET},
  doi={10.1109/IDAP64064.2024.10710994},
  ISSN={},
  month={Sep.},}@ARTICLE{9590550,
  author={Zavvos, Efstathios and Gerding, Enrico H. and Yazdanpanah, Vahid and Maple, Carsten and Stein, Sebastian and schraefel, m.c.},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={Privacy and Trust in the Internet of Vehicles}, 
  year={2022},
  volume={23},
  number={8},
  pages={10126-10141},
  abstract={The Internet of Vehicles aims to fundamentally improve transportation by connecting vehicles, drivers, passengers, and service providers together. Several new services such as parking space identification, platooning and intersection control—to name just a few—are expected to improve traffic congestion, reduce pollution, and improve the efficiency, safety and logistics of transportation. Proposed end-user services, however, make extensive use of private information with little consideration for the impact on users and third parties (those individuals whose information is indirectly involved). This article provides the first comprehensive overview of privacy and trust issues in the Internet of Vehicles at the service level. Various concerns over privacy are formalised into four basic categories: personal information privacy, multi-party privacy, trust, and consent to share information. To help analyse services and to facilitate future research, the main relevant end-user services are taxonomised according to voluntary and involuntary information they require and produce. Finally, this work identifies several open research problems and highlights general approaches to address them. These especially relate to measuring the trade-off between privacy and service functionality, automated consent negotiation, trust towards the IoV and its individual services, and identifying and resolving multi-party privacy conflicts.},
  keywords={Privacy;Internet of Things;Vehicular ad hoc networks;Data privacy;Safety;Security;Peer-to-peer computing;Privacy;trust;Internet of Vehicles;IoV;IoT;connected vehicles},
  doi={10.1109/TITS.2021.3121125},
  ISSN={1558-0016},
  month={Aug},}@INPROCEEDINGS{10426160,
  author={Shi, Zhengyao and Ma, Wenzhi and Wu, Guanghong and Du, Yuhui and Xia, Mingyao and Li, Zhenmin},
  booktitle={2023 IEEE 17th International Conference on Anti-counterfeiting, Security, and Identification (ASID)}, 
  title={Design of Tile-based ARGB Image Lossless Compressor and Decompressor}, 
  year={2023},
  volume={},
  number={},
  pages={57-61},
  abstract={The utilization of lossless compression is an essential technique, and the compression and decompression of images without any loss have consistently remained a prominent subject of research. In the field of chip design, such as GPU and AI, memory access often becomes a bottleneck for system performance. The frequent read and write operations on color buffer data have a significant impact on performance. This paper aims to improve memory access efficiency by reducing the amount of data accessed in the color buffer from the perspective of data compression. However, with the development of the gaming and special effects industries, GPUs need to process images rendered with special effects. Existing algorithms are good at compressing natural images but have poor compatibility and suboptimal compression ratio for this type of image. In this paper, we first design the QOI+ algorithm based on the Quite Ok Image (QOI) algorithm, which is good at dealing with the compression of non-natural images. Then, we propose a fusion optimization algorithm called QOI++, which covers both natural images and synthetic images. We provide a dedicated accelerator for QOI++ compression and decompression, which conforms to the AXI4-Stream interface. It can be selected for compression of tile sizes of 4x4, 8x8, and 16x16. The compression ratio achieved are 48.72% for 4x4 tiles, 41.22% for 8x8 tiles, and 38.60% for 16x16 tiles, with a clock frequency of 400MHz.},
  keywords={Industries;Image coding;Image color analysis;System performance;Memory management;Security;Optimization;lossless;QOI;compression;FPGA implementation;adaptive},
  doi={10.1109/ASID60355.2023.10426160},
  ISSN={2163-5056},
  month={Dec},}@INPROCEEDINGS{10826085,
  author={Ahmadi, Kamilia and Gathwala, Arjun and Osajima, Jason and Hsiao, David and Das, Puja},
  booktitle={2024 IEEE International Conference on Big Data (BigData)}, 
  title={SLLIM-Rank: A Multi-Stage Item-to-Item Recommendation Model using Learning-to-Rank}, 
  year={2024},
  volume={},
  number={},
  pages={2264-2268},
  abstract={Item-to-item recommendations are crucial for user content discovery and engagement on online platforms, often showcased in prominent areas like "You May Also Like." These models typically leverage metadata and user engagement data to generate recommendations; however, data sparsity presents challenges, particularly when new movies or shows are released, limiting the ability to provide optimal recommendations early on. Additionally, as users access content across various devices with different screen sizes, it is essential to optimize the ranking of recommendations to ensure the most relevant items appear at the top. Finally, with platforms serving millions of users and an ever-changing inventory of items, scalable methodologies are necessary to effectively address these challenges. In this paper, we propose a scalable multi-stage item-to-item recommendations model called SLLIM-Rank: Similarity with Large Language Improved Model using Learning-to-Rank. The approach utilizes (a) temporal and contextual features to capture dynamic trends in item similarity, (b) a Learning-to-Rank model to prioritize items based on implicit user feedback and, (c) large language models (LLMs) to generate supplementary metadata for catalog items. We discuss effective strategies for offline evaluation of the model. Additionally, these offline findings lead to substantial improvements in key engagement metrics on a content streaming platform, specially improving the quality of cold item recommendations, demonstrating the high effectiveness of our approach in a real-world context.},
  keywords={Measurement;Limiting;Large language models;Metadata;Big Data;Motion pictures;Market research;Context modeling;Recommendations;Learning to Rank;Item-to-Item Similarity;Closed From Solution;Candidate Generation;Large Language Models},
  doi={10.1109/BigData62323.2024.10826085},
  ISSN={2573-2978},
  month={Dec},}@ARTICLE{9157962,
  author={Zhang, Juyong and Chen, Keyu and Zheng, Jianmin},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Facial Expression Retargeting From Human to Avatar Made Easy}, 
  year={2022},
  volume={28},
  number={2},
  pages={1274-1287},
  abstract={Facial expression retargeting from humans to virtual characters is a useful technique in computer graphics and animation. Traditional methods use markers or blendshapes to construct a mapping between the human and avatar faces. However, these approaches require a tedious 3D modeling process, and the performance relies on the modelers’ experience. In this article, we propose a brand-new solution to this cross-domain expression transfer problem via nonlinear expression embedding and expression domain translation. We first build low-dimensional latent spaces for the human and avatar facial expressions with variational autoencoder. Then we construct correspondences between the two latent spaces guided by geometric and perceptual constraints. Specifically, we design geometric correspondences to reflect geometric matching and utilize a triplet data structure to express users’ perceptual preference of avatar expressions. A user-friendly method is proposed to automatically generate triplets for a system allowing users to easily and efficiently annotate the correspondences. Using both geometric and perceptual correspondences, we trained a network for expression domain translation from human to avatar. Extensive experimental results and user studies demonstrate that even nonprofessional users can apply our method to generate high-quality facial expression retargeting results with less time and effort.},
  keywords={Avatars;Three-dimensional displays;Strain;Animation;Shape;Solid modeling;Machine learning;Facial expression retargeting;variational autoencoder;deformation transfer;cross domain translation;triplet},
  doi={10.1109/TVCG.2020.3013876},
  ISSN={1941-0506},
  month={Feb},}@INPROCEEDINGS{9945388,
  author={Zhang, Wuyi and Xia, Chongkun and Zhu, Xiaojun and Liu, Houde and Liang, Bin},
  booktitle={2022 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, 
  title={TacRot: A Parallel-Jaw Gripper with Rotatable Tactile Sensors for In-Hand Manipulation}, 
  year={2022},
  volume={},
  number={},
  pages={423-429},
  abstract={Finger dexterity and tactile perception are key capabilities for humans to manipulate objects within hand, as well as robots. Inspired by the thumb-forefinger dexterous manipulative movement, we devised a novel robotic finger with an active rotational tactile sensor (i.e. TacRot), and mounted the finger on a parallel-jaw gripper. By processing the high-resolution images of the vision-based tactile sensor, we achieved depth reconstruction of the surface and localization of the contact area. To improve gripping flexibility and stability, we applied a self-adaptive grasping strategy with real-time contact detection feedback, which performed 94% success rate in experiment. Based on the rotational actuator at the fingertip, we proposed two in-hand manipulation primitives: (1) pivot: fingertips co-rotating for object reorientation; (2) twist: fingertips contra-rotating for object spin. The primitives are theoretically analyzed and experimentally verified in two practical tasks: pivoting a paper cup under vertical constraints and twisting a screw with spin angle estimation. Our design and experiments demonstrate a feasible way to enhance the active tactile manipulation ability for common parallel-jaw grippers.},
  keywords={Location awareness;Surface reconstruction;Thumb;Tactile sensors;Stability analysis;Real-time systems;Grippers},
  doi={10.1109/SMC53654.2022.9945388},
  ISSN={2577-1655},
  month={Oct},}@INPROCEEDINGS{9087510,
  author={Islam, Md Shazid and Rahman, Md Saydur and Amin, M Ashraful},
  booktitle={2019 IEEE International Conference on Robotics, Automation, Artificial-intelligence and Internet-of-Things (RAAICON)}, 
  title={Beat Based Realistic Dance Video Generation using Deep Learning}, 
  year={2019},
  volume={},
  number={},
  pages={43-47},
  abstract={Deep learning based feature extraction has enabled us to synchronize audio and body movements. It is a promising research field which has great applications in generating sign language, computer animations as well as dance. Previously, computer generated choreography was limited to just stick figure representation. This paper adds image translation technique in dance generation which produces realistic dance moves. With this technique it is possible to produce dance video of a amateur person dancing like a professional. The mapping of stick figure to realistic image is done using Generative Adversarial Network (GAN). We created our own dataset and after adversarial training reconstructed images have SSIM mean 0.864 and LPIPS mean 0.0168. This method produces realistic dance video which is beat based. Body movement speed varies according to the tempo of music which makes it more relevant to real life dance movement.},
  keywords={Deep Learning;GAN;Image translation;Beat;OpenPose;Pix2pixHD},
  doi={10.1109/RAAICON48939.2019.22},
  ISSN={},
  month={Nov},}@ARTICLE{9145584,
  author={Guo, Shun and Yao, Nianmin},
  journal={IEEE Access}, 
  title={Polyseme-Aware Vector Representation for Text Classification}, 
  year={2020},
  volume={8},
  number={},
  pages={135686-135699},
  abstract={Representation models for text classification have recently shown impressive performance. However, these models neglect the importance of polysemous words in text. When polysemous words appear in a text, imprecise polysemous word embeddings will produce low-quality text representation that results in changing the original meaning of the text. To address this problem, in this paper, we present a more effective model architecture, the polyseme-aware vector representation model (PAVRM), to generate more precise vector representations for words and texts. The PAVRM can effectively identify polysemous words in a corpus with a context clustering algorithm. Additionally, we propose two methods to construct polysemous word representations, PAVRM-Context and PAVRM-Center. Experiments conducted on three standard text classification tasks and a custom text classification task demonstrate that the proposed PAVRM can be effectively introduced into existing models to generate higher-quality word and text representations to achieve better classification performance.},
  keywords={Task analysis;Semantics;Text categorization;Training;Computational modeling;Context modeling;Microsoft Windows;Polysemous words;context clustering algorithm;PAVRM-Context;PAVRM-Center},
  doi={10.1109/ACCESS.2020.3010981},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10262545,
  author={Madhavi, G. Bindu and Bhavani, A. Durga and Reddy, Y. Sowmya and Kiran, Ajmeera and Chitra, N. Thulasi and Reddy, Pundru Chandra Shaker},
  booktitle={2023 International Conference on Computer, Electronics & Electrical Engineering & their Applications (IC2E3)}, 
  title={Traffic Congestion Detection from Surveillance Videos using Deep Learning}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Countless cameras, both public and private, have been installed in recent years for the objectives of surveillance, the monitoring of anomalous human activities, and traffic surveillance. Numerous worrisome and aberrant actions, such as theft, aggression, and accidents, make it difficult to notice and recognise such behaviour in a real-world setting. The topic of this study is car wrecks as depicted in online videos of traffic. Modern traffic monitoring and surveillance rely heavily on video traffic surveillance cameras (VTSS). Consequences of a rapidly expanding human population include a higher frequency of accidental injuries. The VTSS is employed to identify unusual occurrences on various roads and highways, such as traffic congestion and car accidents. When accidents happen on lengthy roadways or in remote areas, victims are often powerless and some don't make it. The purpose of this study is to provide a method for automatically identifying incidents in surveillance footage. Convolutional-neural-networks (CNNs), a specific deep learning approach developed to cope with grid-like data, have been shown to be useful in image and video processing, according to a study of the relevant literature. This study use a rolling prediction method and convolutional neural networks (CNNs) to detect accidents in VTSS footage. A dataset of anomalous photographs, called the Vehicle Accident Image Dataset (VAID), was created and used in the training of the CNN model. The proposed method was put through its paces by analysing data gathered from running the trained CNN model on a number of different films. This study's findings demonstrate a 93% success rate in identifying traffic accident incidents in films from traffic surveillance systems.},
  keywords={Deep learning;Surveillance;Films;Traffic control;Cameras;Convolutional neural networks;Automobiles;Machine-learning;deep-learning;Convolution-Neural-Networks (CNN) Traffic prediction;video classification},
  doi={10.1109/IC2E357697.2023.10262545},
  ISSN={},
  month={June},}@INPROCEEDINGS{9412785,
  author={Fürst, Michael and Gupta, Shriya T. P. and Schuster, René and Wasenmüller, Oliver and Stricker, Didier},
  booktitle={2020 25th International Conference on Pattern Recognition (ICPR)}, 
  title={HPERL: 3D Human Pose Estimation from RGB and LiDAR}, 
  year={2021},
  volume={},
  number={},
  pages={7321-7327},
  abstract={In-the-wild human pose estimation has a huge potential for various fields, ranging from animation and action recognition to intention recognition and prediction for autonomous driving. The current state-of-the-art is focused only on RGB and RGB-D approaches for predicting the 3D human pose. However, not using precise LiDAR depth information limits the performance and leads to very inaccurate absolute pose estimation. With LiDAR sensors becoming more affordable and common on robots and autonomous vehicle setups, we propose an end-to-end architecture using RGB and LiDAR to predict the absolute 3D human pose with unprecedented precision. Additionally, we introduce a weakly-supervised approach to generate 3D predictions using 2D pose annotations from PedX [1]. This allows for many new opportunities in the field of 3D human pose estimation.},
  keywords={Three-dimensional displays;Laser radar;Annotations;Pose estimation;Robot sensing systems;Animation;Distance measurement;sensor fusion;3D human pose estimation;Li-DAR;RGB;autonomous vehicles;perception},
  doi={10.1109/ICPR48806.2021.9412785},
  ISSN={1051-4651},
  month={Jan},}@ARTICLE{10422989,
  author={Zhang, Jingbo and Li, Xiaoyu and Wan, Ziyu and Wang, Can and Liao, Jing},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Text2NeRF: Text-Driven 3D Scene Generation With Neural Radiance Fields}, 
  year={2024},
  volume={30},
  number={12},
  pages={7749-7762},
  abstract={Text-driven 3D scene generation is widely applicable to video gaming, film industry, and metaverse applications that have a large demand for 3D scenes. However, existing text-to-3D generation methods are limited to producing 3D objects with simple geometries and dreamlike styles that lack realism. In this work, we present Text2NeRF, which is able to generate a wide range of 3D scenes with complicated geometric structures and high-fidelity textures purely from a text prompt. To this end, we adopt NeRF as the 3D representation and leverage a pre-trained text-to-image diffusion model to constrain the 3D reconstruction of the NeRF to reflect the scene description. Specifically, we employ the diffusion model to infer the text-related image as the content prior and use a monocular depth estimation method to offer the geometric prior. Both content and geometric priors are utilized to update the NeRF model. To guarantee textured and geometric consistency between different views, we introduce a progressive scene inpainting and updating strategy for novel view synthesis of the scene. Our method requires no additional training data but only a natural language description of the scene as the input. Extensive experiments demonstrate that our Text2NeRF outperforms existing methods in producing photo-realistic, multi-view consistent, and diverse 3D scenes from a variety of natural language prompts. Our code and model are available at https://github.com/eckertzhang/Text2NeRF.},
  keywords={Three-dimensional displays;Solid modeling;Geometry;Natural languages;Semantics;Point cloud compression;Optimization;Text-to-3D;NeRF;3D scene generation;scene inpainting;depth alignment},
  doi={10.1109/TVCG.2024.3361502},
  ISSN={1941-0506},
  month={Dec},}@INPROCEEDINGS{10445548,
  author={Byrne, Sean Anthony and Castner, Nora and Bozkir, Efe and Niehorster, Diederick C. and Kasneci, Enkelejda},
  booktitle={2024 IEEE International Conference on Artificial Intelligence and eXtended and Virtual Reality (AIxVR)}, 
  title={From Lenses to Living Rooms: A Policy Brief on Eye Tracking in XR Before the Impending Boom}, 
  year={2024},
  volume={},
  number={},
  pages={90-96},
  abstract={As tech giants such as Apple and Meta invest heavily in Virtual and Augmented Reality (VR/AR) technologies, often collectively termed Extended Reality (XR) devices, a significant societal concern emerges: The use of eye-tracking technology within these devices. Gaze data holds immense value, revealing insights into user attention, health, and cognitive states. This raises substantial concerns over privacy and fairness, with potential risks of targeted ads, unauthorized surveillance, and data re-purposing. As the impact of eye tracking is due to transition from the lab to the broader public, this paper underscores these pivotal issues in a digestible manner to the general audience. To this end, we first outline the eye-tracking data collection process and its potential for user insights. Second, we introduce perspectives from the domain of privacy, emphasizing its significance as a pivotal measure to guard against the improper use of eye-tracking data. Third, we provide a set of guidelines created by researchers actively working within this space. These recommendations are designed to guide policymakers and the general public toward establishing informed, equitable, and privacy-centric standards surrounding these devices.},
  keywords={Privacy;Ethics;Data privacy;Surveillance;Gaze tracking;X reality;Standards;Extended Reality;Ethics;Privacy;Eye tracking;The Metaverse},
  doi={10.1109/AIxVR59861.2024.00020},
  ISSN={2771-7453},
  month={Jan},}@INPROCEEDINGS{10137939,
  author={Zhang, Meng and Jiang, Ziyin and Zhao, Zhifang and Lv, Xin and Zhang, Lijin},
  booktitle={2022 6th Asian Conference on Artificial Intelligence Technology (ACAIT)}, 
  title={Spectrogram Generation for Music Game Based on Attention-BiLSTM}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={Music game has been popular among digital entertainment since 1960s, and it is significant for children’s musical interests and the inculcation of music. The most important part of music game, charts, however are rarely created by professional staff. In many music games, charts are created by players themselves, resulting in uneven quality. The tedious and labor-intensive production of charts, and the negative impact it can have on the game experience, make them an important and difficult aspect of music game. Most research on music games has conducted from a sociological or design perspective, and there is little on automatic spectrogram for music games. Moreover, BiLSTM neural network mode has achieved remarkable success in processing temporal problems such as speech recognition. Meanwhile, Attention excels in enabling models the ability to discriminate. In this paper, we proposed an automatic generation model combined Attention mechanism with BiLSTM neural network for music game.},
  keywords={Training;Neural networks;Music;Games;Speech recognition;Production;Generative adversarial networks;neural networks;BiLSTM;Attention mechanism;music game},
  doi={10.1109/ACAIT56212.2022.10137939},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9787838,
  author={Paduraru, Ciprian and Paduraru, Miruna and Stefanescu, Alin},
  booktitle={2022 IEEE Conference on Software Testing, Verification and Validation (ICST)}, 
  title={RiverGame - a game testing tool using artificial intelligence}, 
  year={2022},
  volume={},
  number={},
  pages={422-432},
  abstract={As is the case with any very complex and interactive software, many video games are released with various minor or major issues that can potentially affect the user experience, cause security issues for players, or exploit the companies that deliver the products. To test their games, companies invest important resources in quality assurance personnel who usually perform the testing mostly manually. The main goal of our work is to automate various parts of the testing process that involve human users (testers) and thus to reduce costs and run more tests in less time. The secondary goal is to provide mechanisms to make test specification writing easier and more efficient. We focus on solving initial real-world problems that have emerged from several discussions with industry partners. In this paper, we present RiverGame, a tool that allows game developers to automatically test their products from different points of view: the rendered output, the sound played by the game, the animation and movement of the entities, the performance and various statistical analyses. We also address the problem of input priorities, scheduling, and directing the testing effort towards custom and dynamic directions. At the core of our methods, we use state-of-the-art artificial intelligence methods for analysis and a behavior-driven development (BDD) methodology for test specifications. Our technical solution is open-source, independent of game engine, platform, and programming language.},
  keywords={Software testing;Quality assurance;Statistical analysis;Games;Companies;Dynamic scheduling;User experience;game testing;automated testing;BDD;deep learning;reinforcement learning;computer vision},
  doi={10.1109/ICST53961.2022.00048},
  ISSN={2159-4848},
  month={April},}@INPROCEEDINGS{10512011,
  author={Feng, Yulin and Gai, Hailong and Yu, Hongzhi and Wan, Fucheng},
  booktitle={2023 International Conference on Advances in Electrical Engineering and Computer Applications (AEECA)}, 
  title={Conversation Generation Model Based on Attention Mechanism and Emotion Dictionary}, 
  year={2023},
  volume={},
  number={},
  pages={464-467},
  abstract={In recent years, the dialogue system has been widely used in virtual assistant, chatbot, intelligent customer service and other fields, which has attracted the attention of industry and academia, and has become one of the hot spots in artificial intelligence research. However, it faces many challenges, such as insufficient anthropomorphism and lack of emotional response to users in human-computer dialogue. To solve this problem, this paper proposes a dialogue generation model combining concern gating and sentiment dictionary. On the basis of Seq2Seq based on Attention mechanism, this model adds a focus gate to extract emotional features and global features, and combines with external emotion dictionary to obtain global emotion words to identify emotional features of input statements and calculate emotional features of response statements. Finally, based on emotion comparison mechanism, corresponding anthropomorphic responses are generated according to different emotional features. Experimental results show that the model proposed in this paper can effectively improve the anthropomorphic effect of emotional response compared with the traditional model in the Cornell Movie-Dialogs Corpu dataset.},
  keywords={Industries;Emotion recognition;Dictionaries;Computational modeling;Virtual assistants;Natural languages;Logic gates;natural language processing;dialogue generation;sequence-to-sequence;attention mechanism;emotional dictionary},
  doi={10.1109/AEECA59734.2023.00088},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10354679,
  author={Lalrempuii, Candy and Soni, Badal},
  booktitle={2023 18th International Joint Symposium on Artificial Intelligence and Natural Language Processing (iSAI-NLP)}, 
  title={Investigation of Data Augmentation Techniques for Assamese-English Language Pair Machine Translation}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Machine translation can deliver impressive results when a substantial parallel corpus is accessible. However, in a country like India, characterized by its linguistic diversity and numerous languages with distinct origins and scripts, most languages face a scarcity of resources, making it challenging to create translation models of high quality. This work investigates a neural machine translation system with data augmentation techniques to boost the translation quality for an extremely resource-constrained language pair, i.e., English–Assamese. We experiment with back-translation, tagged back-translation, iterative back-translation, and iterative tagged back-translation. A qualitative and quantitative analysis performed on the various data augmentation techniques is performed. Furthermore, human evaluation is carried out to evaluate the adequacy and fluency of the translation. Empirical results show that data augmentation via iterative back-translation methods and tagged approach enhances translation performance in extremely low-resource settings.},
  keywords={Statistical analysis;Linguistics;Data augmentation;Machine translation;Iterative methods;Artificial intelligence;Faces;Neural Machine Translation;Back-translation;Iterative Back-translation;NLP;BLEU},
  doi={10.1109/iSAI-NLP60301.2023.10354679},
  ISSN={2831-4565},
  month={Nov},}@ARTICLE{9689063,
  author={Pereira, Débora and Bozzato, Arianna and Dario, Paolo and Ciuti, Gastone},
  journal={IEEE Transactions on Automation Science and Engineering}, 
  title={Towards Foodservice Robotics: A Taxonomy of Actions of Foodservice Workers and a Critical Review of Supportive Technology}, 
  year={2022},
  volume={19},
  number={3},
  pages={1820-1858},
  abstract={Foodservice workers perform several burdensome, tedious, and unsafe tasks that risk their health and well-being. This could be mitigated or even more avoided by using autonomously-actuated machines. Therefore, this article aims to build the foundation to support the development of a new field of robotics research dedicated to foodservice and with a human/worker-centered framework. As so, we introduce a two-level taxonomy of basic actions that compose the physical tasks of foodservice workers; it can guide future studies to design bio-inspired control models for foodservice robots. Actions are clustered in 16 categories according to their purpose and to the handled food. Furthermore, authors make a critical review of single-action equipment (SAE) and advanced equipment (AE) currently available for foodservice, which allowed us to identify opportunities for research. As a result, authors found some categories of actions rarely automated, aimed at i) separating solid-solid food parts, ii) moving food between workstations or independent appliances in the kitchen, iii) introducing food into another solid food or recipient, and iv) other specific actions, e.g. trussing food. In addition, authors discuss the applicability of collaborative robotics and human-robot collaboration to different contexts in foodservice, and show how artificial intelligence is improving the capabilities of SAE and AE and what else it could improve in this context. Note to Practitioners—This paper was motivated by a critical need in foodservice: the ability to produce consistent and high-quality meals ad-hoc, without overloading the workers or harming their health. Robotic and autonomous systems are promising technologies to solve this. However, there is not a unified framework in robotics research focused on the professional foodservice environment. This paper provides two tools for researchers and engineers in this field: (i) a taxonomy of basic actions that foodservice workers perform during their physical tasks; and (ii) a systematic review of mechatronic systems being developed or already in use in foodservice. The taxonomy can be immediately useful to divide research and development by the classes of actions. In addition, we found specific categories of actions that have been rarely automated so far and need further investigation. The results of our review can be readily applied in industry, too: presently, most equipment is a custom-built machine with limited adaptiveness; when systems include industrial robots, cobots are being preferred; the implementation of collaborative operations between humans and robots is not common yet and its applicability may be suitable only for certain contexts; finally, we identify scientific publications introducing adaptive control strategies and movement policies for some actions that can be implemented today to achieve a more robust actuation.},
  keywords={Robots;Task analysis;Service robots;Taxonomy;Robot kinematics;Collaboration;Stress;Taxonomy of actions;professional appliances;food service automation;foodservice collaborative robots;intelligent systems},
  doi={10.1109/TASE.2021.3129077},
  ISSN={1558-3783},
  month={July},}@INPROCEEDINGS{10420351,
  author={Ajay, B N and Manu, K. S and Preethi, M},
  booktitle={2023 International Conference on Recent Advances in Science and Engineering Technology (ICRASET)}, 
  title={A Comprehensive Overview of the Novel Approach to Detect Alzheimer’s Disease using Deep Learning and Convolutional Neural Network}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={Alzheimer’s disease (AD) is a progressive neurodegenerative disorder characterized by cognitive decline and memory loss. Early and accurate diagnosis of AD is crucial for effective treatment and intervention. In recent years, deep learning techniques, particularly Convolutional Neural Networks (CNNs), have emerged as powerful tools for automated disease diagnosis from medical imaging data. This abstract presents a promising approach utilizing deep learning and CNNs for Alzheimer’s detection. The proposed method involves leveraging neuroimaging data, such as magnetic resonance imaging (MRI) scans, to develop a reliable and automated AD diagnostic system. Initially, the MRI scans are pre-processed to enhance image quality and remove noise. Subsequently, a CNN architecture is designed and trained using a large dataset of both AD and non-AD images. The CNN learns intricate features and patterns directly from the data, enabling it to distinguish AD- related structural abnormalities and identify potential biomarkers. The trained CNN model is then employed for AD diagnosis by inputting new, unseen MRI scans. The model applies its learned knowledge to extract relevant features from the input images and generates a diagnostic output indicating the likelihood of AD presence. The diagnostic output can be further validated and interpreted by medical professionals, assisting them in making informed decisions regarding patient care and treatment strategies.},
  keywords={Deep learning;Neuroimaging;Magnetic resonance imaging;Biological system modeling;Feature extraction;Convolutional neural networks;Alzheimer's disease;Image Processing (IP);Alzheimer’s disease(AD);Stem cell;magnetic resonance imaging (MRI)},
  doi={10.1109/ICRASET59632.2023.10420351},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10165611,
  author={Si, YuHang and He, Dongzhi},
  booktitle={2023 IEEE 3rd International Conference on Information Technology, Big Data and Artificial Intelligence (ICIBA)}, 
  title={Image style transfer based on local matching and global alignment}, 
  year={2023},
  volume={3},
  number={},
  pages={716-720},
  abstract={In recent years, image style transfer and deep learning technology have developed rapidly. It has been widely used in many fields, such as film and TV filters and art creation. However, the quality of the generated stylized images still needs improvement, often with content structure distortion, content detail loss, lack of semantic perception, and other problems. In this paper, we propose an image style transfer method based on local matching and global alignment. The local matching module is used to enhance the semantic similarity perception and improve the local style. The global alignment module improves the content structure distortion problem by aligning the statistical information of features. The integration of local matching information and global alignment information can better balance the style and content structure. The comparison experiments of stylized effects demonstrate that our approach can generate high-quality stylized images.},
  keywords={Deep learning;Matched filters;TV;Deformation;Semantics;Big Data;Distortion;Style transfer;deep learning;attention mechanisms;multi-scale fusion},
  doi={10.1109/ICIBA56860.2023.10165611},
  ISSN={},
  month={May},}@INPROCEEDINGS{10674557,
  author={Sun, Wenjing},
  booktitle={2024 IEEE 4th International Conference on Software Engineering and Artificial Intelligence (SEAI)}, 
  title={Exploiting the Benefits of Popularity Bias Based on Causal Graphs in Optimizing Recommender Systems}, 
  year={2024},
  volume={},
  number={},
  pages={376-381},
  abstract={A common issue with recommend systems is the popularity bias, leading to long-tailed effects on item distribution. The resultant distribution discrepancy between hot and long-tail items would not only inherit the bias but also amplify the bias, which contradicts personalized recommendations. Existing methods tend to overlook the benign popularity bias caused by differences in item quality or directly injecting item popularity scores into prediction. In order to utilize item quality information revealing the item's inherent property, we use the casual graph to separate the beneficial popularity bias from the harmful popularity bias along the time dimension. We found that item quality, representing inherent properties, remains stable and static, whereas item popular bias, influenced by recent item clicks, is highly time-sensitive. Based on the therapy, we propose a novel framework to capture the critical cause-and-effect relationships named Time-Dimension Separating framework(TDS), where we model a click by casual graph generated from three components: the static item quality, the dynamic popularity effect, and the user-item matching score returned by any recommendation model. During testing, we employ counterfactual inference to mitigate the impact of item popularity. Significantly, our approach modifies the training process of recommendation models, making it applicable to a wide range of existing methods. Experiments on the Ciao, Amazon-Music, and Douban-Movie show that TDS outperforms the state-of-the-art methods. Especially the precision on Ciao, our TDS has improved by 46.1 percent over the baseline MF.},
  keywords={Training;Knowledge engineering;Medical treatment;Cognition;Recommender systems;Testing;Software engineering;recommend systems;debias;popular bias},
  doi={10.1109/SEAI62072.2024.10674557},
  ISSN={},
  month={June},}@ARTICLE{9465696,
  author={Yu, Lingyun and Xie, Hongtao and Zhang, Yongdong},
  journal={IEEE Transactions on Multimedia}, 
  title={Multimodal Learning for Temporally Coherent Talking Face Generation With Articulator Synergy}, 
  year={2022},
  volume={24},
  number={},
  pages={2950-2962},
  abstract={Talking face generation is a demanding task to synthesize a high quality video with accurate lip synchronization and rhythmic head motion. However, existing methods always suffer from unrealistic facial animations, because 1) they only take single-mode input, but ignore the complementarity of multimodal inputs for lip-sync improvement; 2) they only explore lip movements, but ignore the articulator synergy between lips and jaw; 3) they generate each video frame in a temporal-independent way, but ignore the temporal continuity among the entire video. To address these limitations, in this paper, we present a novel method to generate realistic and temporally coherent talking heads by considering multimodal inputs, articulator synergy, inter-frame consistency and intra-frame consistency. Firstly, for landmark prediction, a novel Multiple Synergy Network (MSN) is proposed to improve the accuracy of landmark prediction by incorporating multimodal inputs (i.e., audio and text inputs). Besides, instead of merely considering lip landmarks, we also explore the jaw movements to ensure articulator synergy among lips and jaw. Secondly, for realistic video generation, a Video Consistency Network (VCN) is proposed conditioned on the predicted landmarks. In VCN, the optical flow is adopted to model the temporal continuity between frames to ensure inter-frame consistency. Meanwhile, a mouth generation branch is proposed to enhance mouth texture and the corresponding mouth mask is employed to ensure intra-frame consistency between the mouth area and the others. Extensive experiments demonstrate that our approach exhibits excellent superiority on lip-sync and can generate photo-realistic facial animations. Project is available at http://imcc.ustc.edu.cn/project/tfgen/.},
  keywords={Mouth;Lips;Faces;Facial animation;Shape;Visualization;Task analysis;Articulator synergy;multimodal learning;talking face generation;adversarial training;video synthesis},
  doi={10.1109/TMM.2021.3091863},
  ISSN={1941-0077},
  month={},}@INPROCEEDINGS{8923033,
  author={Al-Zboon, Sa'ad A. and Tawalbeh, Saja Khaled and Ai-Jarrah, Heba and Al-Asa'd, Muntaha and Hammad, Mahmoud and Al-Smadi, Mohammad},
  booktitle={2019 2nd International Conference on new Trends in Computing Sciences (ICTCS)}, 
  title={Resolving Conflict of Interests in Recommending Reviewers for Academic Publications Using Link Prediction Techniques}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  abstract={An honest peer-review process is a key for producing high quality scientific research. However, this process depends on two main factors: (1) the expertise of reviewers in the topic of a submitted paper and (2) the relationships between reviewers and authors. To satisfy the first factor, editors and conferences chairs manually select reviewers. Whereas to prevent any conflict of interest (CoI) between reviewers and authors to satisfy the second factor, reviewers and authors are asked to declare any CoI manually. Such a solution is tedious to all actors and error-prone. To solve this problem and satisfy those two factors, we have developed a novel framework that (1) recommend expert reviewers and (2) resolve the CoIproblem. To develop our framework, we have represented the DBLP citation network dataset as a graph database using Neo4J. A Cypher queries used to select expert reviewers. Various link prediction algorithms, especially the Adamic Adar and the Common Neighbors algorithms, have been utilized to resolve any notential conflict of interest.},
  keywords={Prediction algorithms;Databases;Computer science;Social network services;Ciphers;Image edge detection;Marine vehicles;Conflict of Interests (CoIs);DBLP;Link Prediction;Adamic Adar;Common Neighbors},
  doi={10.1109/ICTCS.2019.8923033},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10407362,
  author={Rajendran, Saranpriya and Jadhav, Sanjay Akaram and Praba, J. Amutha and Muthukumaran, D. and Kiran., Kalvacherla and Sharma, Smita},
  booktitle={2023 9th International Conference on Smart Structures and Systems (ICSSS)}, 
  title={Leveraging the Internet of Things (IoT) for Disaster Management: Enhancing Resilience, Early Warning System in a Globally Connected World}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Natural disasters such as earthquakes, fires, and landslides pose significant threats to humanity. While it is impossible to prevent these disasters entirely, careful planning and the implementation of emergency measures, including effective alert systems, can help mitigate their consequences. Recent advancements in communication technology have paved the way for innovative monitoring systems that are designed to enhance disaster preparedness and response. This new monitoring system focuses on the real-time tracking of critical parameters, including water levels, earth vibrations, and room temperatures, through the use of sensors. These sensors are programmed to generate alert signals when the measured values surpass predefined threshold values, which are set to trigger warnings at levels indicative of potential disaster risks. The alerts generated by the system are transmitted in the form of text messages and Android application notifications. These alerts are promptly sent to relevant authorities through their mobile phones, ensuring that they are informed of the developing emergency situation in a timely manner. Additionally, the system incorporates a public address (PA) system to broadcast warning messages to local residents residing near the affected area. This broader alert mechanism ensures that not only authorities but also the general public are aware of potential dangers and can take necessary precautions. In conclusion, the integration of advanced communication technologies and sensor-based monitoring systems has paved the way for more effective disaster preparedness and response strategies.},
  keywords={Temperature sensors;Temperature measurement;Disasters;Sensor systems;Communications technology;Internet of Things;Monitoring;Internet of Things (IoT);Disaster Management;Temperature Sensor;Gas Sensor},
  doi={10.1109/ICSSS58085.2023.10407362},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10633328,
  author={Zhang, Yifan and Towey, Dave and Pike, Matthew},
  booktitle={2024 IEEE 48th Annual Computers, Software, and Applications Conference (COMPSAC)}, 
  title={Enabling Effective Metamorphic- Relation Generation by Novice Testers: A Pilot Study}, 
  year={2024},
  volume={},
  number={},
  pages={2393-2398},
  abstract={This paper presents a pilot study that examines the capacity of novice testers to generate Metamorphic Relations (MRs) for autonomous driving systems (ADSs), specifically fo-cusing on parking functions. By comparing MRs generated by human participants with those generated by artificial intelligence (AI), we seek to understand the variances in quality, particularly in terms of correctness, applicability, novelty, and utility. Our findings indicate that despite receiving only minimal training, human participants were capable of producing MRs with a wide range of effectiveness. Notably, humans exhibited a potential for creative thinking, contrasting with AI's ability to generate MRs that adhere closely to technical and applicability standards. The study underscores the need for improved educational strategies aimed at enhancing the quality and confidence of MRs produced by humans. Future research directions will explore the optimization of training approaches, particularly within a constrained timeframe to create a positive learning experience and maintain participant engagement, to fully harness the creative capabilities of human learners in the context of ADS testing.},
  keywords={Training;Computational modeling;Software;Artificial intelligence;Standards;Optimization;Autonomous vehicles;Metamorphic testing;autonomous driving system;metamorphic relation;driving scenarios;large language models;artificial intelligence},
  doi={10.1109/COMPSAC61105.2024.00384},
  ISSN={2836-3795},
  month={July},}@ARTICLE{9157954,
  author={Chavez-Garcia, R. Omar and Furger, Emian and Kronauer, Samuele and Brianza, Christian and Scarfo, Marco and Diviani, Luca and Giusti, Alessandro},
  journal={IEEE Robotics and Automation Letters}, 
  title={Learning to Predict Metal Deformations in Hot-Rolling Processes}, 
  year={2020},
  volume={5},
  number={4},
  pages={6270-6277},
  abstract={Hot-rolling is a metal forming process that produces a workpiece with a desired target cross-section from an input workpiece through a sequence of plastic deformations; each deformation is generated by a stand composed of opposing rolls with a specific geometry. In current practice, the rolling sequence (i.e., the sequence of stands and the geometry of their rolls) needed to achieve a given final cross-section is designed by experts based on previous experience, and iteratively refined in a costly trial-and-error process. Finite Element Method simulations are increasingly adopted to make this process more efficient and to test potential rolling sequences, achieving good accuracy at the cost of long simulation times, limiting the practical use of the approach. We propose a supervised learning approach to predict the deformation of a given workpiece by a set of rolls with a given geometry; the model is trained on a large dataset of procedurally-generated FEM simulations, which we publish as supplementary material. The resulting predictor is four orders of magnitude faster than simulations, and yields an average Jaccard Similarity Index of 0.972 (against ground truth from simulations) and 0.925 (against real-world measured deformations); we additionally report preliminary results on using the predictor for automatic planning of rolling sequences.},
  keywords={Strain;Finite element analysis;Deformable models;Geometry;Metals;Two dimensional displays;Predictive models;Product design, development and prototyping;simulation and animation;deep learning for visual perception},
  doi={10.1109/LRA.2020.3013833},
  ISSN={2377-3766},
  month={Oct},}@ARTICLE{10038280,
  author={Zhou, Boyu and Xu, Hao and Shen, Shaojie},
  journal={IEEE Transactions on Robotics}, 
  title={RACER: Rapid Collaborative Exploration With a Decentralized Multi-UAV System}, 
  year={2023},
  volume={39},
  number={3},
  pages={1816-1835},
  abstract={Although the use of multiple unmanned aerial vehicles (UAVs) has great potential for fast autonomous exploration, it has received far too little attention. In this article, we present a RApid Collaborative ExploRation (RACER) approach using a fleet of decentralized UAVs. To effectively dispatch the UAVs, a pairwise interaction based on an online hgrid space decomposition is used. It ensures that all UAVs simultaneously explore distinct regions, using only asynchronous and limited communication. Furthermore, we optimize the coverage paths of unknown space and balance the workloads partitioned to each UAV with a capacitated vehicle routing problem formulation. Given the task allocation, each UAV constantly updates the coverage path and incrementally extracts crucial information to support the exploration planning. A hierarchical planner finds exploration paths, refines local viewpoints, and generates minimum-time trajectories in sequence to explore the unknown space agilely and safely. The proposed approach is evaluated extensively, showing high exploration efficiency, scalability, and robustness to limited communication. Furthermore, for the first time, we achieve fully decentralized collaborative exploration with multiple UAVs in the real world. We will release our implementation as an open-source package.},
  keywords={Robots;Robot kinematics;Collaboration;Quadrotors;Task analysis;Resource management;Multi-robot systems;Aerial system;aerial systems;applications;cooperating robots;perception and autonomy},
  doi={10.1109/TRO.2023.3236945},
  ISSN={1941-0468},
  month={June},}@ARTICLE{10151951,
  author={Wang, Weiping and Zhang, Shunqi and Wang, Zhen and Luo, Xiong and Luan, Ping and Hramov, Alexander and Kurths, Jürgen and He, Chang and Li, Jianwu},
  journal={IEEE Transactions on Cognitive and Developmental Systems}, 
  title={Diagnosis of Early Mild Cognitive Impairment Based on Associated High-Order Functional Connection Network Generated by Multimodal MRI}, 
  year={2024},
  volume={16},
  number={2},
  pages={618-627},
  abstract={Mild cognitive impairment (MCI) is highly likely to convert to Alzheimer’s disease (AD). The main approach to identifying MCI is using a functional connection network (FCN). Traditional FCN is used to study the correlation between two brain regions, but it lacks deeper brain interaction information. Neuroscientists found the internal functional activity pattern in the human brain is characterized by sparse, modular, and overlapping structures, and the FCN is restricted by the brain structural connection network (SCN). They can improve the estimation accuracy of FCN. Therefore, this article first constructs low order FCN (LFCN) based on brain sparse, modular, and overlapping activity patterns. Then, new high-order FCN (HFCN) is proposed based on the restrictive relationship between SCN and FCN. To combine high robustness of LFCN with high sensitivity of HFCN, a new combination strategy of LFCN and HFCN is proposed. It integrates the idea of brain modular and overlapping with the restricted relationship between SCN and FCN. Finally, the experimental results show that in early MCI (EMCI) recognition the best classification performance is acquired with an accuracy of 91.42%, which is better than similar methods. This method will be instrumental in the early recognition of clinical MCI.},
  keywords={Diseases;Diffusion tensor imaging;Neuroimaging;Robustness;Functional magnetic resonance imaging;Time series analysis;Task analysis;Associated high-order functional connectivity network;early diagnosis;mild cognitive impairment (MCI);multimodal magnetic resonance imaging (MRI)},
  doi={10.1109/TCDS.2023.3283406},
  ISSN={2379-8939},
  month={April},}@INPROCEEDINGS{10188504,
  author={Sarder, Md. Nazmul and Al Mamun, Md. Abdullah and Ali, Md. Hasan and Haque, Md. Dulal and Rahman, Md. Ferdous and Islam, Abu Zafor Md. Touhidul},
  booktitle={2022 International Conference on Recent Progresses in Science, Engineering and Technology (ICRPSET)}, 
  title={Numerical simulation of MoSe2 based solar cell by SCAPS-1D}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={In this study, traditional $\text{MoSe}_{2}$ -based solar cells built with a thin-film Molybdenum diselenide $(\text{MoSe}_{2})$ back-surface field (BSF) layer have been produced and studied. The development of highly efficient, low-cost solar cells is the main goal of this research. The performance of the conventional AI/FTO/ZnSe/MoSe2/Ni SC is compared to that of the proposed AI/FTO/ZnSe/MoSe2/MoSe2/Ni SC structure. The photovoltaic characteristics of the devices, including open-circuit voltage, short-circuit current density, fill factor, and power conversion efficiency, have been investigated using Solar Cell Capacitance Simulator in One Dimension (SCAPS-1D) applications. The highly-doped $\text{MoSe}_{2}$ BSF layer and the MoSe2 absorber layer have been modified to have thicknesses of 0.5 and 0.1 m, respectively. The efficiency of the proposed photovoltaic (PV) structure, using a 0.5 $\text{m MoSe}_{2}$ absorber layer, is found to be 23.75%. The simulation's results suggest that using highly doped $\text{MoSe}_{2}$ as a BSF layer could result in the creation of cheap solar cells with a high efficiency. Keywords- Thin film solar cell, Transition metal dichalcogenides, $\text{MoSe}_{2}$, BSF layer, temperature, high efficiency.},
  keywords={Performance evaluation;Photovoltaic cells;Simulation;Short-circuit currents;Voltage;Numerical simulation;Transition metal dichalcogenides},
  doi={10.1109/ICRPSET57982.2022.10188504},
  ISSN={},
  month={Dec},}@ARTICLE{10286064,
  author={Hammoud, Ahmad and Mizouni, Rabeb and Otrok, Hadi and Singh, Shakti and Mourad, Azzam and Dziong, Zbigniew},
  journal={IEEE Transactions on Services Computing}, 
  title={A Blockchain-Based Hedonic Game Scheme for Reputable Fog Federations}, 
  year={2023},
  volume={16},
  number={6},
  pages={4432-4443},
  abstract={Fog computing empowers the internet of vehicles (IoV) paradigm by offering computational resources near the end users. In this dynamic paradigm, users tend to move in and out of the range of fog nodes which has implications for the quality of service of the vehicular applications. To cope with these limitations, scholars addressed forming federations of fog providers for task offloading purposes. Nonetheless, a few challenges remain a burden for the formation of the federations. The formation mechanisms used to structure the federations of providers are still not fully stable. This causes a problem because a structureless federation can lead to an underperforming infrastructure. Furthermore, most of the literature ignored the honesty metrics of the providers and how trustworthy they are in allocating the agreed-upon resources for processing the tasks. Moreover, adopting a central reputation mechanism is questionable in terms of reliability due to many complications including the lack of consensus. In this work, we develop a Blockchain-based reputation mechanism for assisting the formation of fog federations for IoV applications. Our mechanism comprises on-chain smart contracts for storing and manipulating the providers’ reputations, and an off-chain Hedonic-based formation process that considers the parameters extracted from the chain to build the federations. We develop smart contracts using Solidity and deploy them on the Ethereum Blockchain. We test our mechanism using the EUA dataset as a proof of concept and compare it to other works in the literature. The results obtained show that our approach is able to enhance the overall payoff and quality of service in the IoV paradigm.},
  keywords={Servers;Cloud computing;Quality of service;Games;Blockchains;Task analysis;Smart contracts;Fog federations;blockchain;Ethereum;Internet of Vehicles;game theory},
  doi={10.1109/TSC.2023.3324734},
  ISSN={1939-1374},
  month={Nov},}@INPROCEEDINGS{10895414,
  author={Narmatha, S. and Mythili, S.},
  booktitle={2024 International Conference on Emerging Research in Computational Science (ICERCS)}, 
  title={Deep Inception V5 Convolution Neural Network as Latent Features Supervision Network Towards Deep Fake Detection}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Deepfake has been widely exploited in recent years across various areas of social media platforms, movies, and news industries, which has led to multiple serious security concerns for society. Artificial intelligence approaches, in particular, make it easier to create and populate fake content on public platforms. Thus, it becomes mandatory to detect and prevent illegal deepfake content propagation. However, many researchers have developed Deepfake detection approaches using machine learning and deep learning architecture while those approaches bring more challenges in the form of generalization, underfitting and overfitting issues due to limited training labels. Hence, a new latent feature supervision network entitled Deep Inception V5 Convolution Neural Network increases the detection speed and detection accuracy with the general layer of the deep learning network on factorizing. Architecture provides excellent generalization on detecting the manipulated region of the content when processing the spatial and temporal features of the data. An inception network is highly capable of capturing a global and local distribution of the content effectively with the effective use of multiple filters simultaneously instead of increasing the layer of the network. Initially, content preprocessing is carried out to enhance the quality of the content based on transformation which changes the structure of the data and augmentation is to increase the structure of the data in terms of size and multiple characteristics. Those preprocessed data are projected to deep inception V5 architecture, which is composed of five inception modules with a convolution layer composed of filters of multiple sizes to capture the details of the image, The factorization layer is to reduce the parameter on factorizing the larger convolution to smaller convolutions, max pooling layer which calculate the maximum to the feature in the feature map and obtain the global features and local information separately, output layer provides the feature map and fully connected layer uses the SoftMax function through XG boost classifier to classifies the manipulated region from normal region accurately. And loss function through cross entropy to eliminate the overfitting and underfitting issues. Experimental analysis of the proposed deep inception V5 module is carried out using the DFDC dataset which is considered a deepfake dataset in a Python environment. Further performance of the proposed model is evaluated using cross-fold validation on test data against the conventional approaches. Finally, the proposed architecture provides 95.7% accuracy while training the model and 93.8% accuracy while validating the model.},
  keywords={Training;Deepfakes;Accuracy;Filters;Convolution;Social networking (online);Neural networks;Feature extraction;Entropy;Overfitting;Deepfake Detection;Inception V5 architecture;DFDC dataset;Deep Learning;Manipulated Region},
  doi={10.1109/ICERCS63125.2024.10895414},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10019499,
  author={Elsherbini, A. and Jun, K. and Liff, S. and Talukdar, T. and Bielefeld, J. and Li, W. and Vreeland, R. and Niazi, H. and Rawlings, B. and Ajayi, T. and Tsunoda, N. and Hoff, T. and Woods, C. and Pasdast, G. and Tiagaraj, S. and Kabir, E. and Shi, Y. and Brezinski, W. and Jordan, R. and Ng, J. and Brun, X. and Krisnatreya, B. and Liu, P. and Zhang, B. and Qian, Z. and Goel, M. and Swan, J. and Yin, G. and Pelto, C. and Torres, J. and Fischer, P.},
  booktitle={2022 International Electron Devices Meeting (IEDM)}, 
  title={Enabling Next Generation 3D Heterogeneous Integration Architectures on Intel Process}, 
  year={2022},
  volume={},
  number={},
  pages={27.3.1-27.3.4},
  abstract={This paper discusses a new generation of heterogeneous integration architectures which we refer to as quasi-monolithic chips (QMC). QMC enables flexible out-of-order combinations of silicon process & packaging techniques to create flexible and ultra-high interconnect density 3D architectures to fit future computing & AI needs. We show the main structural elements of the architecture and its performance including up to 10X interconnect power reduction and density improvements. We also cover the main new process modules needed to enable QMC including high density back-end compatible hybrid bonding and ultra-thick oxide fill modules.},
  keywords={Three-dimensional displays;Optical imaging;Silicon;Hybrid power systems;Dielectrics;Optical films;Bonding},
  doi={10.1109/IEDM45625.2022.10019499},
  ISSN={2156-017X},
  month={Dec},}@INPROCEEDINGS{10150143,
  author={Mira, Fahad},
  booktitle={2023 IEEE IAS Global Conference on Emerging Technologies (GlobConET)}, 
  title={Deep Learning Technique for Recognition of Deep Fake Videos}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={New computing methods and digital content have been created thanks to recent advancements in digital media technology. They have also contributed to advancing recent AI-based innovations and provide straightforward instruments for producing real video changes. These "Deep Fakes" or fraudulent films might seriously jeopardise the public’s perceptions of a case or society. These films’ consequences on spreading fake news, particularly, are significant when they act as accurate depictions. These false films may, however, be created by manipulating software. Data protection, identifying deep fakes, and preventing media manipulation are just a few ways deep fake detection contributes to cybersecurity. In light of this, it is essential and mandatory to be able to spot this sort of misleading data. This paper examines the most promising new approaches to deep fake video detection by analysing the latest findings from the research community. It analysed the results from two research and proposed using convolutional neural networks and long short-term memory to distinguish fake from real video frames. The report suggested using these and other detection methods and the unique method for identifying deep fakes that used the YOLO face detector to distinguish facial video frames (YOLO-CNN-XGBoost) and suggested investigating other novel detection methods.},
  keywords={Deep learning;Deepfakes;Visualization;Technological innovation;Social networking (online);Films;Instruments;Deep Learning;Deep Fake;Deep Fake Video;Video Recognition;Yolo;Fake Detection},
  doi={10.1109/GlobConET56651.2023.10150143},
  ISSN={},
  month={May},}@INPROCEEDINGS{9412507,
  author={Do, Thien and Pham, Van and Nguyen, Anh and Dang, Trung and Nguyen, Quoc and Hoang, Bach and Nguyen, Giao},
  booktitle={2020 25th International Conference on Pattern Recognition (ICPR)}, 
  title={Anime Sketch Colorization by Component-based Matching using Deep Appearance Features and Graph Representation}, 
  year={2021},
  volume={},
  number={},
  pages={3154-3161},
  abstract={Sketch colorization is usually expensive and time-consuming for artists, and automating this process can have many pragmatic applications in the animation, comic book, and video game industry. However, automatic image colorization faces many challenges, because sketches not only lack texture information but also potentially entail complicated objects that require acute coloring. These difficulties usually result in incorrect color assignments that can ruin the aesthetic appeal of the final output. In this paper, we present a novel component-based matching framework that combines deep learned features and quadratic programming with a new cost function to solve this colorization problem. The proposed framework inputs a character's sketches as well as a colored image in the same cut of a movie, and outputs a high-quality sequence of colorized frames based on the color assignment in the reference colored image. To carry out this colorization task, we first utilize a pretrained ResNet-34 model to extract elementary components' features to match certain pairs of components (one component from the sketch and one from reference). Next, a graph representation is constructed in order to process and match the remaining components that could not be done in the first step. Since the first step has reduced the number of components to be matched by the graph, we can solve this graph problem in a short computing time even when there are hundreds of different components present in each sketch. We demonstrate the effectiveness of the proposed solution by conducting comprehensive experiments and producing aesthetically pleasing results. To the best of our knowledge, our framework is the first work that combines deep learning extraction and graph representation to colorize anime sketches and achieves a high pixel-level accuracy at a reasonable time cost.},
  keywords={Visualization;Image color analysis;Shape;Semantics;Tools;Feature extraction;User experience},
  doi={10.1109/ICPR48806.2021.9412507},
  ISSN={1051-4651},
  month={Jan},}@INPROCEEDINGS{10961658,
  author={Aswathy, V S and Mathew, Tina Elizabeth},
  booktitle={2025 Emerging Technologies for Intelligent Systems (ETIS)}, 
  title={A Brief Study on Deepfake Detection and Prevention Approaches}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Images, movies, and sounds produced using artificial intelligence (AI) technologies that depict events or things that do not exist in reality are known as Deepfakes. Large volumes of labeled training data are needed for deep learning models, which are frequently employed in AI-based Deepfake detection, to learn meaningful representations of real and modified material. The expanding complexity of AI-generated material has raised concerns about Deepfake prevention. The prevention of Deepfake technology abuse necessitates a multifaceted strategy that includes social, legal, and technological safeguards. In this paper describes a guideline for Deepfake detection and prevention methods, its supporting tools and specifies various datasets to solving different modalities.},
  keywords={Deep learning;Deepfakes;Law;Prevention and mitigation;Training data;Motion pictures;Data models;Intelligent systems;Systematic literature review;Guidelines;Deepfake detection;Deepfake prevention;datasets},
  doi={10.1109/ETIS64005.2025.10961658},
  ISSN={},
  month={Feb},}@ARTICLE{10749763,
  author={Fachri, Moch and Hariadi, Mochamad and Mardi Susiki Nugroho, Supeno},
  journal={IEEE Access}, 
  title={Emotional Reciprocal Velocity Obstacles for Leader-Following: A Velocity Obstacles-Based Steering Behavior}, 
  year={2024},
  volume={12},
  number={},
  pages={169977-169987},
  abstract={The steering behavior of autonomous agents in animation and games aims to form agent movement to navigate around a virtual world. Leader-following behavior is a steering behavior formed by followers who must follow their leader while the leader guides the group to their destination. Followers need to deter themself from crowding their leader as it will interfere with their leader’s navigation, but at the same time, they want to remain close to the leader to avoid missing their way. These followers’ actions may hinder the leader’s movement thus creating a disturbance. This study propose a new design for leader-following behavior. We employ Emotional Reciprocal Velocity Obstacles (ERVO) to handle the multi-agent navigation in a leader-following manner. Our method lies in applying the ERVO model to embed the necessity for the follower to follow their leader with stress safety direction that lies at a certain distance to their respective leader. We also conducted a series of experiments to compare our method with several other leader-following methods. The experiment with up to 100 agents shows that our method produced less interaction overhead by 0.753 seconds with 18.81% less collision compared with other leader-following method.},
  keywords={Hazards;Mathematical models;Navigation;Anxiety disorders;Attenuation;Collision avoidance;Autonomous agents;Animation;Trajectory;Games;Autonomous agents;emotional reciprocal velocity obstacles;leader-following;steering behavior;velocity obstacles},
  doi={10.1109/ACCESS.2024.3494834},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10386329,
  author={Kaplunovich, Alex},
  booktitle={2023 IEEE International Conference on Big Data (BigData)}, 
  title={Wealth of Nations, Wealth of Data: How GDP Shapes Diverse Large Language Models like ChatGPT : Interviewing Assorted Open Source Generative AI Models}, 
  year={2023},
  volume={},
  number={},
  pages={4654-4663},
  abstract={Generative large language models (such as ChatGPT) are increasingly influencing various aspects of our lives, partly due to their training on vast datasets that encompassing big data paradigms and range of topics. "Intervista," an award-winning Italian film by Federico Fellini, focuses on his interview with a Japanese TV crew. Inspired by this, we conducted interviews with a diverse set of open-source and OpenAI models to explore various political, economic, and cultural aspects of life, evaluating LLM performance. We also examined whether a correlation exists between a country’s GDP per capita and the quality of the model’s answers. To this end, we utilized a Huggingface model leaderboard to select appropriate models and deployed them in an AWS SageMaker GPU environment. The identical questions were posed about nearly 200 countries, and the responses were analyzed to verify their accuracy and correlation with Gross Domestic Product (GDP). We were amazed by the diversity, quantity, and quality of existing pretrained open-source LLMs. Our journey provided insights into model selection, inference pipeline automation, GPU configuration, generated texts benchmarking, and systematic evaluation of model quality. Overall, leading LLMs performed well, providing reasonable responses for many countries. However, we discovered that the depth and detail of the answers were influenced by a country’s GDP per capita, with higher-income nations receiving more accurate responses.},
  keywords={Training;Economic indicators;Biological system modeling;Pipelines;Graphics processing units;Chatbots;Data models;LLM;Generative AI;GDP per capita;AWS Sagemaker;Huggingface;Inference Analysis;Automation;ChatGPT},
  doi={10.1109/BigData59044.2023.10386329},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10375046,
  author={Ismail, Muhammad and Shah, Syed Luqman and Muhammad, Fazal and Shafiq, Zeeshan},
  booktitle={2023 18th International Conference on Emerging Technologies (ICET)}, 
  title={Enhancing Vehicular Network Performance through Integrated RSU and UAV Deployment}, 
  year={2023},
  volume={},
  number={},
  pages={281-286},
  abstract={The on growing demand for reliable vehicle commu-nication services creates issues in providing continuous connectiv-ity and effective data delivery. Traditional roadside units (RSUs) need help adapting to changing traffic circumstances and user density. Integrating unmanned aerial Vehicles (UAVs) as aerial base stations provides a solution by increasing the coverage, relia-bility, and line-of-sight communication, and allowing for dynamic deployment. This research work uses self-learning methodology to focus on efficient and effective RSUs, UAVs, and UAV-assistant (UAVa) deployment inside vehicular networks. The primary goals are to improve network performance, Quality of Service (QoS), and interference management. In this article, we have considered two different scenarios in vehicular networks in which we have integrated a UAVa to handle emergency situations on the roads which dynamically provides network coverage to the uncovered vehicles on the roadside. We strategically deploy UAVa using a hybrid method that combines heuristic algorithms and real-world traffic insights to balance existing vehicular network resources, minimize latency, and eliminate interference. The simulation findings show that the UAVa has a much higher throughput than RSUs, emphasizing the need for dynamic adaptation and strategic positioning. This study emphasizes the significance of proper location and intelligent support in maximizing throughput and ensuring the reliability of vehicle data exchange.},
  keywords={Base stations;Roads;Heuristic algorithms;Line-of-sight propagation;Quality of service;Interference;Throughput;Vehicular Ad-hoc Networks (VANETs);Road-Side-Units (RSUs);Unmanned-Aerial-Vehicle (UAV);Line-of-Sight (LoS);Dynamic Deployment},
  doi={10.1109/ICET59753.2023.10375046},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9777160,
  author={Pandey, Amit and Janga, Vijaykumar and Aweke Wako, Desalegn and Senbato Genale, Assefa and Sundaram, B.Barani and Karthika, P.},
  booktitle={2022 6th International Conference on Trends in Electronics and Informatics (ICOEI)}, 
  title={Deep Learning Technology using New Media on Traditional Arts and Crafts of Complex Forms}, 
  year={2022},
  volume={},
  number={},
  pages={1359-1365},
  abstract={In the age of Computer technology, new media art Technology has grown rapidly. The technology comprises virtual art, animation, digital art, computer graphics, 3D Art, sound art, video games, robotics, internet art, 3Dpaintings, and 3D printing. The new media art Technology creates a lot of new jobs and also major universities offer courses and graduate programs in this field. The new media art Technology will not affect the traditional arts as critics say. Today there is a need for new media art. Everything has been digitalized by every business the digital media platforms social media video sharing video other internet Technologies for marketing. Digital marketing has replaced marketing techniques to a great extent. In this research article, we are going to study how the new media and deep learning Technology influences traditional arts and crafts in complex forms. For example, ceramic arts and potteries are traditional arts and crafts in complex forms. Ceramic arts and crafts and pottery are popular cultures and heritage symbols in many civilizations. This form of art for handmade traditionally involves a lot of painstaking effort in manufacturing. In this study, we are going to see how the new media art Technology is going to help in creating complex art forms with ease. The new media art Technology makes use of 3D printing technology to carry out this task. Deep learning is referred to as a type of machine learning Technology that uses artificial neural networks layers processing. Thus we found various advantages of new media art in the manufacturing of complex art forms like ceramic art pottery etc. In this research Broyden–Fletcher–Goldfarb–Shanno (L-BFGS) Algorithm is executed to analyze the presentation of the traditional arts and crafts learning with the aid of new media technology.},
  keywords={Deep learning;Art;Machine learning algorithms;Three-dimensional displays;Symbols;Media;Three-dimensional printing;Broyden-Fletcher-Goldfarb–Shanno (L-BFGS) Algorithm;New Media Art;Deep Learning (DL);Traditional Arts and Crafts;Crafts of Complex Forms;Ceramic Art;Pottery;Artificial Intelligence (AI;3D-Painting;Machine Learning (ML)},
  doi={10.1109/ICOEI53556.2022.9777160},
  ISSN={},
  month={April},}@INPROCEEDINGS{10657347,
  author={Wang, Zifan and Chen, Junyu and Chen, Ziqing and Xie, Pengwei and Chen, Rui and Yi, Li},
  booktitle={2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={GenH2R: Learning Generalizable Human-to-Robot Handover via Scalable Simulation, Demonstration, and Imitation}, 
  year={2024},
  volume={},
  number={},
  pages={16362-16372},
  abstract={This paper presents GenH2R, a framework for learning generalizable vision-based human-to-robot (H2R) handover skills. The goal is to equip robots with the ability to reliably receive objects with unseen geometry handed over by humans in various complex trajectories. We acquire such generalizability by learning H2R handover at scale with a comprehensive solution including procedural simulation assets creation, automated demonstration generation, and effective imitation learning. We leverage large-scale 3D model repositories, dexterous grasp generation methods, and curve-based 3D animation to create an H2R handover simulation environment named GenH2R-Sim, surpassing the number of scenes in existing simulators by three orders of magnitude. We further introduce a distillation-friendly demonstration generation method that automati-cally generates a million high-quality demonstrations suitable for learning. Finally, we present a 4D imitation learning method augmented by a future forecasting objective to distill demonstrations into a visuo-motor handover policy. Experimental evaluations in both simulators and the real world demonstrate significant improvements (at least +10% success rate) over baselines in all cases.},
  keywords={Geometry;Solid modeling;Three-dimensional displays;Imitation learning;Handover;Animation;Trajectory;Human-to-Robot Handover;Human Robot Interaction;Imitation Learning;Sim-to-Real Transfer},
  doi={10.1109/CVPR52733.2024.01548},
  ISSN={2575-7075},
  month={June},}@INPROCEEDINGS{9879640,
  author={Dai, Peng and Yu, Xin and Ma, Lan and Zhang, Baoheng and Li, Jia and Li, Wenbo and Shen, Jiajun and Qi, Xiaojuan},
  booktitle={2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Video Demoiréing with Relation-Based Temporal Consistency}, 
  year={2022},
  volume={},
  number={},
  pages={17601-17610},
  abstract={Moiré patterns, appearing as color distortions, severely degrade image and video qualities when filming a screen with digital cameras. Considering the increasing demands for capturing videos, we study how to remove such undesirable moiré patterns in videos, namely video demoiréing. To this end, we introduce the first hand-held video demoiréing dataset with a dedicated data collection pipeline to ensure spatial and temporal alignments of captured data. Further, a baseline video demoiréing model with implicit feature space alignment and selective feature aggregation is developed to leverage complementary information from nearby frames to improve frame-level video demoiréing. More importantly, we propose a relation-based temporal consistency loss to encourage the model to learn temporal consistency priors directly from ground-truth reference videos, which facilitates producing temporally consistent predictions and effectively maintains frame-level qualities. Extensive experiments manifest the superiority of our model. Code is available at ht tps:// daipengwa. github.io/VDmoire_ProjectPage/.},
  keywords={Visualization;Image color analysis;Pipelines;Predictive models;Data collection;Distortion;Digital cameras;Low-level vision; Computational photography; Datasets and evaluation},
  doi={10.1109/CVPR52688.2022.01710},
  ISSN={2575-7075},
  month={June},}@ARTICLE{10938585,
  author={Vaz, Marlon de Oliveira and Frates Rohrich, Ronnier and Fabro, João Alberto and Oliveira, André Schneider de},
  journal={IEEE Access}, 
  title={A Concise Dataset for Intelligent Behaviors in Domestic Tasks}, 
  year={2025},
  volume={13},
  number={},
  pages={54722-54738},
  abstract={For service robots operating in domestic environments, high-level intelligent behaviors require a comprehensive understanding of objects through visual perception. The random placement of objects introduces variations that impact the accuracy of object detection and recognition. This study presents a novel method for automatically generating a concise image dataset, named the Object Dataset Federal University of Technology (ODUTF), to enhance intelligent behaviors in service robots to focus on domestic tasks. The dataset is produced using an automatic multicapture device that gathers RGB images, stereo information, depth images, and point-cloud data. This device has two degrees of freedom to adjust both the orientation of objects and the camera’s viewpoint. The method creates a precise and detailed visual description of objects, which improves a service robot’s ability to approach and pick up objects. This approach is evaluated within the context of the RoboCup@Home Brazil League, part of the international RoboCup competition dedicated to domestic service robots. This league involves diverse tasks, emphasizing object detection and recognition. The use of high-level intelligent behaviors is critical for overcoming domestic challenges, and ODUTF facilitates the deployment of more reliable deep neural network methods for tracking objects during pick-up tasks. Furthermore, ODUTF can be dynamically adapted using post-processing scripts to incorporate artificial features like varying backgrounds, luminosity, and noise.},
  keywords={Service robots;Robots;Cameras;Accuracy;Visual perception;Reliability;Visualization;Standards;Object recognition;Noise;Concise dataset;domestic tasks;multicapture device;RoboCup@Home;service robots},
  doi={10.1109/ACCESS.2025.3554607},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9362569,
  author={Tao, Xuejiao and Bai, Sen and Liu, Chun and Zhu, Change and Chen, Haojun and Yan, Yi},
  booktitle={2021 IEEE International Conference on Power Electronics, Computer Applications (ICPECA)}, 
  title={Algorithm of Controllable Fractal Image Based on IFS Code}, 
  year={2021},
  volume={},
  number={},
  pages={801-809},
  abstract={Simulated generation of fractal images is useful in various fields such as information steganography, art decoration, film and television scenes. However, the generation mechanism of fractal images has not been clarified, the function of generation parameters is not clear, and the generated fractal object is insufficiently controllable, which limit the application. Therefore, it is of great significance to explore the role of various affine transformation parameters in the IFS system to obtain the method of generating free and controllable fractal images. Based on the principle of generating fractal images by iterated function system, this paper analyzed the influence of the generation of each affine transformation of IFS code on the appearance of the fractal image. Fractal images with different transformation characteristics were generated by analyzing the types and variation law of affine transformation. The controllability parameters of the IFS code were adjusted to simulate different forms of fractal trees and fractal mountains, and to construct more natural fractal forest and fractal mountains based on this, so as to provide more controllable fractal images for application fields such as information steganography.},
  keywords={TV;Shape;Simulation;Forestry;Vegetation;Fractals;Power electronics;Fractal;affine transformation;controllable IFS code;fractal forest;fractal mountains},
  doi={10.1109/ICPECA51329.2021.9362569},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{10763313,
  author={Podishetti, Jagadeeshwar and Chintala, Sridhar and Gude, Srihari},
  booktitle={2024 4th International Conference on Sustainable Expert Systems (ICSES)}, 
  title={An Application of Deep Learning Techniques in Trajectory Planning of Autonomous Vehicles}, 
  year={2024},
  volume={},
  number={},
  pages={776-780},
  abstract={This research explores trajectory planning for Autonomous Vehicles, with a focus on optimizing routes for energy efficiency, safety, and regulatory compliance. Autonomous Vehicles utilize sensors, maps, and real-time traffic data to navigate dynamic and static obstacles, ensuring the safety of all road users. Collaborative planning, enabled by vehicle-to-vehicle and vehicle- to-infrastructure communication, is emerging as a crucial aspect of autonomous vehicles development, promising to enhance traffic flow and efficiency. The study examines various machine learning techniques, particularly deep learning and reinforcement learning, employed to improve the quality and safety of autonomous vehicles trajectory planning. These techniques enable autonomous vehicles to learn from human driving behaviors, adapt to complex environments, and optimize navigation strategies. Moreover, the study highlights the significant advancements and future potential of deep learning and reinforcement learning in creating more efficient, safe, and reliable autonomous driving systems.},
  keywords={Deep learning;Trajectory planning;Navigation;Vehicular ad hoc networks;Reinforcement learning;Trajectory;Safety;Vehicle dynamics;Autonomous vehicles;Vehicles;Trajectory Planning;Deep Learning;Autonomous Vehicles;Advanced Driver Assistance System;Machine Learning;Reinforcement Learning},
  doi={10.1109/ICSES63445.2024.10763313},
  ISSN={},
  month={Oct},}@ARTICLE{9540892,
  author={Chatzopoulos, Dimitris and Jain, Anurag and Gujar, Sujit and Faltings, Boi and Hui, Pan},
  journal={IEEE Internet of Things Journal}, 
  title={Toward Mobile Distributed Ledgers}, 
  year={2022},
  volume={9},
  number={11},
  pages={7891-7903},
  abstract={Advances in mobile computing have paved the way for new types of distributed applications that can be executed solely by mobile devices on Device-to-Device (D2D) ecosystems (e.g., crowdsensing). Sophisticated applications, like cryptocurrencies, need distributed ledgers (DLs) to function. DLs, such as blockchains and directed acyclic graphs (DAGs), employ consensus protocols to add data in the form of blocks. However, such protocols are designed for resourceful devices that are interconnected via the Internet. Moreover, existing DLs are not deployable to D2D ecosystems since their storage needs are continuously increasing. In this work, we introduce and analyze Mneme, a DAG-based DL that can be maintained solely by mobile devices. Mneme utilizes two novel consensus protocols: 1) Proof of Context (PoC) and 2) Proof of Equivalence (PoE). PoC employs users’ context to add data on Mneme. PoE is executed periodically to summarize data and produce equivalent blocks that require less storage. We analyze Mneme’s security and justify the ability of PoC and PoE to guarantee the characteristics of DLs: persistence and liveness. Furthermore, we analyze potential attacks from malicious users and prove that the probability of a successful attack is inversely proportional to the square of the number of mobile users who maintain Mneme.},
  keywords={Protocols;Distributed ledger;Mobile handsets;Internet of Things;Directed acyclic graph;Consensus protocol;Ecosystems;Consensus protocols;Device-to-Device (D2D) ecosystems;distributed ledgers (DLs)},
  doi={10.1109/JIOT.2021.3113730},
  ISSN={2327-4662},
  month={June},}@INPROCEEDINGS{9156752,
  author={Zamir, Syed Waqas and Arora, Aditya and Khan, Salman and Hayat, Munawar and Khan, Fahad Shahbaz and Yang, Ming-Hsuan and Shao, Ling},
  booktitle={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={CycleISP: Real Image Restoration via Improved Data Synthesis}, 
  year={2020},
  volume={},
  number={},
  pages={2693-2702},
  abstract={The availability of large-scale datasets has helped unleash the true potential of deep convolutional neural networks (CNNs). However, for the single-image denoising problem, capturing a real dataset is an unacceptably expensive and cumbersome procedure. Consequently, image denoising algorithms are mostly developed and evaluated on synthetic data that is usually generated with a widespread assumption of additive white Gaussian noise (AWGN). While the CNNs achieve impressive results on these synthetic datasets, they do not perform well when applied on real camera images, as reported in recent benchmark datasets. This is mainly because the AWGN is not adequate for modeling the real camera noise which is signal-dependent and heavily transformed by the camera imaging pipeline. In this paper, we present a framework that models camera imaging pipeline in forward and reverse directions. It allows us to produce any number of realistic image pairs for denoising both in RAW and sRGB spaces. By training a new image denoising network on realistic synthetic data, we achieve the state-of-the-art performance on real camera benchmark datasets. The parameters in our models are ~5 times lesser than the previous best method for RAW denoising. Furthermore, we demonstrate that the proposed framework generalizes beyond image denoising problem e.g., for color matching in stereoscopic cinema. The source code and pre-trained models are available at https://github.com/swz30/CycleISP.},
  keywords={Cameras;Image color analysis;Noise reduction;AWGN;Image denoising;Sensors;Pipelines},
  doi={10.1109/CVPR42600.2020.00277},
  ISSN={2575-7075},
  month={June},}@INPROCEEDINGS{10275999,
  author={Nithya, A. and Raja, Mandapati and Latha, D and Preetha, M and Karthikeyan, M and Uthayakumar, G S},
  booktitle={2023 4th International Conference on Smart Electronics and Communication (ICOSEC)}, 
  title={Artificial Intelligence on Mobile Multimedia Networks for Call Admission Control Systems}, 
  year={2023},
  volume={},
  number={},
  pages={1678-1683},
  abstract={An increased demand for multimedia services necessitates the implementation of high-speed networks and call admission control (CAC) schemes. Increasingly, consumers want to be able to watch movies and TV shows on their smartphones. The primary goal of this integrated neural fuzzy-based CAC method is to enhance quality of service (QoS) while also ensuring equitable allocation of resources, with the end goal of reducing the likelihood of calls being dropped or blocked in mobile multimedia networks. This results in a more accurate and reliable control system. This hybrid technique is further developed to produce a more effective computational model for traffic management and the equitable allocation of radio resources for new calls and handoff calls. The findings of the simulation reveal that a neural fuzzy-based CAC has the potential to achieve low call-dropping probability and maximum resource utilization in high-speed networks.},
  keywords={Wireless communication;Training;TV;Call admission control;High-speed networks;Multimedia systems;Supervised learning;Call Admission Control (CAC);Quality of Service (QoS);Fuzzy-based;Mobile Unit;Fixed Channel Allocation (FCA)},
  doi={10.1109/ICOSEC58147.2023.10275999},
  ISSN={},
  month={Sep.},}@ARTICLE{9444481,
  author={Mirza, Aamir Mehmood and Khan, Muhammad Naeem Ahmed and Wagan, Raja Asif and Laghari, Muhammad Bux and Ashraf, Muhammad and Akram, Muhammad and Bilal, Muhammad},
  journal={IEEE Access}, 
  title={ContextDrive: Towards a Functional Scenario-Based Testing Framework for Context-Aware Applications}, 
  year={2021},
  volume={9},
  number={},
  pages={80478-80490},
  abstract={Context-aware applications are emerging applications in the modern era of computing. These applications can determine and adapt to situational context to provide better user experience. Testing these applications is not straightforward. Constantly changing nature of context makes testing context-aware application is a challenging task. To uncover a defect in context-aware application, a test engineer needs activity (sequence of actions) and context information (context data); this makes test case development a difficult task. Conventional test case development methodologies do not cater for context information. Besides, conventional applications have only one input source, but context-aware application must obtain data from many sources to infer the context. Yet another issue that these applications often face is the noisy data problem as input data collected from physical sensors could be noisy. Test adequacy criteria are used as test stoppage rule and define the quality of testing as well as for generating test suites. Test adequacy criteria is helpful to control the cost of testing as well as determining/establishing confidence in the software product quality. A number of test adequacy criteria exist for testing conventional applications, but the same is not true for context-aware applications. Defining test adequacy criteria and test coverage measures for context-aware applications warrants further research. Several techniques have been developed by researchers to generate and execute test cases for context-aware applications; however, end-to-end testing and result analysis of executed test cases still remains a grueling task for the test engineers. The aim of this study is to automate end-to-end functional testing, analysis of the generated test results as well as functional/requirement coverage assessment. Moreover, we also present a confidence assessment template for result analysis. Test engineers can use our proposed framework to assess the requirement coverage. Our proposed framework will reduce testing time, efforts and cost thus enabling test engineers to execute more testing cycles to attain higher degree of test coverage.},
  keywords={Testing;Context-aware services;Automation;Software;Tools;Task analysis;Information and communication technology;Automatic testing;context awareness;end-to-end testing;model based testing;scenario-based testing;software quality;software testing},
  doi={10.1109/ACCESS.2021.3084887},
  ISSN={2169-3536},
  month={},}@ARTICLE{10614144,
  author={Yang, Wanyu and Cai, Feifan and Shu, Yang and Zhang, Zihao and Liu, Qi and Ding, Youdong},
  journal={IEEE Access}, 
  title={Colorize at Will: Harnessing Diffusion Prior for Image Colorization}, 
  year={2024},
  volume={12},
  number={},
  pages={107287-107296},
  abstract={Image colorization, a pivotal aspect of computer vision, employs advanced algorithms to transform grayscale images into realistic colors. This task is inherently challenging due to the need to balance colorfulness and fidelity while preserving local spatial structures and eliminating ghosting effect. To address these issues, Our research introduces a novel pipeline leveraging Stable Diffusion for image colorization, guided by color hint points or textual descriptions. Compared to current text-to-image model, Our key contributions include multi-modal input flexibility, a trainable pixel-level encoder and a controllable feature modulation block. The multi-modal input flexibility allows for the simultaneous use of grayscale images with color hint points and textual descriptions, facilitating the generation of colorized outputs with greater precision and alignment with user instructions. The trainable pixel-level encoder extracts multi-scale features from input images, guiding the diffusion process to capture generative diffusion prior for image colorization, thereby achieving better consistency between the input and output images. Additionally, the controllable feature modulation block is introduced to strike a balance between colorfulness and precision through an adjustable coefficient  $\alpha $ . By integrating Stable Diffusion with these innovative guidance advancements, our model overcomes previous limitations and showcases the potential of advanced generative models to produce highly realistic and contextually appropriate colorized images, significantly impacting applications such as historical restoration and contemporary creative processes.},
  keywords={Image color analysis;Gray-scale;Feature extraction;Task analysis;Modulation;Diffusion models;Diffusion processes;Diffusion models;Multisensory integration;Image colorization;diffusion models;color hint points;pixel-level control;multi-modal input},
  doi={10.1109/ACCESS.2024.3435485},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10775587,
  author={Shi, Yang and Chen, Gang and Li, Shuo and Zhou, Quan and Liang, Xueying and Gao, Hongqiu and Ge, Xiaoning and Zhao, Jingyu},
  booktitle={2024 6th International Conference on Energy, Power and Grid (ICEPG)}, 
  title={Research and Application of the Energy Science and Technology Intelligence Brain Integrating Large Model Technology and Patent Big Data Analysis}, 
  year={2024},
  volume={},
  number={},
  pages={19-26},
  abstract={Purpose/Significance] In the context of global carbon peak and carbon neutrality, China’s new energy industry has experienced rapid development, with its installed capacity consistently ranking first worldwide. To further strengthen and optimize this industry, there is an urgent need for technological empowerment to create a new quality of productivity and maintain competitive advantages. [Method/Process] This paper proposes an integration concept based on “energy technology + intelligence methods + digital intelligence technology”, incorporating advanced digital intelligence technology of large language models, and an energy technology analysis method with patent big data analysis as the starting point. [Results/Conclusion] D developed and established an energy central enterprise technology intelligence system that encompasses core functions such as industrial technology, enterprise talent, and industry trends. Based on this system, we have conducted an analysis study on cadmium telluride solar technology. Furthermore, the system has already provided practical support for the technological innovation work of national ministries, energy central enterprises, and others, which is of great significance for enhancing the development of China’s energy technology.},
  keywords={Industries;Productivity;Patents;Analytical models;Technological innovation;Big Data;Brain modeling;Data models;Digital intelligence;Tellurium;New Energy;Science and Technology Intelligence;Large Models;Artificial Intelligence;Patent Big Data;Photovoltaics;Cadmium Telluride;Digital Platform},
  doi={10.1109/ICEPG63230.2024.10775587},
  ISSN={},
  month={Sep.},}@ARTICLE{10557586,
  author={Bao, Yunjiao and Yan, Gangping and Cao, Lei and Niu, Chuqiao and Li, Qingkun and Sang, Guanqiao and Li, Lianlian and Wei, Yanzhao and Zhang, Xuexiang and Luo, Jie and Yang, Yanyu and Xu, Gaobo and Yin, Huaxiang},
  journal={IEEE Journal of the Electron Devices Society}, 
  title={Partially Isolated Dual Work Function Gate IGZO TFT With Obviously Reduced Leakage Current for 3D DRAMs}, 
  year={2024},
  volume={12},
  number={},
  pages={637-644},
  abstract={In this article, a partially isolated dual work function (PIDWF) gate In-Ga-Zn-O (IGZO) thin-film transistor (TFT) is proposed to reduce the off-state current (Ioff) obviously, which also provides a feasible integration method for stacking IGZO TFT on Si-based devices. It is found that compared with the general back gate IGZO TFT structure, the Ioff of the proposed IGZO TFT reduces from  $2.57\times 10{^{-}14 }$  A/ $\mu $  m to  $7.57\times 10{^{-}16 }$  A/ $\mu $  m, achieving two orders of magnitude improvement. This breakthrough has the potential to increase the retention time of DRAM applications by nearly 100 times. Moreover, the pronounced novel structure has mitigated parasitic capacitance, thereby leading to a notable 47.7% reduction in write latency within dynamic-random-access-memory (DRAM) circuits. The relevant operation mechanism is carefully demonstrated and verified by the simulation of the electric field and potential barrier results by technical computer-aided design (TCAD). Furthermore, the impacts of the dual gate work function level, the length, and the type of isolation dielectric between dual work function gates are systematically investigated. The results show that the off-state leakage is further reduced by increasing the difference of the work function levels between in dual gates, the dielectric length (LD) and using the isolation layer with a lower dielectric constant. The PIDWF gate IGZO TFT exhibits scalability and is capable of achieving an 84.6% reduction in leakage current even with ultra-short channel lengths, which offers a promising application for future 3D DRAM applications with little extra cost.},
  keywords={Logic gates;Thin film transistors;Three-dimensional displays;Metals;Fabrication;Transistors;Stacking;Gallium compounds;Dielectrics;Dual work function gate;In-Ga-Zn-O (IGZO) thin-fifilm transistor (TFT);isolation dielectric;off-state current (Ioff);partially isolated},
  doi={10.1109/JEDS.2024.3414469},
  ISSN={2168-6734},
  month={},}@INPROCEEDINGS{10085277,
  author={Paikaray, Divya and Chauhan, Ankit},
  booktitle={2023 International Conference on Artificial Intelligence and Smart Communication (AISC)}, 
  title={Complexity of Blockchain's Distributed Configuration to Rational User Behavior}, 
  year={2023},
  volume={},
  number={},
  pages={1262-1267},
  abstract={As a means of uniquely identifying mobile phones, this research plans to make use of naturally occurring defects in hardware components. Sensors and other mobile phone I/O components were tested for functionality. The goal of this method was to create hardware failure samples that could be sorted using just the device's mic and speaker. In this technique, an audio sample was generated by playing a known audio via the device's speakers and recording the resulting sound. The impact of these major elements on the reliability of the samples was investigated by collecting several sample sets. The collected samples' frequency responses were then extracted and sorted. Several classifiers were employed to sort the data into categories, and in some cases the results were more than 99.9 percent accurate. The results of this article suggest that microphone and speaker production faults might might possibly be utilized to identify devices.},
  keywords={Microwave integrated circuits;Production;Mobile handsets;Hardware;Blockchains;Safety;Sensors;Crypto currency monitoring;Block chain;Security Network},
  doi={10.1109/AISC56616.2023.10085277},
  ISSN={},
  month={Jan},}@ARTICLE{9739734,
  author={Siddharthan, Hariprasad and Deepa, T. and Chandhar, Prabhu},
  journal={IEEE Access}, 
  title={SENMQTT-SET: An Intelligent Intrusion Detection in IoT-MQTT Networks Using Ensemble Multi Cascade Features}, 
  year={2022},
  volume={10},
  number={},
  pages={33095-33110},
  abstract={Recently, the number of Internet of Things (IoT) networks has been grown exponentially, which results in more data sharing between devices without appropriate security mechanisms. Since huge data management is involved, maintaining the time constraints between the devices in IoT networks is another significant issue. To address these issues, an intelligent intrusion detection system has been adapted to recognize or predict a cyber-attack using Elite Machine Learning algorithms (EML), and a lightweight protocol is used to manage the time-constrained issue. The experimental analysis of work is done on a testbed setup with the hardware and sensors connected using a lightweight Message Queue Telemetry Transport (MQTT) protocol. This comprises three parts: (i) collection of data with the help of a sensor for three different scenarios called SEN-MQTTSET; (ii) multi-context feature generation using an ensemble statistical multi-view cascade feature generation algorithm from the SEN-MQTTSET dataset; and (iii) evaluating the dataset using ML algorithms. The SEN-MQTTSET dataset has been created from the three scenarios, such as normal, attack on a subscriber, and attack on a broker. The multi-context feature is generated from the raw dataset using an ensemble statistical multi-view cascade feature generation algorithm. The EML is proposed to select the best model for intrusion detection among ML algorithms such as Logistic Regression, K-Nearest Neighbour, Random Forest, Naive Bias, Support Vector Machine, Gradient Boosting, and Decision Tree by the performance metrics such as accuracy, prediction time, F1-score, and others. The proposed dataset is validated and the accuracy is found to be above 99% for the considered system model. Different quality parameters have been carried out for legitimate and attack traffic features to calculate the delay between the IoT-MQTT network.},
  keywords={Protocols;Quality of service;Sensors;Internet of Things;Wireless sensor networks;Logic gates;Telemetry;IoT-MQTT networks;DoS;multi-cascade features;machine learning},
  doi={10.1109/ACCESS.2022.3161566},
  ISSN={2169-3536},
  month={},}@ARTICLE{9627535,
  author={Lv, Pei and Fan, Jianqi and Nie, Xixi and Dong, Weiming and Jiang, Xiaoheng and Zhou, Bing and Xu, Mingliang and Xu, Changsheng},
  journal={IEEE Transactions on Multimedia}, 
  title={User-Guided Personalized Image Aesthetic Assessment Based on Deep Reinforcement Learning}, 
  year={2023},
  volume={25},
  number={},
  pages={736-749},
  abstract={Personalized image aesthetic assessment (PIAA) has recently become a hot topic due to its wide applications, such as photography, film, television, e-commerce, fashion design, and so on. This task is more seriously affected by subjective factors and samples provided by users. In order to acquire precise personalized aesthetic distribution by small amount of samples, we propose a novel user-guided personalized image aesthetic assessment framework. This framework leverages user interactions to retouch and rank images for aesthetic assessment based on deep reinforcement learning (DRL), and generates personalized aesthetic distribution that is more in line with the aesthetic preferences of different users. It mainly consists of two stages. In the first stage, personalized aesthetic ranking is generated by interactive image enhancement and manual ranking, meanwhile, two policy networks will be trained. These two networks will be trained iteratively and alternatively to facilitate the final personalized aesthetic assessment. In the second stage, these modified images are labeled with aesthetic attributes by one style-specific classifier, and then the personalized aesthetic distribution is generated based on the multiple aesthetic attributes of these images, which conforms to the aesthetic preference of users better. Compared with other existing methods, our approach has achieved new state-of-the-art in the task of personalized image aesthetic assessment on the public AVA and FLICKR-AES datasets.},
  keywords={Image enhancement;Task analysis;Reinforcement learning;Feature extraction;Visualization;Training;Neural networks;Deep reinforcement learning;image aesthetic assessment;personalized aesthetic distribution;personalized image enhancement;user interaction},
  doi={10.1109/TMM.2021.3130752},
  ISSN={1941-0077},
  month={},}@ARTICLE{9650580,
  author={Yu, Chih-Min and Ku, Meng-Lin and Wang, Li-Chun},
  journal={IEEE Internet of Things Journal}, 
  title={DTC-HSR: Distributed Topology Control and Hierarchical Self-Routing for Bluetooth Load Balancing Networks}, 
  year={2022},
  volume={9},
  number={20},
  pages={19545-19560},
  abstract={In this article, a distributed topology control approach with hierarchical self-routing (DTC-HSR) is presented for Bluetooth low-energy (BLE) networks. First, the conventional star piconet is replaced by the designed mesh-ring subnet with better throughput and lower delay. To achieve the goal of load balancing design, two phases, including the leader selection and the topology construction are executed in the proposed approach. In the leader selection phase, each master node discovers its adjacent slave nodes to determine a leader master as a coordinator. In the topology construction phase, the local mesh-ring subnet is first formed and then the global mesh-ring subnets are interconnected into the desired DTC-HSR topology. To form the local mesh-ring subnet, each leader master computes the desired number of piconets with even link connectivity and distributes the piconet connection information for each node to form a mesh-ring subnet. In addition, each master node connects with the other local mesh-ring subnets via its associated bridge nodes, including slave nodes, intrabridges, and interbridges to create the definitive DTC-HSR scatternet. Afterward, a hierarchical self-routing strategy is jointly employed for the DTC-HSR to efficiently deliver routed packets through different mesh-ring subnets. Simulation results demonstrate that the DTC-HSR topology with the even connectivity feature outperforms the dual-ring tree (DRT) and cluster-based mesh (CBM) approaches in terms of network transmission and energy efficiency performances. The DTC-HSR configuration thus achieves efficient topology construction and hierarchical self-routing for load balancing in BLE networks.},
  keywords={Topology;Network topology;Bluetooth;Routing;Routing protocols;Bridges;Spread spectrum communication;Hierarchical routing;load balance;mesh-ring network;topology construction},
  doi={10.1109/JIOT.2021.3135408},
  ISSN={2327-4662},
  month={Oct},}@INPROCEEDINGS{10131876,
  author={Silat, Safa and Mishra, Ved P. and Sadath, Lipsa},
  booktitle={2023 International Conference on Computational Intelligence and Knowledge Economy (ICCIKE)}, 
  title={Remo Vision: A Computer Vision Web Application}, 
  year={2023},
  volume={},
  number={},
  pages={134-139},
  abstract={With computer vision providing several functions which are used in many fields, it is essential to have accessibility to all available functions in one place and by all. The aim of this project is to develop a web application as a platform implementing various features such as real-time object detection, removal of background text and reduction of noise in images. This involves using the Flask framework to run python scripts to create a web application. This web application can then also be easily integrated into other systems as well as easily customisable on different devices with better flexibility and scalability of the application. Most of the features focused on are based on removal, hence the name RemoVision.},
  keywords={Knowledge engineering;Computer vision;Scalability;Object detection;Feature extraction;Real-time systems;Computational intelligence;Artificial intelligence;deep learning;neural networks;back-end development;front-end development},
  doi={10.1109/ICCIKE58312.2023.10131876},
  ISSN={},
  month={March},}@INPROCEEDINGS{10040274,
  author={Thamizharasi, M. and Lakshmi, M.},
  booktitle={2022 1st International Conference on Computational Science and Technology (ICCST)}, 
  title={Alzheimer's disease detection through Deep learning techniques: A Study}, 
  year={2022},
  volume={},
  number={},
  pages={429-434},
  abstract={Alzheimer's disease is one of the commonly occurring disease in which the common cause of dementia called as memory loss will happen resiliently and damage the brain activity. It also produces cognitive abilities and serious impact of interference with the day today life. Disease contains 60% to 80% of dementia cases in the early stages are predicted and further actions are initiated to alert the patient behaviour from abnormal activity. The direct impact of Alzheimer's disease (AD) interfere with the regular activity and make complexity in making decisions, thinking capability, problem solving and speaking. The evaluation of artificial intelligence (AI) created numerous ways of analysing strategies, helpful for making the early prediction. In spite of image processing technology, Machine learning models are created to analyse the disease features, symptoms, Chronic records to perform AD detection. The role of deep learning algorithm incorporated with image processing, deep feature extraction, and deep feature fusion enhances the scope of research in AD analysis. Further the benefit of deep learning algorithm to provide search detection mechanism. The presented study discusses various criteria of AD detection and tabulated the findings.},
  keywords={Deep learning;Analytical models;Machine learning algorithms;Scientific computing;Magnetic resonance imaging;Interference;Feature extraction;Alzheimer's disease;Machine learning;Image processing;Deep learning;brain disorders},
  doi={10.1109/ICCST55948.2022.10040274},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10896143,
  author={Chen, Jia and Liu, Fangze and Wang, Yingying},
  booktitle={2025 IEEE International Conference on Artificial Intelligence and eXtended and Virtual Reality (AIxVR)}, 
  title={MDD: Masked Deconstructed Diffusion for 3D Human Motion Generation from Text}, 
  year={2025},
  volume={},
  number={},
  pages={61-72},
  abstract={We present MDD (Masked Deconstructed Diffusion), a novel framework for generating high-fidelity 3D human motions from textual descriptions. Our MDD framework employs a multi-stage Kinematic Chain Quantization (KCQ) that effectively encodes motion sequences into a compact yet expressive codebook by capturing both local and global human kinematic features. This codebook is then leveraged by a Masked Deconstructed Diffusion Transformer (MDDT), which takes text inputs and iteratively refines the output motion sequence through masked index prediction in a deconstructed diffusion process. By aligning the prediction with the denoising process, our method strikes an optimal balance between generation quality and computational efficiency. Extensive evaluations on multiple established benchmarks demonstrate that MDD consistently outperforms state-of-the-art methods in terms of precision and semantic accuracy, while achieving superior inference speed. Our generated motions are further validated in multiple virtual reality (VR) scenes, showcasing the effectiveness of our framework in VR applications.},
  keywords={Solid modeling;Three-dimensional displays;Quantization (signal);Semantics;Noise reduction;Diffusion processes;Kinematics;Virtual reality;Transformers;Computational efficiency;3D Human Motion Generation;Artificial Intelligence;Virtual Reality;Character Animation;Deep Learning},
  doi={10.1109/AIxVR63409.2025.00017},
  ISSN={2771-7453},
  month={Jan},}@INPROCEEDINGS{10215412,
  author={Al-Hakimi, Asmaa Mahfoud and Subbiah, Ahgalya and Johar, Md Gapar Bin Md and Jaharadak, Adam Amril Bin},
  booktitle={2023 IEEE 14th Control and System Graduate Research Colloquium (ICSGRC)}, 
  title={A Review Study of an Intelligent Strategy Towards Higher Education Examination Management Structure Based on Fog Computing}, 
  year={2023},
  volume={},
  number={},
  pages={117-122},
  abstract={Universities currently employ manual and partial digital methods for managing examinations, which involve extensive paperwork and consume significant time. This approach raises significant issues, such as time-consuming processes, errors, poor exam and result quality, submission delays, plagiarism, inaccurate grading, and a lack of security. Lecturers face challenges when creating exam questions for every subject every semester, often reusing previous questions without considering their quality, failing educational quality standards. The marking of exam scripts is often rushed to meet deadlines, leading to substandard grading, and the entire process is time-consuming and requires unnecessary effort. Un considerable amount of paper is utilized, and the storage of exam scripts occupies substantial physical space, posing the risk of damage or loss. A novel approach was proposed via Intelligent Green Examination Structure based on fog computing to address these issues. This innovative structure aims to transform traditional examination procedures into an automated, intelligent, and secure system that reduces human involvement and ensures high-quality outcomes. This research focuses on evaluating the effectiveness of an Artificial Intelligence (AI)-powered digital exam management structure based on Fog Computing in enhancing the efficiency and security of exam administration. The structure of this paper begins with a problem discussion, hypothesis, objectives, significance of the research, literature review, and research methodology.},
  keywords={Plagiarism;Transforms;Manuals;Control systems;Delays;Security;Artificial intelligence;Big Data;IoT;AI;Green IT;Fog Computing},
  doi={10.1109/ICSGRC57744.2023.10215412},
  ISSN={2833-1028},
  month={Aug},}@ARTICLE{8481568,
  author={Chao, Qianwen and Deng, Zhigang and Xiao, Yangxi and He, Dunbang and Miao, Qiguang and Jin, Xiaogang},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Dictionary-based Fidelity Measure for Virtual Traffic}, 
  year={2020},
  volume={26},
  number={3},
  pages={1490-1501},
  abstract={Aiming at objectively measuring the realism of virtual traffic flows and evaluating the effectiveness of different traffic simulation techniques, this paper introduces a general, dictionary-based learning method to evaluate the fidelity of any traffic trajectory data. First, a traffic pattern dictionary that characterizes common patterns of real-world traffic behavior is built offline from pre-collected ground truth traffic data. The corresponding learning error is set as the benchmark of the dictionary-based traffic representation. With the aid of the constructed dictionary, the realism of input simulated traffic flow data can be evaluated by comparing its dictionary-based reconstruction error with the dictionary error benchmark. This evaluation metric can be robustly applied to any simulated traffic flow data; in other words, it is independent of how the traffic data are generated. We demonstrated the effectiveness and robustness of this metric through many experiments on real-world traffic data and various simulated traffic data, comparisons with the state-of-the-art entropy-based similarity metric for aggregate crowd motions, and perceptual evaluation studies.},
  keywords={Computational modeling;Measurement;Solid modeling;Trajectory;Dictionaries;Data models;Benchmark testing;Traffic simulation;crowd animation;data-driven simulation;dictionary learning;user study},
  doi={10.1109/TVCG.2018.2873695},
  ISSN={1941-0506},
  month={March},}
